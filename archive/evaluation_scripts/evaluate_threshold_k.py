#!/usr/bin/env python3
"""
Charlestonæ´ªæ°´è´å¶æ–¯ç½‘ç»œé˜ˆå€¼å’ŒTop-Kä¼˜åŒ–è„šæœ¬

åŠŸèƒ½ï¼š
1. ä½¿ç”¨å›ºå®šçš„ä¼˜åŒ–ç½‘ç»œ
2. ç½‘æ ¼æœç´¢æœ€ä½³æ¦‚ç‡é˜ˆå€¼å’ŒTop-Kå‚æ•°
3. è¯„ä¼°ä¸åŒå‚æ•°ç»„åˆçš„æ€§èƒ½
4. ç”Ÿæˆçƒ­å›¾å’Œæœ€ä¼˜å‚æ•°æ¨è

ç”¨æ³•ï¼š
    python evaluate_threshold_k.py

è¾“å‡ºï¼š
    - ç»ˆç«¯è¾“å‡ºæœ€ä½³å‚æ•°ç»„åˆ
    - results/grid_metrics.csv - ç½‘æ ¼æœç´¢ç»“æœ
    - figs/pr_heatmap.png - F1åˆ†æ•°çƒ­å›¾

æ³¨æ„ï¼š
    ç¡®ä¿å·²è¿è¡Œmain_clean.pyç”Ÿæˆç½‘ç»œæ–‡ä»¶
"""

import random
import numpy as np
import pandas as pd
import os
from collections import Counter, defaultdict
from typing import Dict, List, Tuple, Any

# æœºå™¨å­¦ä¹ å’Œè¯„ä¼°
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_auc_score, average_precision_score,
    brier_score_loss, classification_report
)

# å¯è§†åŒ–
import matplotlib.pyplot as plt
import seaborn as sns

# è´å¶æ–¯ç½‘ç»œ
from model import FloodBayesNetwork

# è®¾ç½®éšæœºç§å­ï¼ˆä¸main_clean.pyä¿æŒä¸€è‡´ï¼‰
RANDOM_SEED = 42
random.seed(0)
np.random.seed(0)

class ThresholdKOptimizer:
    """é˜ˆå€¼å’ŒTop-Kå‚æ•°ä¼˜åŒ–å™¨"""
    
    def __init__(self, 
                 network_csv_path="charleston_flood_network.csv",
                 data_csv_path="Road_Closures_2024.csv",
                 results_dir="results",
                 figs_dir="figs"):
        self.network_csv_path = network_csv_path
        self.data_csv_path = data_csv_path
        self.results_dir = results_dir
        self.figs_dir = figs_dir
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(results_dir, exist_ok=True)
        os.makedirs(figs_dir, exist_ok=True)
        
        # ç½‘æ ¼æœç´¢å‚æ•°
        self.prob_thr_list = [0.2, 0.3, 0.4, 0.5]
        self.topk_list = [1, 3, 5]
        
        # åˆå§‹åŒ–æ•°æ®å’Œæ¨¡å‹
        self.train_df = None
        self.test_df = None
        self.flood_net = None
        self.network_nodes = set()
        
        # é¢„è®¡ç®—çš„é¢„æµ‹ç»“æœï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
        self.prediction_cache = []
        
    def load_and_split_data(self):
        """åŠ è½½æ•°æ®å¹¶æŒ‰ç›¸åŒæ–¹å¼åˆ†å‰²"""
        print("1. åŠ è½½å’Œåˆ†å‰²æ•°æ®...")
        
        # åŠ è½½æ•°æ®ï¼ˆä¸evaluate_testset.pyå®Œå…¨ä¸€è‡´ï¼‰
        df = pd.read_csv(self.data_csv_path)
        df = df[df["REASON"].str.upper() == "FLOOD"].copy()
        
        # æ•°æ®é¢„å¤„ç†
        df["time_create"] = pd.to_datetime(df["START"], utc=True)
        df["link_id"] = df["STREET"].str.upper().str.replace(" ", "_")
        df["link_id"] = df["link_id"].astype(str)
        df["id"] = df["OBJECTID"].astype(str)
        
        # ä½¿ç”¨ç›¸åŒçš„éšæœºç§å­åˆ†å‰²
        self.train_df, self.test_df = train_test_split(
            df, test_size=0.3, random_state=RANDOM_SEED
        )
        
        print(f"   è®­ç»ƒé›†: {len(self.train_df)}æ¡")
        print(f"   æµ‹è¯•é›†: {len(self.test_df)}æ¡")
        
        return self.train_df, self.test_df
        
    def rebuild_bayesian_network(self):
        """é‡å»ºè´å¶æ–¯ç½‘ç»œï¼ˆå›ºå®šç½‘ç»œé…ç½®ï¼‰"""
        print("2. é‡å»ºå›ºå®šè´å¶æ–¯ç½‘ç»œ...")
        
        # åˆ›å»ºç½‘ç»œå®ä¾‹
        self.flood_net = FloodBayesNetwork(t_window="D")
        
        # æ‹Ÿåˆè¾¹é™…æ¦‚ç‡
        self.flood_net.fit_marginal(self.train_df)
        
        # ä½¿ç”¨å›ºå®šçš„ä¼˜åŒ–å‚æ•°
        self.flood_net.build_network_by_co_occurrence(
            self.train_df,
            occ_thr=10,    # å›ºå®šå‚æ•°
            edge_thr=3,
            weight_thr=0.4,
            report=False
        )
        
        # æ‹Ÿåˆæ¡ä»¶æ¦‚ç‡
        self.flood_net.fit_conditional(self.train_df, max_parents=2, alpha=1)
        
        # æ„å»ºæœ€ç»ˆè´å¶æ–¯ç½‘ç»œ
        try:
            self.flood_net.build_bayes_network()
            self.flood_net.check_bayesian_network()
            print("   âœ… å›ºå®šç½‘ç»œé‡å»ºæˆåŠŸ")
        except Exception as e:
            print(f"   âš ï¸ ç½‘ç»œæ„å»ºè­¦å‘Š: {e}")
        
        # è·å–ç½‘ç»œèŠ‚ç‚¹
        self.network_nodes = set(self.flood_net.network.nodes())
        print(f"   ç½‘ç»œèŠ‚ç‚¹æ•°: {len(self.network_nodes)}")
        
        return self.flood_net
        
    def compute_predictions_cache(self):
        """é¢„è®¡ç®—æ‰€æœ‰é¢„æµ‹ç»“æœï¼Œé¿å…é‡å¤è®¡ç®—"""
        print("3. é¢„è®¡ç®—é¢„æµ‹ç»“æœ...")
        
        road_frequencies = Counter(self.train_df['link_id'])
        test_by_date = self.test_df.groupby(self.test_df["time_create"].dt.floor("D"))
        
        total_predictions = 0
        
        for date, day_group in test_by_date:
            # å½“å¤©æ´ªæ°´é“è·¯
            flooded_roads = set(day_group["link_id"].unique())
            flooded_in_network = flooded_roads & self.network_nodes
            
            if len(flooded_in_network) == 0:
                continue
                
            # é€‰æ‹©evidence
            potential_evidence = {road for road in flooded_in_network 
                                if road_frequencies.get(road, 0) >= 2}
            
            if len(potential_evidence) == 0:
                continue
                
            evidence_roads = list(potential_evidence)[:3]
            evidence = {road: 1 for road in evidence_roads}
            target_roads = self.network_nodes - set(evidence_roads)
            
            if len(target_roads) == 0:
                continue
                
            # å¯¹æ¯ä¸ªç›®æ ‡é“è·¯è®¡ç®—é¢„æµ‹æ¦‚ç‡
            day_predictions = []
            for road in target_roads:
                try:
                    result = self.flood_net.infer_w_evidence(road, evidence)
                    prob_flood = result.get("flooded", 0.5)
                    true_flood = 1 if road in flooded_roads else 0
                    
                    day_predictions.append({
                        "date": str(date.date()),
                        "road": road,
                        "prob_flood": prob_flood,
                        "true_flood": true_flood,
                        "evidence": evidence.copy()
                    })
                    total_predictions += 1
                    
                except Exception as e:
                    continue
            
            # æŒ‰æ¦‚ç‡æ’åºï¼ˆç”¨äºTop-Kï¼‰
            day_predictions.sort(key=lambda x: x["prob_flood"], reverse=True)
            self.prediction_cache.append(day_predictions)
        
        print(f"   é¢„è®¡ç®—å®Œæˆ: {total_predictions}ä¸ªé¢„æµ‹, {len(self.prediction_cache)}å¤©")
        
    def evaluate_threshold_strategy(self, prob_thr: float) -> Dict[str, float]:
        """è¯„ä¼°æ¦‚ç‡é˜ˆå€¼ç­–ç•¥"""
        y_true, y_pred = [], []
        
        for day_predictions in self.prediction_cache:
            for pred in day_predictions:
                y_true.append(pred["true_flood"])
                y_pred.append(1 if pred["prob_flood"] >= prob_thr else 0)
        
        if len(y_true) == 0:
            return {"precision": 0, "recall": 0, "f1": 0, "hits_at_k": 0, "total_samples": 0}
        
        precision = precision_score(y_true, y_pred, zero_division=0)
        recall = recall_score(y_true, y_pred, zero_division=0)
        f1 = f1_score(y_true, y_pred, zero_division=0)
        
        return {
            "precision": precision,
            "recall": recall,
            "f1": f1,
            "hits_at_k": 0,  # ä¸é€‚ç”¨äºé˜ˆå€¼ç­–ç•¥
            "total_samples": len(y_true)
        }
        
    def evaluate_topk_strategy(self, k: int) -> Dict[str, float]:
        """è¯„ä¼°Top-Kç­–ç•¥"""
        total_hits = 0
        total_possible = 0
        all_true = []
        all_pred = []
        
        for day_predictions in self.prediction_cache:
            if len(day_predictions) == 0:
                continue
                
            # è®¡ç®—å½“å¤©å®é™…æ´ªæ°´æ•°
            actual_floods = sum(1 for pred in day_predictions if pred["true_flood"] == 1)
            total_possible += min(k, actual_floods) if actual_floods > 0 else 0
            
            # Top-Ké¢„æµ‹
            topk_roads = set()
            for i, pred in enumerate(day_predictions):
                if i < k:
                    topk_roads.add(pred["road"])
                    all_pred.append(1)  # Top-Kä¸­çš„é“è·¯æ ‡è®°ä¸ºé¢„æµ‹æ´ªæ°´
                else:
                    all_pred.append(0)  # å…¶ä»–é“è·¯æ ‡è®°ä¸ºé¢„æµ‹æ— æ´ªæ°´
                all_true.append(pred["true_flood"])
            
            # è®¡ç®—å‘½ä¸­æ•°
            day_hits = sum(1 for pred in day_predictions[:k] if pred["true_flood"] == 1)
            total_hits += day_hits
        
        # è®¡ç®—Hits@K
        hits_at_k = total_hits / total_possible if total_possible > 0 else 0
        
        # è®¡ç®—ä¼ ç»ŸæŒ‡æ ‡
        if len(all_true) > 0:
            precision = precision_score(all_true, all_pred, zero_division=0)
            recall = recall_score(all_true, all_pred, zero_division=0)
            f1 = f1_score(all_true, all_pred, zero_division=0)
        else:
            precision = recall = f1 = 0
        
        return {
            "precision": precision,
            "recall": recall,
            "f1": f1,
            "hits_at_k": hits_at_k,
            "total_samples": len(all_true)
        }
        
    def run_grid_search(self) -> pd.DataFrame:
        """è¿è¡Œç½‘æ ¼æœç´¢"""
        print("4. è¿è¡Œç½‘æ ¼æœç´¢...")
        
        results = []
        total_combinations = len(self.prob_thr_list) + len(self.topk_list)
        current = 0
        
        # è¯„ä¼°æ¦‚ç‡é˜ˆå€¼ç­–ç•¥
        for prob_thr in self.prob_thr_list:
            current += 1
            print(f"   è¿›åº¦ {current}/{total_combinations}: æ¦‚ç‡é˜ˆå€¼ {prob_thr}")
            
            metrics = self.evaluate_threshold_strategy(prob_thr)
            results.append({
                "strategy": "threshold",
                "prob_thr": prob_thr,
                "topk": 0,
                "precision": metrics["precision"],
                "recall": metrics["recall"],
                "f1": metrics["f1"],
                "hits_at_k": metrics["hits_at_k"],
                "total_samples": metrics["total_samples"]
            })
        
        # è¯„ä¼°Top-Kç­–ç•¥
        for k in self.topk_list:
            current += 1
            print(f"   è¿›åº¦ {current}/{total_combinations}: Top-{k}")
            
            metrics = self.evaluate_topk_strategy(k)
            results.append({
                "strategy": "topk",
                "prob_thr": 0.0,  # ä¸é€‚ç”¨
                "topk": k,
                "precision": metrics["precision"],
                "recall": metrics["recall"],
                "f1": metrics["f1"],
                "hits_at_k": metrics["hits_at_k"],
                "total_samples": metrics["total_samples"]
            })
        
        df = pd.DataFrame(results)
        print("   âœ… ç½‘æ ¼æœç´¢å®Œæˆ")
        return df
        
    def save_results(self, results_df: pd.DataFrame):
        """ä¿å­˜ç»“æœåˆ°CSV"""
        print("5. ä¿å­˜ç½‘æ ¼æœç´¢ç»“æœ...")
        
        csv_path = os.path.join(self.results_dir, "grid_metrics.csv")
        results_df.to_csv(csv_path, index=False, float_format='%.4f')
        
        print(f"   âœ… ç»“æœä¿å­˜åˆ°: {csv_path}")
        
    def print_top_results(self, results_df: pd.DataFrame):
        """æ‰“å°æŒ‰F1æ’åºçš„å‰5ä¸ªç»“æœ"""
        print("6. æœ€ä½³å‚æ•°ç»„åˆåˆ†æ...")
        
        # æŒ‰F1åˆ†æ•°æ’åº
        sorted_df = results_df.sort_values('f1', ascending=False)
        
        print(f"\n{'='*80}")
        print("ğŸ† æŒ‰F1åˆ†æ•°æ’åºçš„æœ€ä½³å‚æ•°ç»„åˆ (å‰5)")
        print(f"{'='*80}")
        
        print(f"{'æ’å':<4} {'ç­–ç•¥':<10} {'é˜ˆå€¼':<6} {'Top-K':<6} {'Precision':<10} {'Recall':<8} {'F1':<8} {'Hits@K':<8}")
        print("-" * 80)
        
        for i, (_, row) in enumerate(sorted_df.head(5).iterrows()):
            rank_symbol = "â˜…" if i == 0 else f"{i+1:2d}"
            strategy_display = "é˜ˆå€¼" if row['strategy'] == 'threshold' else f"Top-{int(row['topk'])}"
            thr_display = f"{row['prob_thr']:.1f}" if row['strategy'] == 'threshold' else "-"
            k_display = f"{int(row['topk'])}" if row['strategy'] == 'topk' else "-"
            
            print(f"{rank_symbol:<4} {strategy_display:<10} {thr_display:<6} {k_display:<6} "
                  f"{row['precision']:<10.4f} {row['recall']:<8.4f} {row['f1']:<8.4f} {row['hits_at_k']:<8.4f}")
        
        # æ ‡æ³¨æœ€ä½³é…ç½®
        best_row = sorted_df.iloc[0]
        print(f"\nğŸ¯ æ¨èé…ç½® (æœ€é«˜F1åˆ†æ•°):")
        if best_row['strategy'] == 'threshold':
            print(f"   ç­–ç•¥: æ¦‚ç‡é˜ˆå€¼ = {best_row['prob_thr']:.1f}")
        else:
            print(f"   ç­–ç•¥: Top-{int(best_row['topk'])} é¢„è­¦")
        print(f"   æ€§èƒ½: F1={best_row['f1']:.4f}, Precision={best_row['precision']:.4f}, Recall={best_row['recall']:.4f}")
        
        if best_row['strategy'] == 'topk':
            print(f"   Hits@{int(best_row['topk'])}: {best_row['hits_at_k']:.4f}")
        
    def create_heatmap(self, results_df: pd.DataFrame):
        """åˆ›å»ºF1åˆ†æ•°çƒ­å›¾"""
        print("7. ç”Ÿæˆçƒ­å›¾å¯è§†åŒ–...")
        
        # å‡†å¤‡çƒ­å›¾æ•°æ®
        # ç”±äºæˆ‘ä»¬æœ‰ä¸¤ç§ä¸åŒçš„ç­–ç•¥ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
        plt.figure(figsize=(12, 8))
        
        # åˆ†åˆ«å¤„ç†é˜ˆå€¼å’ŒTop-Kç­–ç•¥
        threshold_data = results_df[results_df['strategy'] == 'threshold']
        topk_data = results_df[results_df['strategy'] == 'topk']
        
        # åˆ›å»ºå­å›¾
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # é˜ˆå€¼ç­–ç•¥æŸ±çŠ¶å›¾
        if not threshold_data.empty:
            bars1 = ax1.bar(threshold_data['prob_thr'], threshold_data['f1'], 
                           color='skyblue', alpha=0.8, edgecolor='black')
            ax1.set_xlabel('Probability Threshold')
            ax1.set_ylabel('F1 Score')
            ax1.set_title('F1 Score vs Probability Threshold')
            ax1.grid(True, alpha=0.3)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, f1 in zip(bars1, threshold_data['f1']):
                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                        f'{f1:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # Top-Kç­–ç•¥æŸ±çŠ¶å›¾
        if not topk_data.empty:
            bars2 = ax2.bar(topk_data['topk'], topk_data['f1'], 
                           color='lightcoral', alpha=0.8, edgecolor='black')
            ax2.set_xlabel('Top-K')
            ax2.set_ylabel('F1 Score')
            ax2.set_title('F1 Score vs Top-K')
            ax2.grid(True, alpha=0.3)
            ax2.set_xticks(topk_data['topk'])
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, f1 in zip(bars2, topk_data['f1']):
                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                        f'{f1:.3f}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        
        # ä¿å­˜
        heatmap_path = os.path.join(self.figs_dir, "pr_heatmap.png")
        plt.savefig(heatmap_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"   ğŸ“Š çƒ­å›¾ä¿å­˜åˆ°: {heatmap_path}")
        
        # é¢å¤–åˆ›å»ºç»„åˆæ¯”è¾ƒå›¾
        self._create_combined_comparison(results_df)
        
    def _create_combined_comparison(self, results_df: pd.DataFrame):
        """åˆ›å»ºç­–ç•¥å¯¹æ¯”å›¾"""
        plt.figure(figsize=(14, 10))
        
        # åˆ›å»ºå¤šæŒ‡æ ‡å¯¹æ¯”
        metrics = ['precision', 'recall', 'f1']
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c']
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Threshold vs Top-K Strategy Comparison', fontsize=16, fontweight='bold')
        
        # 1. F1åˆ†æ•°å¯¹æ¯”
        ax1 = axes[0, 0]
        threshold_data = results_df[results_df['strategy'] == 'threshold']
        topk_data = results_df[results_df['strategy'] == 'topk']
        
        if not threshold_data.empty:
            ax1.plot(threshold_data['prob_thr'], threshold_data['f1'], 
                    'o-', color='blue', label='Threshold Strategy', linewidth=2, markersize=8)
        
        # ä¸ºTop-Kåˆ›å»ºè™šæ‹Ÿxè½´ä½ç½®
        if not topk_data.empty:
            x_pos = [0.6, 0.7, 0.8]  # å¯¹åº”k=1,3,5çš„ä½ç½®
            ax1.plot(x_pos, topk_data['f1'], 
                    's-', color='red', label='Top-K Strategy', linewidth=2, markersize=8)
            
            # æ·»åŠ Top-Kæ ‡ç­¾
            for x, k, f1 in zip(x_pos, topk_data['topk'], topk_data['f1']):
                ax1.annotate(f'K={int(k)}', (x, f1), textcoords="offset points", 
                           xytext=(0,10), ha='center', fontsize=9)
        
        ax1.set_xlabel('Threshold / Scaled K Position')
        ax1.set_ylabel('F1 Score')
        ax1.set_title('F1 Score Comparison')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. Precision-Recallæ•£ç‚¹å›¾
        ax2 = axes[0, 1]
        if not threshold_data.empty:
            ax2.scatter(threshold_data['recall'], threshold_data['precision'], 
                       c='blue', s=100, alpha=0.7, label='Threshold', marker='o')
            for _, row in threshold_data.iterrows():
                ax2.annotate(f'{row["prob_thr"]:.1f}', 
                           (row['recall'], row['precision']), 
                           textcoords="offset points", xytext=(5,5), fontsize=9)
        
        if not topk_data.empty:
            ax2.scatter(topk_data['recall'], topk_data['precision'], 
                       c='red', s=100, alpha=0.7, label='Top-K', marker='s')
            for _, row in topk_data.iterrows():
                ax2.annotate(f'K={int(row["topk"])}', 
                           (row['recall'], row['precision']), 
                           textcoords="offset points", xytext=(5,5), fontsize=9)
        
        ax2.set_xlabel('Recall')
        ax2.set_ylabel('Precision')
        ax2.set_title('Precision-Recall Plot')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. Hits@Kä¸“ç”¨å›¾
        ax3 = axes[1, 0]
        if not topk_data.empty:
            bars = ax3.bar(topk_data['topk'], topk_data['hits_at_k'], 
                          color='green', alpha=0.7, edgecolor='black')
            ax3.set_xlabel('K')
            ax3.set_ylabel('Hits@K')
            ax3.set_title('Hits@K Performance')
            ax3.set_xticks(topk_data['topk'])
            
            for bar, hits in zip(bars, topk_data['hits_at_k']):
                ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,
                        f'{hits:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # 4. ç»¼åˆæ’å
        ax4 = axes[1, 1]
        sorted_df = results_df.sort_values('f1', ascending=True)  # å‡åºï¼Œä¾¿äºæ°´å¹³æ¡å½¢å›¾
        
        y_pos = range(len(sorted_df))
        colors_rank = ['red' if i == len(sorted_df)-1 else 'lightblue' for i in range(len(sorted_df))]
        
        bars = ax4.barh(y_pos, sorted_df['f1'], color=colors_rank, alpha=0.8, edgecolor='black')
        
        # è®¾ç½®æ ‡ç­¾
        labels = []
        for _, row in sorted_df.iterrows():
            if row['strategy'] == 'threshold':
                labels.append(f"Thr={row['prob_thr']:.1f}")
            else:
                labels.append(f"Top-{int(row['topk'])}")
        
        ax4.set_yticks(y_pos)
        ax4.set_yticklabels(labels)
        ax4.set_xlabel('F1 Score')
        ax4.set_title('Strategy Ranking by F1 Score')
        
        # æ ‡æ³¨æœ€ä½³
        best_idx = len(sorted_df) - 1
        ax4.text(sorted_df.iloc[best_idx]['f1'] + 0.005, best_idx, 'â˜… Best', 
                va='center', fontweight='bold', color='red')
        
        plt.tight_layout()
        
        # ä¿å­˜ç»„åˆå›¾
        combined_path = os.path.join(self.figs_dir, "strategy_comparison.png")
        plt.savefig(combined_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"   ğŸ“ˆ ç­–ç•¥å¯¹æ¯”å›¾ä¿å­˜åˆ°: {combined_path}")
        
    def run_optimization(self):
        """è¿è¡Œå®Œæ•´çš„ä¼˜åŒ–æµç¨‹"""
        print("ğŸš€ å¼€å§‹é˜ˆå€¼å’ŒTop-Kå‚æ•°ä¼˜åŒ–...")
        print("="*60)
        
        try:
            # 1. æ•°æ®å‡†å¤‡
            self.load_and_split_data()
            
            # 2. é‡å»ºå›ºå®šç½‘ç»œ
            self.rebuild_bayesian_network()
            
            # 3. é¢„è®¡ç®—é¢„æµ‹ç»“æœ
            self.compute_predictions_cache()
            
            # 4. ç½‘æ ¼æœç´¢
            results_df = self.run_grid_search()
            
            # 5. ä¿å­˜ç»“æœ
            self.save_results(results_df)
            
            # 6. æ˜¾ç¤ºæœ€ä½³ç»“æœ
            self.print_top_results(results_df)
            
            # 7. ç”Ÿæˆå¯è§†åŒ–
            self.create_heatmap(results_df)
            
            print("\n" + "="*60)
            print("âœ… å‚æ•°ä¼˜åŒ–å®Œæˆï¼")
            print(f"ğŸ“ è¯¦ç»†ç»“æœ: {self.results_dir}/grid_metrics.csv")
            print(f"ğŸ“Š å¯è§†åŒ–å›¾è¡¨: {self.figs_dir}/")
            print("="*60)
            
            return results_df
            
        except Exception as e:
            print(f"\nâŒ ä¼˜åŒ–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None

def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = ThresholdKOptimizer()
    
    # è¿è¡Œä¼˜åŒ–
    results_df = optimizer.run_optimization()
    
    if results_df is not None:
        best_row = results_df.sort_values('f1', ascending=False).iloc[0]
        print(f"\nğŸ¯ æœ€ä¼˜é…ç½®å»ºè®®:")
        if best_row['strategy'] == 'threshold':
            print(f"   ä½¿ç”¨æ¦‚ç‡é˜ˆå€¼ç­–ç•¥: prob_thr = {best_row['prob_thr']:.1f}")
        else:
            print(f"   ä½¿ç”¨Top-{int(best_row['topk'])}é¢„è­¦ç­–ç•¥")
        print(f"   é¢„æœŸæ€§èƒ½: F1={best_row['f1']:.4f}")
    else:
        print("\nâŒ ä¼˜åŒ–å¤±è´¥")

if __name__ == "__main__":
    main()