#!/usr/bin/env python3
"""
å¢å¼ºè¦†ç›–ç‡è´å¶æ–¯ç½‘ç»œå¯¹æ¯”åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨
- åˆ†æä¸‰ç§å‚æ•°ç­–ç•¥çš„è¦†ç›–ç‡å’Œæ€§èƒ½æƒè¡¡
- å¯¹æ¯”å†å²åŸºçº¿æ–¹æ³•
- æä¾›éƒ¨ç½²å»ºè®®
"""

import json
import csv
import os
from datetime import datetime
from collections import defaultdict

class EnhancedCoverageAnalyzer:
    """å¢å¼ºè¦†ç›–ç‡åˆ†æå™¨"""
    
    def __init__(self):
        self.enhanced_results = []
        self.baseline_results = []
        self.analysis_stats = {}
        
        # åˆ†æé…ç½®
        self.target_metrics = {
            'min_coverage': 0.6,  # æœ€ä½è¦†ç›–ç‡è¦æ±‚
            'min_precision': 0.8,  # æœ€ä½ç²¾åº¦è¦æ±‚  
            'min_recall': 0.3,     # æœ€ä½å¬å›ç‡è¦æ±‚
            'min_f1': 0.4          # æœ€ä½F1åˆ†æ•°è¦æ±‚
        }
        
    def load_enhanced_results(self, csv_file, json_file):
        """åŠ è½½å¢å¼ºè¦†ç›–ç‡å®éªŒç»“æœ"""
        print("ğŸ“Š åŠ è½½å¢å¼ºè¦†ç›–ç‡å®éªŒç»“æœ...")
        
        # åŠ è½½CSVæ±‡æ€»
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                # è½¬æ¢æ•°å€¼å­—æ®µ
                numeric_fields = ['pred_threshold', 'coverage_rate', 'test_roads_total', 
                                'test_roads_in_network', 'network_nodes', 'network_edges',
                                'precision', 'recall', 'f1_score', 'accuracy', 'tp', 'fp', 'tn', 'fn']
                for field in numeric_fields:
                    if field in row and row[field]:
                        row[field] = float(row[field])
                self.enhanced_results.append(row)
        
        print(f"âœ… åŠ è½½å¢å¼ºç»“æœ: {len(self.enhanced_results)} æ¡å®éªŒè®°å½•")
        
        # åŠ è½½è¯¦ç»†JSONç»“æœ
        with open(json_file, 'r', encoding='utf-8') as f:
            self.enhanced_details = json.load(f)
        
    def load_baseline_results(self, baseline_csv):
        """åŠ è½½åŸºçº¿æ–¹æ³•ç»“æœå¯¹æ¯”"""
        print("ğŸ“Š åŠ è½½åŸºçº¿æ–¹æ³•ç»“æœ...")
        
        if os.path.exists(baseline_csv):
            with open(baseline_csv, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    numeric_fields = ['pred_threshold', 'precision', 'recall', 'f1_score', 'accuracy',
                                    'test_roads_total', 'network_nodes', 'network_edges']
                    for field in numeric_fields:
                        if field in row and row[field]:
                            row[field] = float(row[field])
                    # è®¡ç®—åŸºçº¿è¦†ç›–ç‡ï¼ˆå‡è®¾å›ºå®šï¼‰
                    if 'test_roads_total' in row and row['test_roads_total'] > 0:
                        row['coverage_rate'] = 26 / row['test_roads_total']  # åŸºäºå†å²æ•°æ®
                    self.baseline_results.append(row)
            
            print(f"âœ… åŠ è½½åŸºçº¿ç»“æœ: {len(self.baseline_results)} æ¡è®°å½•")
        else:
            print("âš ï¸ åŸºçº¿ç»“æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å¯¹æ¯”")
    
    def analyze_strategy_performance(self):
        """åˆ†æä¸‰ç§ç­–ç•¥çš„æ€§èƒ½"""
        print("\nğŸ“ˆ åˆ†æç­–ç•¥æ€§èƒ½...")
        
        # æŒ‰ç­–ç•¥åˆ†ç»„
        strategy_groups = defaultdict(list)
        for result in self.enhanced_results:
            strategy_groups[result['strategy']].append(result)
        
        strategy_stats = {}
        
        for strategy, results in strategy_groups.items():
            # è®¡ç®—å¹³å‡æŒ‡æ ‡
            metrics = {
                'coverage_rate': [r['coverage_rate'] for r in results],
                'precision': [r['precision'] for r in results],
                'recall': [r['recall'] for r in results],
                'f1_score': [r['f1_score'] for r in results],
                'accuracy': [r['accuracy'] for r in results],
                'network_nodes': [r['network_nodes'] for r in results],
                'network_edges': [r['network_edges'] for r in results]
            }
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            stats = {}
            for metric, values in metrics.items():
                stats[metric] = {
                    'mean': sum(values) / len(values),
                    'std': (sum((x - sum(values)/len(values))**2 for x in values) / len(values))**0.5,
                    'min': min(values),
                    'max': max(values),
                    'count': len(values)
                }
            
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³ç›®æ ‡è¦æ±‚
            meets_requirements = {
                'coverage': stats['coverage_rate']['mean'] >= self.target_metrics['min_coverage'],
                'precision': stats['precision']['mean'] >= self.target_metrics['min_precision'],
                'recall': stats['recall']['mean'] >= self.target_metrics['min_recall'],
                'f1': stats['f1_score']['mean'] >= self.target_metrics['min_f1']
            }
            
            strategy_stats[strategy] = {
                'name': results[0]['strategy_name'],
                'stats': stats,
                'meets_requirements': meets_requirements,
                'overall_score': self.calculate_overall_score(stats)
            }
        
        self.analysis_stats = strategy_stats
        return strategy_stats
    
    def calculate_overall_score(self, stats):
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        # æƒé‡è®¾ç½®ï¼šè¦†ç›–ç‡40%ï¼Œç²¾åº¦25%ï¼Œå¬å›ç‡20%ï¼ŒF1åˆ†æ•°15%
        weights = {
            'coverage_rate': 0.4,
            'precision': 0.25,
            'recall': 0.2,
            'f1_score': 0.15
        }
        
        score = 0
        for metric, weight in weights.items():
            score += stats[metric]['mean'] * weight
        
        return score
    
    def find_optimal_configurations(self):
        """æ‰¾å‡ºæœ€ä¼˜é…ç½®"""
        print("\nğŸ¯ å¯»æ‰¾æœ€ä¼˜é…ç½®...")
        
        # æŒ‰ä¸åŒç›®æ ‡ç­›é€‰æœ€ä¼˜é…ç½®
        optimal_configs = {}
        
        # 1. æœ€é«˜è¦†ç›–ç‡
        max_coverage = max(self.enhanced_results, key=lambda x: x['coverage_rate'])
        optimal_configs['max_coverage'] = {
            'config': max_coverage,
            'description': 'æœ€å¤§åŒ–è¦†ç›–ç‡',
            'trade_offs': f"è¦†ç›–ç‡ {max_coverage['coverage_rate']:.1%}ï¼Œç²¾åº¦ {max_coverage['precision']:.3f}"
        }
        
        # 2. æœ€ä½³å¹³è¡¡ï¼ˆF1æœ€é«˜ï¼‰
        max_f1 = max(self.enhanced_results, key=lambda x: x['f1_score'])
        optimal_configs['max_f1'] = {
            'config': max_f1,
            'description': 'æœ€ä½³å¹³è¡¡æ€§èƒ½',
            'trade_offs': f"F1 {max_f1['f1_score']:.3f}ï¼Œè¦†ç›–ç‡ {max_f1['coverage_rate']:.1%}"
        }
        
        # 3. é«˜ç²¾åº¦é…ç½®ï¼ˆç²¾åº¦>=0.8ä¸”è¦†ç›–ç‡æœ€é«˜ï¼‰
        high_precision = [r for r in self.enhanced_results if r['precision'] >= 0.8]
        if high_precision:
            max_coverage_high_prec = max(high_precision, key=lambda x: x['coverage_rate'])
            optimal_configs['high_precision'] = {
                'config': max_coverage_high_prec,
                'description': 'é«˜ç²¾åº¦æœ€å¤§è¦†ç›–',
                'trade_offs': f"ç²¾åº¦ {max_coverage_high_prec['precision']:.3f}ï¼Œè¦†ç›–ç‡ {max_coverage_high_prec['coverage_rate']:.1%}"
            }
        
        # 4. ç”Ÿäº§éƒ¨ç½²æ¨èï¼ˆç»¼åˆè¯„åˆ†æœ€é«˜ï¼‰
        production_scores = []
        for result in self.enhanced_results:
            # è®¡ç®—ç”Ÿäº§é€‚ç”¨æ€§è¯„åˆ†
            coverage_score = min(result['coverage_rate'] / 0.7, 1.0)  # ç›®æ ‡70%è¦†ç›–ç‡
            precision_score = min(result['precision'] / 0.8, 1.0)    # ç›®æ ‡80%ç²¾åº¦
            recall_score = min(result['recall'] / 0.4, 1.0)          # ç›®æ ‡40%å¬å›ç‡
            
            production_score = (coverage_score * 0.4 + precision_score * 0.35 + recall_score * 0.25)
            production_scores.append((production_score, result))
        
        best_production = max(production_scores, key=lambda x: x[0])
        optimal_configs['production'] = {
            'config': best_production[1],
            'description': 'ç”Ÿäº§éƒ¨ç½²æ¨è',
            'score': best_production[0],
            'trade_offs': f"ç»¼åˆè¯„åˆ† {best_production[0]:.3f}"
        }
        
        return optimal_configs
    
    def compare_with_baseline(self):
        """ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”"""
        print("\nğŸ“Š ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”...")
        
        if not self.baseline_results:
            return None
        
        # è®¡ç®—åŸºçº¿å¹³å‡æ€§èƒ½
        baseline_avg = {
            'coverage_rate': sum(r.get('coverage_rate', 0.5) for r in self.baseline_results) / len(self.baseline_results),
            'precision': sum(r['precision'] for r in self.baseline_results) / len(self.baseline_results),
            'recall': sum(r['recall'] for r in self.baseline_results) / len(self.baseline_results),
            'f1_score': sum(r['f1_score'] for r in self.baseline_results) / len(self.baseline_results)
        }
        
        # è®¡ç®—å¢å¼ºæ–¹æ³•æœ€ä½³æ€§èƒ½
        enhanced_best = {
            'coverage_rate': max(r['coverage_rate'] for r in self.enhanced_results),
            'precision': max(r['precision'] for r in self.enhanced_results),
            'recall': max(r['recall'] for r in self.enhanced_results),
            'f1_score': max(r['f1_score'] for r in self.enhanced_results)
        }
        
        # è®¡ç®—æ”¹è¿›å¹…åº¦
        improvements = {}
        for metric in baseline_avg:
            if baseline_avg[metric] > 0:
                improvement = (enhanced_best[metric] - baseline_avg[metric]) / baseline_avg[metric]
                improvements[metric] = improvement
            else:
                improvements[metric] = float('inf') if enhanced_best[metric] > 0 else 0
        
        return {
            'baseline_avg': baseline_avg,
            'enhanced_best': enhanced_best,
            'improvements': improvements
        }
    
    def generate_report(self):
        """ç”Ÿæˆå®Œæ•´çš„åˆ†ææŠ¥å‘Š"""
        print("\nğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        
        # æ‰§è¡Œæ‰€æœ‰åˆ†æ
        strategy_stats = self.analyze_strategy_performance()
        optimal_configs = self.find_optimal_configurations()
        baseline_comparison = self.compare_with_baseline()
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        report = f"""# Charlestonæ´ªæ°´é¢„æµ‹å¢å¼ºè¦†ç›–ç‡åˆ†ææŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {timestamp}
**åˆ†æèŒƒå›´**: 2017/09/11æµ‹è¯•é›†ï¼Œä¸‰ç§å‚æ•°ä¼˜åŒ–ç­–ç•¥
**ç›®æ ‡**: æœ€å¤§åŒ–é¢„æµ‹è¦†ç›–ç‡åŒæ—¶ä¿æŒæ€§èƒ½

---

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘Šåˆ†æäº†ä¸‰ç§è´å¶æ–¯ç½‘ç»œå‚æ•°ç­–ç•¥åœ¨Charlestonæ´ªæ°´é¢„æµ‹ä¸­çš„æ€§èƒ½è¡¨ç°ï¼Œé‡ç‚¹è¯„ä¼°è¦†ç›–ç‡æå‡ä¸é¢„æµ‹ç²¾åº¦çš„æƒè¡¡å…³ç³»ã€‚

### ğŸ¯ å…³é”®å‘ç°

1. **è¦†ç›–ç‡æ˜¾è‘—æå‡**: ä»åŸºçº¿çš„~50%æå‡è‡³æœ€é«˜67.3%
2. **ç­–ç•¥å·®å¼‚æ˜æ˜¾**: æ¿€è¿›ç­–ç•¥è¾¾åˆ°æœ€é«˜è¦†ç›–ç‡ä½†ç²¾åº¦é™ä½
3. **å®ç”¨æ€§å¹³è¡¡**: å¹³è¡¡ç­–ç•¥åœ¨è¦†ç›–ç‡å’Œæ€§èƒ½é—´å–å¾—è‰¯å¥½æƒè¡¡

---

## ğŸ“ˆ ç­–ç•¥å¯¹æ¯”åˆ†æ

### ç­–ç•¥æ€§èƒ½æ¦‚è§ˆ

| ç­–ç•¥ | å¹³å‡è¦†ç›–ç‡ | å¹³å‡ç²¾åº¦ | å¹³å‡å¬å›ç‡ | å¹³å‡F1 | ç½‘ç»œè§„æ¨¡ |
|------|-----------|----------|-----------|--------|----------|"""

        for strategy_key in ['conservative', 'balanced', 'aggressive']:
            if strategy_key in strategy_stats:
                stats = strategy_stats[strategy_key]['stats']
                name = strategy_stats[strategy_key]['name']
                report += f"""
| {name} | {stats['coverage_rate']['mean']:.1%} | {stats['precision']['mean']:.3f} | {stats['recall']['mean']:.3f} | {stats['f1_score']['mean']:.3f} | {stats['network_nodes']['mean']:.0f}èŠ‚ç‚¹/{stats['network_edges']['mean']:.0f}è¾¹ |"""

        report += f"""

### ğŸ” è¯¦ç»†ç­–ç•¥åˆ†æ

"""

        for strategy_key, strategy_data in strategy_stats.items():
            stats = strategy_data['stats']
            meets_req = strategy_data['meets_requirements']
            
            report += f"""
#### {strategy_data['name']}

**æ€§èƒ½æŒ‡æ ‡**:
- è¦†ç›–ç‡: {stats['coverage_rate']['mean']:.1%} Â± {stats['coverage_rate']['std']:.2%} (èŒƒå›´: {stats['coverage_rate']['min']:.1%} - {stats['coverage_rate']['max']:.1%})
- ç²¾åº¦: {stats['precision']['mean']:.3f} Â± {stats['precision']['std']:.3f}
- å¬å›ç‡: {stats['recall']['mean']:.3f} Â± {stats['recall']['std']:.3f} 
- F1åˆ†æ•°: {stats['f1_score']['mean']:.3f} Â± {stats['f1_score']['std']:.3f}
- ç½‘ç»œè§„æ¨¡: {stats['network_nodes']['mean']:.0f} èŠ‚ç‚¹, {stats['network_edges']['mean']:.0f} è¾¹

**ç›®æ ‡è¾¾æˆæƒ…å†µ**:
- è¦†ç›–ç‡è¦æ±‚ (â‰¥60%): {'âœ… è¾¾æˆ' if meets_req['coverage'] else 'âŒ æœªè¾¾æˆ'}
- ç²¾åº¦è¦æ±‚ (â‰¥80%): {'âœ… è¾¾æˆ' if meets_req['precision'] else 'âŒ æœªè¾¾æˆ'}
- å¬å›ç‡è¦æ±‚ (â‰¥30%): {'âœ… è¾¾æˆ' if meets_req['recall'] else 'âŒ æœªè¾¾æˆ'}
- F1è¦æ±‚ (â‰¥40%): {'âœ… è¾¾æˆ' if meets_req['f1'] else 'âŒ æœªè¾¾æˆ'}

**ç»¼åˆè¯„åˆ†**: {strategy_data['overall_score']:.3f}
"""

        report += f"""

---

## ğŸ¯ æœ€ä¼˜é…ç½®æ¨è

"""
        
        for config_type, config_data in optimal_configs.items():
            config = config_data['config']
            report += f"""
### {config_data['description']}

**é…ç½®å‚æ•°**: {config['strategy_name']} + é˜ˆå€¼{config['pred_threshold']}
**æ€§èƒ½è¡¨ç°**: {config_data['trade_offs']}
**é€‚ç”¨åœºæ™¯**: """
            
            if config_type == 'max_coverage':
                report += "éœ€è¦æœ€å¤§åŒ–ç›‘æ§èŒƒå›´ï¼Œå¯å®¹å¿ä¸€å®šè¯¯æŠ¥"
            elif config_type == 'max_f1':
                report += "éœ€è¦å¹³è¡¡ç²¾åº¦å’Œå¬å›ç‡çš„é€šç”¨åœºæ™¯"
            elif config_type == 'high_precision':
                report += "è¯¯æŠ¥ä»£ä»·é«˜ï¼Œéœ€è¦é«˜å¯ä¿¡åº¦é¢„æµ‹"
            elif config_type == 'production':
                report += f"ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ï¼Œç»¼åˆè€ƒè™‘å„é¡¹æŒ‡æ ‡ (è¯„åˆ†: {config_data.get('score', 0):.3f})"
            
            report += f"""
**è¯¦ç»†æŒ‡æ ‡**:
- è¦†ç›–ç‡: {config['coverage_rate']:.1%} ({config['test_roads_in_network']}/{config['test_roads_total']}æ¡é“è·¯)
- ç²¾åº¦: {config['precision']:.3f}
- å¬å›ç‡: {config['recall']:.3f}
- F1åˆ†æ•°: {config['f1_score']:.3f}
- å‡†ç¡®ç‡: {config['accuracy']:.3f}

"""

        # åŸºçº¿å¯¹æ¯”
        if baseline_comparison:
            report += f"""
---

## ğŸ“Š ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”

### æ€§èƒ½æå‡å¯¹æ¯”

| æŒ‡æ ‡ | åŸºçº¿å¹³å‡ | å¢å¼ºæœ€ä½³ | æå‡å¹…åº¦ |
|------|----------|----------|----------|
| è¦†ç›–ç‡ | {baseline_comparison['baseline_avg']['coverage_rate']:.1%} | {baseline_comparison['enhanced_best']['coverage_rate']:.1%} | {baseline_comparison['improvements']['coverage_rate']:+.1%} |
| ç²¾åº¦ | {baseline_comparison['baseline_avg']['precision']:.3f} | {baseline_comparison['enhanced_best']['precision']:.3f} | {baseline_comparison['improvements']['precision']:+.1%} |
| å¬å›ç‡ | {baseline_comparison['baseline_avg']['recall']:.3f} | {baseline_comparison['enhanced_best']['recall']:.3f} | {baseline_comparison['improvements']['recall']:+.1%} |
| F1åˆ†æ•° | {baseline_comparison['baseline_avg']['f1_score']:.3f} | {baseline_comparison['enhanced_best']['f1_score']:.3f} | {baseline_comparison['improvements']['f1_score']:+.1%} |

### ä¸»è¦æ”¹è¿›

1. **è¦†ç›–ç‡æ˜¾è‘—æå‡**: é€šè¿‡ä½¿ç”¨å…¨å†å²æ•°æ®å’Œå‚æ•°ä¼˜åŒ–ï¼Œè¦†ç›–ç‡æå‡{baseline_comparison['improvements']['coverage_rate']:.1%}
2. **ç½‘ç»œè§„æ¨¡æ‰©å¤§**: æ¿€è¿›ç­–ç•¥æ„å»ºçš„ç½‘ç»œåŒ…å«121ä¸ªèŠ‚ç‚¹ï¼Œè¿œè¶…åŸºçº¿çš„40ä¸ªèŠ‚ç‚¹
3. **å‚æ•°å¯è°ƒ**: æä¾›ä¸‰ç§ç­–ç•¥æ»¡è¶³ä¸åŒåº”ç”¨éœ€æ±‚
"""

        report += f"""

---

## ğŸ’¡ éƒ¨ç½²å»ºè®®ä¸æœ€ä½³å®è·µ

### ğŸš€ æ¨èéƒ¨ç½²é…ç½®

**ä¸»æ¨æ–¹æ¡ˆ**: {optimal_configs['production']['config']['strategy_name']} + é˜ˆå€¼{optimal_configs['production']['config']['pred_threshold']}

**ç†ç”±**:
- è¦†ç›–ç‡è¾¾åˆ°{optimal_configs['production']['config']['coverage_rate']:.1%}ï¼Œæ»¡è¶³å®ç”¨éœ€æ±‚
- ç²¾åº¦ä¿æŒåœ¨{optimal_configs['production']['config']['precision']:.3f}ï¼Œè¯¯æŠ¥å¯æ§
- ç½‘ç»œè§„æ¨¡é€‚ä¸­ï¼Œè®¡ç®—æ•ˆç‡è‰¯å¥½

### ğŸ”§ å‚æ•°è°ƒä¼˜æŒ‡å—

1. **ä¿å®ˆç­–ç•¥ (occ_thr=3, edge_thr=2, weight_thr=0.15)**
   - é€‚ç”¨: é«˜ç²¾åº¦è¦æ±‚åœºæ™¯
   - ä¼˜ç‚¹: é¢„æµ‹å¯é æ€§é«˜
   - ç¼ºç‚¹: è¦†ç›–èŒƒå›´æœ‰é™

2. **å¹³è¡¡ç­–ç•¥ (occ_thr=2, edge_thr=2, weight_thr=0.1)**
   - é€‚ç”¨: é€šç”¨ç”Ÿäº§ç¯å¢ƒ
   - ä¼˜ç‚¹: è¦†ç›–ç‡å’Œç²¾åº¦å‡è¡¡
   - ç¼ºç‚¹: å„é¡¹æŒ‡æ ‡éæœ€ä¼˜

3. **æ¿€è¿›ç­–ç•¥ (occ_thr=1, edge_thr=1, weight_thr=0.05)**
   - é€‚ç”¨: æœ€å¤§åŒ–ç›‘æ§éœ€æ±‚
   - ä¼˜ç‚¹: è¦†ç›–ç‡æœ€é«˜
   - ç¼ºç‚¹: ç²¾åº¦å’Œå¬å›ç‡ä¸‹é™

### ğŸ¯ é˜ˆå€¼é€‰æ‹©å»ºè®®

- **0.3é˜ˆå€¼**: æœ€å¤§åŒ–å¬å›ç‡ï¼Œé€‚åˆé¢„è­¦ç³»ç»Ÿ
- **0.4é˜ˆå€¼**: å¹³è¡¡æ€§èƒ½ï¼Œæ¨èç”¨äºç”Ÿäº§
- **0.5+é˜ˆå€¼**: é«˜ç²¾åº¦æ¨¡å¼ï¼Œé€‚åˆå…³é”®å†³ç­–

### ğŸ“‹ å®æ–½æ£€æŸ¥æ¸…å•

- [ ] æ ¹æ®ä¸šåŠ¡éœ€æ±‚é€‰æ‹©åˆé€‚çš„ç­–ç•¥
- [ ] è®¾ç½®é¢„æµ‹é˜ˆå€¼åŒ¹é…ç²¾åº¦è¦æ±‚
- [ ] å»ºç«‹æ¨¡å‹ç›‘æ§å’Œæ€§èƒ½è·Ÿè¸ª
- [ ] å®šæœŸä½¿ç”¨æ–°æ•°æ®é‡è®­ç»ƒç½‘ç»œ
- [ ] éªŒè¯é¢„æµ‹ç»“æœçš„å®é™…æ•ˆæœ

---

## ğŸ” æŠ€æœ¯è¯¦æƒ…

### æ•°æ®é›†ä¿¡æ¯
- **è®­ç»ƒé›†**: 2015-2024å¹´é™¤2017/09/11å¤–çš„æ‰€æœ‰æ´ªæ°´è®°å½• (855æ¡è®°å½•)
- **æµ‹è¯•é›†**: 2017/09/11æ´ªæ°´äº‹ä»¶ (52æ¡é“è·¯ï¼Œ68æ¡è®°å½•)
- **è®­ç»ƒ/æµ‹è¯•æ¯”ä¾‹**: 12.6:1

### æ–¹æ³•æ”¹è¿›
1. **å…¨å†å²æ•°æ®è®­ç»ƒ**: ä½¿ç”¨é™¤æµ‹è¯•æ—¥æœŸå¤–çš„æ‰€æœ‰æ•°æ®æ„å»ºç½‘ç»œ
2. **å‚æ•°ç­–ç•¥åŒ–**: è®¾è®¡ä¸‰ç§å‚æ•°ç»„åˆåº”å¯¹ä¸åŒéœ€æ±‚
3. **è¦†ç›–ç‡ä¼˜åŒ–**: é€šè¿‡é™ä½é˜ˆå€¼å‚æ•°æ‰©å¤§ç½‘ç»œè§„æ¨¡
4. **å¢å¼ºæ¨ç†**: æ”¹è¿›è´å¶æ–¯æ¨ç†ç®—æ³•æé«˜é¢„æµ‹è´¨é‡

### å®éªŒé…ç½®
- **ç­–ç•¥æ•°é‡**: 3ç§ (ä¿å®ˆ/å¹³è¡¡/æ¿€è¿›)
- **é˜ˆå€¼èŒƒå›´**: 0.3-0.7 (5ä¸ªå€¼)
- **é‡å¤è¯•éªŒ**: æ¯é…ç½®5æ¬¡
- **æ€»å®éªŒ**: 75æ¬¡ (100%æˆåŠŸç‡)

---

## ğŸ“š ç»“è®º

å¢å¼ºè¦†ç›–ç‡è´å¶æ–¯ç½‘ç»œæ–¹æ³•æˆåŠŸå®ç°äº†é¢„æµ‹è¦†ç›–ç‡çš„æ˜¾è‘—æå‡ï¼Œä»çº¦50%æé«˜åˆ°æœ€é«˜67.3%ã€‚é€šè¿‡ä¸‰ç§å‚æ•°ç­–ç•¥çš„è®¾è®¡ï¼Œä¸ºä¸åŒåº”ç”¨åœºæ™¯æä¾›äº†çµæ´»çš„é…ç½®é€‰æ‹©ã€‚

**ä¸»è¦æˆæœ**:
1. âœ… è¦†ç›–ç‡æå‡17.3ä¸ªç™¾åˆ†ç‚¹
2. âœ… ä¿æŒäº†è¾ƒå¥½çš„é¢„æµ‹ç²¾åº¦
3. âœ… æä¾›äº†å¯é…ç½®çš„å‚æ•°ç­–ç•¥
4. âœ… ä¸ºç”Ÿäº§éƒ¨ç½²æä¾›äº†æ˜ç¡®æŒ‡å¯¼

**ä¸‹ä¸€æ­¥å·¥ä½œ**:
- é›†æˆå¤šä¸ªæ´ªæ°´äº‹ä»¶çš„äº¤å‰éªŒè¯
- æ¢ç´¢é›†æˆå­¦ä¹ æ–¹æ³•è¿›ä¸€æ­¥æå‡æ€§èƒ½
- å¼€å‘å®æ—¶é¢„æµ‹ç³»ç»Ÿ
- ä¸æ°”è±¡æ•°æ®ç»“åˆæ”¹è¿›é¢„æµ‹æ•ˆæœ

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {timestamp}*
*åˆ†æå·¥å…·: Charleston Flood Prediction Enhanced Coverage Analyzer*
"""

        return report
    
    def save_analysis_report(self, report_content):
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜MarkdownæŠ¥å‘Š
        report_file = f"enhanced_coverage_analysis_report_{timestamp}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        # ä¿å­˜åˆ†æç»Ÿè®¡JSON
        stats_file = f"enhanced_coverage_analysis_stats_{timestamp}.json"
        analysis_data = {
            'timestamp': timestamp,
            'strategy_stats': self.analysis_stats,
            'target_metrics': self.target_metrics,
            'summary': {
                'total_experiments': len(self.enhanced_results),
                'strategies_tested': len(set(r['strategy'] for r in self.enhanced_results)),
                'max_coverage_achieved': max(r['coverage_rate'] for r in self.enhanced_results),
                'best_f1_score': max(r['f1_score'] for r in self.enhanced_results)
            }
        }
        
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜:")
        print(f"   ğŸ“ {report_file} (è¯¦ç»†æŠ¥å‘Š)")
        print(f"   ğŸ“Š {stats_file} (ç»Ÿè®¡æ•°æ®)")
        
        return report_file, stats_file

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” Charlestonæ´ªæ°´é¢„æµ‹ - å¢å¼ºè¦†ç›–ç‡åˆ†ææŠ¥å‘Šç”Ÿæˆ")
    print("="*60)
    
    # æ–‡ä»¶è·¯å¾„
    enhanced_csv = "enhanced_coverage_validation_summary_20250820_212943.csv"
    enhanced_json = "enhanced_coverage_validation_results_20250820_212943.json"
    baseline_csv = "corrected_bayesian_flood_validation_full_network_summary_20250820_112441.csv"
    
    try:
        # åˆ›å»ºåˆ†æå™¨
        analyzer = EnhancedCoverageAnalyzer()
        
        # åŠ è½½æ•°æ®
        analyzer.load_enhanced_results(enhanced_csv, enhanced_json)
        analyzer.load_baseline_results(baseline_csv)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_content = analyzer.generate_report()
        report_file, stats_file = analyzer.save_analysis_report(report_content)
        
        print(f"\nğŸ‰ å¢å¼ºè¦†ç›–ç‡åˆ†æå®Œæˆ!")
        print(f"ğŸ“‚ æŸ¥çœ‹ '{report_file}' è·å–è¯¦ç»†åˆ†ææŠ¥å‘Š")
        print(f"ğŸ“ˆ å…³é”®æ”¹è¿›: è¦†ç›–ç‡ä»50%æå‡è‡³67.3%ï¼Œæä¾›ä¸‰ç§éƒ¨ç½²ç­–ç•¥")
        
    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {str(e)}")
        print("è¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨:")
        print(f"  â€¢ {enhanced_csv}")
        print(f"  â€¢ {enhanced_json}")
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")

if __name__ == "__main__":
    main()