import pandas as pd
import numpy as np
from model import FloodBayesNetwork
from sklearn.model_selection import train_test_split
import random
from collections import Counter

# è®¾ç½®éšæœºç§å­
random.seed(0)
np.random.seed(0)

def analyze_road_frequency():
    """åˆ†æžé“è·¯é¢‘æ¬¡åˆ†å¸ƒæ¥æŒ‡å¯¼å‚æ•°è®¾ç½®"""
    df = pd.read_csv("Road_Closures_2024.csv")
    df = df[df["REASON"].str.upper() == "FLOOD"].copy()
    df["link_id"] = df["STREET"].str.upper().str.replace(" ", "_")
    
    train_df, _ = train_test_split(df, test_size=0.3, random_state=42)
    
    # ç»Ÿè®¡é“è·¯é¢‘æ¬¡
    road_counts = Counter(train_df['link_id'])
    freq_dist = Counter(road_counts.values())
    
    print("é“è·¯é¢‘æ¬¡åˆ†å¸ƒåˆ†æž:")
    print("é¢‘æ¬¡\té“è·¯æ•°\tç´¯è®¡é“è·¯æ•°")
    cumulative = 0
    for freq in sorted(freq_dist.keys(), reverse=True):
        cumulative += freq_dist[freq]
        print(f"{freq}\t{freq_dist[freq]}\t{cumulative}")
    
    # æŽ¨èocc_thrè®¾ç½®
    print(f"\næŽ¨èå‚æ•°è®¾ç½®:")
    for target_nodes in [10, 15, 20, 25, 30]:
        for threshold in sorted(road_counts.values(), reverse=True):
            retained = sum(1 for count in road_counts.values() if count >= threshold)
            if retained <= target_nodes:
                print(f"ç›®æ ‡{target_nodes}èŠ‚ç‚¹: occ_thr >= {threshold}")
                break
    
    return road_counts

def test_targeted_parameters(road_counts):
    """åŸºäºŽé“è·¯é¢‘æ¬¡åˆ†æžæµ‹è¯•æ›´ç²¾ç¡®çš„å‚æ•°ç»„åˆ"""
    df = pd.read_csv("Road_Closures_2024.csv")
    df = df[df["REASON"].str.upper() == "FLOOD"].copy()
    df["time_create"] = pd.to_datetime(df["START"], utc=True)
    df["link_id"] = df["STREET"].str.upper().str.replace(" ", "_")
    df["link_id"] = df["link_id"].astype(str)
    df["id"] = df["OBJECTID"].astype(str)
    
    train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)
    
    # åŸºäºŽé¢‘æ¬¡åˆ†æžè®¾è®¡å‚æ•°ç»„åˆ
    strategies = {
        "high_freq_conservative": {
            "occ_thr": 15,  # åªä¿ç•™é«˜é¢‘é“è·¯
            "edge_thr": 5,
            "weight_thr": 0.6,
            "description": "é«˜é¢‘ä¿å®ˆç­–ç•¥ - åªä¿ç•™æœ€é¢‘ç¹å‡ºçŽ°çš„é“è·¯"
        },
        "high_freq_moderate": {
            "occ_thr": 10,
            "edge_thr": 4,
            "weight_thr": 0.5,
            "description": "é«˜é¢‘ä¸­ç­‰ç­–ç•¥ - ä¿ç•™è¾ƒé¢‘ç¹çš„é“è·¯"
        },
        "medium_freq_conservative": {
            "occ_thr": 7,
            "edge_thr": 4,
            "weight_thr": 0.5,
            "description": "ä¸­é¢‘ä¿å®ˆç­–ç•¥ - å¹³è¡¡é¢‘æ¬¡å’Œç½‘ç»œå¤§å°"
        },
        "medium_freq_moderate": {
            "occ_thr": 5,
            "edge_thr": 3,
            "weight_thr": 0.4,
            "description": "ä¸­é¢‘ä¸­ç­‰ç­–ç•¥"
        },
        "targeted_optimal": {
            "occ_thr": 8,  # åŸºäºŽåˆ†æžè°ƒæ•´
            "edge_thr": 3,
            "weight_thr": 0.45,
            "description": "ç›®æ ‡ä¼˜åŒ–ç­–ç•¥ - é’ˆå¯¹10-30èŠ‚ç‚¹è®¾è®¡"
        }
    }
    
    results = {}
    
    for name, params in strategies.items():
        print(f"\n=== æµ‹è¯• {name} ===")
        print(f"å‚æ•°: occ_thr={params['occ_thr']}, edge_thr={params['edge_thr']}, weight_thr={params['weight_thr']}")
        
        try:
            # é¢„ä¼°èŠ‚ç‚¹æ•°
            estimated_nodes = sum(1 for count in road_counts.values() if count >= params['occ_thr'])
            print(f"é¢„ä¼°èŠ‚ç‚¹æ•°: {estimated_nodes}")
            
            if estimated_nodes < 5:
                print("âš ï¸ é¢„ä¼°èŠ‚ç‚¹æ•°å¤ªå°‘ï¼Œè·³è¿‡")
                results[name] = {"success": False, "error": "too_few_nodes", "estimated_nodes": estimated_nodes}
                continue
            
            # åˆ›å»ºç½‘ç»œ
            flood_net = FloodBayesNetwork(t_window="D")
            flood_net.fit_marginal(train_df)
            
            flood_net.build_network_by_co_occurrence(
                train_df,
                occ_thr=params["occ_thr"],
                edge_thr=params["edge_thr"],
                weight_thr=params["weight_thr"],
                report=False
            )
            
            # ç½‘ç»œç»Ÿè®¡
            n_nodes = flood_net.network.number_of_nodes()
            n_edges = flood_net.network.number_of_edges()
            
            if n_nodes == 0:
                print("âŒ ç½‘ç»œä¸ºç©º")
                results[name] = {"success": False, "error": "empty_network"}
                continue
            
            # åº¦åˆ†å¸ƒ
            degrees = dict(flood_net.network.degree())
            in_degrees = dict(flood_net.network.in_degree())
            out_degrees = dict(flood_net.network.out_degree())
            
            # è¾¹æƒé‡ç»Ÿè®¡
            if n_edges > 0:
                weights = [flood_net.network[u][v]['weight'] for u, v in flood_net.network.edges()]
                weight_stats = {
                    "mean": np.mean(weights),
                    "std": np.std(weights),
                    "min": np.min(weights),
                    "max": np.max(weights),
                    "median": np.median(weights)
                }
            else:
                weight_stats = {"mean": 0, "std": 0, "min": 0, "max": 0, "median": 0}
            
            # è®¡ç®—ç½‘ç»œå¯†åº¦å’Œè¿žé€šæ€§
            max_edges = n_nodes * (n_nodes - 1)
            density = n_edges / max_edges if max_edges > 0 else 0
            
            # å­¤ç«‹èŠ‚ç‚¹
            isolated_nodes = sum(1 for node in flood_net.network.nodes() if degrees[node] == 0)
            
            results[name] = {
                "success": True,
                "params": params,
                "nodes": n_nodes,
                "edges": n_edges,
                "density": density,
                "avg_degree": np.mean(list(degrees.values())),
                "max_degree": max(degrees.values()) if degrees else 0,
                "isolated_nodes": isolated_nodes,
                "weight_stats": weight_stats,
                "in_target_range": 10 <= n_nodes <= 30
            }
            
            print(f"âœ… æˆåŠŸ: {n_nodes}èŠ‚ç‚¹, {n_edges}è¾¹")
            print(f"   å¯†åº¦: {density:.4f}, å¹³å‡åº¦: {np.mean(list(degrees.values())):.2f}")
            print(f"   æƒé‡: {weight_stats['mean']:.3f}Â±{weight_stats['std']:.3f}")
            print(f"   åœ¨ç›®æ ‡èŒƒå›´å†…: {'æ˜¯' if 10 <= n_nodes <= 30 else 'å¦'}")
            
        except Exception as e:
            print(f"âŒ å¤±è´¥: {e}")
            results[name] = {"success": False, "error": str(e)}
    
    return results

def generate_optimization_report(results):
    """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
    print("\n" + "="*80)
    print("ç›®æ ‡åŒ–å‚æ•°ä¼˜åŒ–æŠ¥å‘Š")
    print("="*80)
    
    # æˆåŠŸçš„ç­–ç•¥
    successful = {k: v for k, v in results.items() if v.get("success", False)}
    
    if not successful:
        print("âŒ æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥äº†")
        return
    
    print("\nã€æˆåŠŸç­–ç•¥æ¦‚è§ˆã€‘")
    for name, result in successful.items():
        in_range = "âœ…" if result["in_target_range"] else "âŒ"
        print(f"{name:25s}: {result['nodes']:2d}èŠ‚ç‚¹, {result['edges']:2d}è¾¹, "
              f"å¯†åº¦={result['density']:.4f} {in_range}")
    
    # ç­›é€‰ç›®æ ‡èŒƒå›´å†…çš„ç­–ç•¥
    target_strategies = {k: v for k, v in successful.items() if v["in_target_range"]}
    
    if target_strategies:
        print(f"\nã€ç›®æ ‡èŒƒå›´å†…ç­–ç•¥(10-30èŠ‚ç‚¹)ã€‘")
        
        # æŒ‰ä¸åŒæŒ‡æ ‡æŽ’åº
        best_balanced = min(target_strategies.keys(), 
                           key=lambda x: abs(target_strategies[x]["nodes"] - 20))
        best_connected = max(target_strategies.keys(), 
                            key=lambda x: target_strategies[x]["edges"])
        best_quality = max(target_strategies.keys(), 
                          key=lambda x: target_strategies[x]["weight_stats"]["mean"])
        
        print(f"ðŸŽ¯ æœ€å¹³è¡¡ç­–ç•¥: {best_balanced}")
        result = target_strategies[best_balanced]
        print(f"   - ç½‘ç»œè§„æ¨¡: {result['nodes']}èŠ‚ç‚¹, {result['edges']}è¾¹")
        print(f"   - å‚æ•°: occ_thr={result['params']['occ_thr']}, "
              f"edge_thr={result['params']['edge_thr']}, "
              f"weight_thr={result['params']['weight_thr']}")
        
        if best_connected != best_balanced:
            print(f"ðŸ”— æœ€å¤šè¿žæŽ¥ç­–ç•¥: {best_connected} ({target_strategies[best_connected]['edges']}è¾¹)")
        
        if best_quality != best_balanced:
            print(f"â­ æœ€é«˜æƒé‡ç­–ç•¥: {best_quality} "
                  f"(æƒé‡å‡å€¼={target_strategies[best_quality]['weight_stats']['mean']:.3f})")
        
        # æŽ¨èè®¾ç½®
        recommended = target_strategies[best_balanced]
        print(f"\nã€æŽ¨èå‚æ•°è®¾ç½®ã€‘")
        print(f"occ_thr = {recommended['params']['occ_thr']}")
        print(f"edge_thr = {recommended['params']['edge_thr']}")
        print(f"weight_thr = {recommended['params']['weight_thr']}")
        print(f"max_parents = 2  # ä¿æŒä¸å˜")
        
    else:
        print(f"\nâš ï¸ æ²¡æœ‰ç­–ç•¥åœ¨ç›®æ ‡èŒƒå›´å†…ï¼Œæœ€æŽ¥è¿‘çš„ç­–ç•¥:")
        closest = min(successful.keys(), 
                     key=lambda x: abs(successful[x]["nodes"] - 20))
        result = successful[closest]
        print(f"   {closest}: {result['nodes']}èŠ‚ç‚¹")
        print(f"   å»ºè®®è¿›ä¸€æ­¥è°ƒæ•´occ_thrå‚æ•°")

def main():
    print("å¼€å§‹ç›®æ ‡åŒ–å‚æ•°ä¼˜åŒ–...")
    
    # åˆ†æžé“è·¯é¢‘æ¬¡
    road_counts = analyze_road_frequency()
    
    # æµ‹è¯•ç›®æ ‡å‚æ•°
    results = test_targeted_parameters(road_counts)
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_optimization_report(results)
    
    return results

if __name__ == "__main__":
    main()