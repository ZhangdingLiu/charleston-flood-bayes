#!/usr/bin/env python3
"""
åŸºäºè®­ç»ƒé›†çš„é“è·¯å…±ç°åˆ†æ

åŠŸèƒ½ï¼š
1. ä¸¥æ ¼åŸºäºè®­ç»ƒé›†æ•°æ®è®¡ç®—é“è·¯å…±ç°ç»Ÿè®¡
2. é¿å…æ•°æ®æ³„éœ²ï¼Œç¡®ä¿è®­ç»ƒ-æµ‹è¯•åˆ†ç¦»
3. è®¡ç®—æ¡ä»¶æ¦‚ç‡confA2Bï¼Œé€‰æ‹©æœ€å¼ºå…³è”çš„é“è·¯å¯¹
4. ä¸ºåŸºäºè®­ç»ƒé›†çš„è´å¶æ–¯ç½‘ç»œæ„å»ºæä¾›ç»Ÿè®¡åŸºç¡€

åˆ†ææŒ‡æ ‡ï¼š
- countA: é“è·¯Açš„æ´ªæ°´æ¬¡æ•°
- countB: é“è·¯Bçš„æ´ªæ°´æ¬¡æ•°  
- countAB: é“è·¯Aå’ŒBåŒæ—¶æ´ªæ°´çš„æ¬¡æ•°
- confA2B: P(Bæ´ªæ°´|Aæ´ªæ°´) = countAB / countA
- confB2A: P(Aæ´ªæ°´|Bæ´ªæ°´) = countAB / countB

é€‰æ‹©ç­–ç•¥ï¼š
é€‰æ‹©confA2Bæœ€é«˜çš„å‰3å¯¹é“è·¯ï¼Œæ„å»ºAâ†’Bçš„æœ‰å‘è¾¹

ç”¨æ³•ï¼š
    python train_cooccurrence_analysis.py

è¾“å‡ºï¼š
    - results/train_cooccurrence_stats.csv - è®­ç»ƒé›†å…±ç°ç»Ÿè®¡è¡¨
    - figs/train_cooccurrence_heatmap.png - è®­ç»ƒé›†å…±ç°çƒ­å›¾
    - ç»ˆç«¯è¾“å‡ºæœ€å¼ºå…³è”çš„é“è·¯å¯¹åˆ†æ
"""

import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict, Counter
from sklearn.model_selection import train_test_split
from itertools import combinations

# è®¾ç½®éšæœºç§å­ï¼ˆä¸å…¶ä»–è„šæœ¬ä¿æŒä¸€è‡´ï¼‰
RANDOM_SEED = 42

class TrainCooccurrenceAnalyzer:
    """åŸºäºè®­ç»ƒé›†çš„é“è·¯å…±ç°åˆ†æå™¨"""
    
    def __init__(self, 
                 data_csv_path="Road_Closures_2024.csv",
                 results_dir="results",
                 figs_dir="figs",
                 min_road_count=3):
        self.data_csv_path = data_csv_path
        self.results_dir = results_dir
        self.figs_dir = figs_dir
        self.min_road_count = min_road_count  # æœ€å°é“è·¯å‡ºç°æ¬¡æ•°é˜ˆå€¼
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(results_dir, exist_ok=True)
        os.makedirs(figs_dir, exist_ok=True)
        
        # æ•°æ®å­˜å‚¨
        self.train_df = None
        self.test_df = None
        self.road_stats = {}
        self.cooccurrence_stats = []
        
    def load_and_split_data(self):
        """åŠ è½½æ•°æ®å¹¶åˆ†å‰²ï¼ˆä¸å…¶ä»–è„šæœ¬ä¿æŒä¸€è‡´çš„åˆ†å‰²ï¼‰"""
        print("1. åŠ è½½å’Œåˆ†å‰²æ•°æ®...")
        
        # åŠ è½½æ•°æ®
        df = pd.read_csv(self.data_csv_path)
        df = df[df["REASON"].str.upper() == "FLOOD"].copy()
        
        # æ•°æ®é¢„å¤„ç†
        df["time_create"] = pd.to_datetime(df["START"], utc=True)
        df["road"] = df["STREET"].str.upper().str.strip()
        df["date"] = df["time_create"].dt.floor("D")
        df["id"] = df["OBJECTID"].astype(str)
        
        # ä½¿ç”¨ç›¸åŒçš„éšæœºç§å­åˆ†å‰²
        self.train_df, self.test_df = train_test_split(
            df, test_size=0.3, random_state=RANDOM_SEED
        )
        
        print(f"   æ€»æ´ªæ°´è®°å½•: {len(df)}æ¡")
        print(f"   è®­ç»ƒé›†: {len(self.train_df)}æ¡")
        print(f"   æµ‹è¯•é›†: {len(self.test_df)}æ¡")
        
        return self.train_df, self.test_df
        
    def analyze_road_frequencies(self):
        """åˆ†æè®­ç»ƒé›†ä¸­å„é“è·¯çš„æ´ªæ°´é¢‘ç‡"""
        print("2. åˆ†æè®­ç»ƒé›†é“è·¯é¢‘ç‡...")
        
        # ç»Ÿè®¡æ¯æ¡é“è·¯çš„å‡ºç°æ¬¡æ•°
        road_counts = Counter(self.train_df['road'])
        
        # è¿‡æ»¤æ‰å‡ºç°æ¬¡æ•°è¿‡å°‘çš„é“è·¯
        filtered_roads = {road: count for road, count in road_counts.items() 
                         if count >= self.min_road_count}
        
        print(f"   è®­ç»ƒé›†ä¸­ç‹¬ç‰¹é“è·¯æ•°: {len(road_counts)}")
        print(f"   å‡ºç°â‰¥{self.min_road_count}æ¬¡çš„é“è·¯æ•°: {len(filtered_roads)}")
        
        # æ˜¾ç¤ºå‰20ä¸ªæœ€é¢‘ç¹çš„é“è·¯
        print(f"   å‰20ä¸ªæœ€é¢‘ç¹æ´ªæ°´é“è·¯:")
        for road, count in sorted(filtered_roads.items(), 
                                key=lambda x: x[1], reverse=True)[:20]:
            print(f"     {road}: {count}æ¬¡")
        
        self.road_stats = filtered_roads
        return filtered_roads
        
    def compute_cooccurrence_matrix(self):
        """è®¡ç®—è®­ç»ƒé›†ä¸­é“è·¯çš„å…±ç°çŸ©é˜µ"""
        print("3. è®¡ç®—é“è·¯å…±ç°çŸ©é˜µ...")
        
        # æŒ‰æ—¥æœŸåˆ†ç»„ï¼Œè·å–æ¯å¤©æ´ªæ°´çš„é“è·¯é›†åˆ
        daily_roads = defaultdict(set)
        for _, row in self.train_df.iterrows():
            road = row['road']
            if road in self.road_stats:  # åªè€ƒè™‘é¢‘ç¹é“è·¯
                date_str = str(row['date'].date())
                daily_roads[date_str].add(road)
        
        print(f"   åˆ†æå¤©æ•°: {len(daily_roads)}å¤©")
        
        # è®¡ç®—æ‰€æœ‰é“è·¯å¯¹çš„å…±ç°ç»Ÿè®¡
        road_list = list(self.road_stats.keys())
        cooccurrence_data = []
        
        for i, road_a in enumerate(road_list):
            for j, road_b in enumerate(road_list):
                if i >= j:  # é¿å…é‡å¤è®¡ç®—å’Œè‡ªç¯
                    continue
                    
                count_a = self.road_stats[road_a]
                count_b = self.road_stats[road_b]
                
                # è®¡ç®—å…±ç°æ¬¡æ•°
                count_ab = 0
                for date, roads_set in daily_roads.items():
                    if road_a in roads_set and road_b in roads_set:
                        count_ab += 1
                
                # è®¡ç®—æ¡ä»¶æ¦‚ç‡
                conf_a2b = count_ab / count_a if count_a > 0 else 0
                conf_b2a = count_ab / count_b if count_b > 0 else 0
                
                # åªä¿å­˜æœ‰å…±ç°çš„é“è·¯å¯¹
                if count_ab > 0:
                    cooccurrence_data.append({
                        'road_a': road_a,
                        'road_b': road_b,
                        'count_a': count_a,
                        'count_b': count_b,
                        'count_ab': count_ab,
                        'conf_a2b': conf_a2b,
                        'conf_b2a': conf_b2a,
                        'max_conf': max(conf_a2b, conf_b2a)
                    })
        
        print(f"   æ‰¾åˆ°å…±ç°é“è·¯å¯¹: {len(cooccurrence_data)}å¯¹")
        
        self.cooccurrence_stats = cooccurrence_data
        return cooccurrence_data
        
    def select_top_road_pairs(self, top_k=10):
        """é€‰æ‹©æ¡ä»¶æ¦‚ç‡æœ€é«˜çš„é“è·¯å¯¹"""
        print("4. é€‰æ‹©æœ€å¼ºå…³è”é“è·¯å¯¹...")
        
        if not self.cooccurrence_stats:
            print("   âŒ æ²¡æœ‰å…±ç°ç»Ÿè®¡æ•°æ®")
            return []
        
        # æŒ‰æœ€å¤§æ¡ä»¶æ¦‚ç‡æ’åº
        sorted_pairs = sorted(self.cooccurrence_stats, 
                            key=lambda x: x['max_conf'], reverse=True)
        
        top_pairs = sorted_pairs[:top_k]
        
        print(f"   Top-{top_k} é“è·¯å¯¹ (æŒ‰æ¡ä»¶æ¦‚ç‡):")
        print(f"   {'é“è·¯A':<20} {'é“è·¯B':<20} {'countA':<8} {'countB':<8} {'countAB':<9} {'confA2B':<8} {'confB2A':<8}")
        print("-" * 100)
        
        for pair in top_pairs:
            print(f"   {pair['road_a']:<20} {pair['road_b']:<20} "
                  f"{pair['count_a']:<8} {pair['count_b']:<8} "
                  f"{pair['count_ab']:<9} {pair['conf_a2b']:<8.4f} {pair['conf_b2a']:<8.4f}")
        
        return top_pairs
        
    def create_cooccurrence_heatmap(self, top_pairs):
        """åˆ›å»ºå…±ç°å…³ç³»çƒ­å›¾"""
        print("5. ç”Ÿæˆå…±ç°å…³ç³»çƒ­å›¾...")
        
        if len(top_pairs) < 3:
            print("   âš ï¸  é“è·¯å¯¹æ•°é‡ä¸è¶³ï¼Œè·³è¿‡çƒ­å›¾ç”Ÿæˆ")
            return None
        
        # é€‰æ‹©å‰15å¯¹ç”¨äºå¯è§†åŒ–
        viz_pairs = top_pairs[:15]
        
        # è·å–æ‰€æœ‰æ¶‰åŠçš„é“è·¯
        all_roads = set()
        for pair in viz_pairs:
            all_roads.add(pair['road_a'])
            all_roads.add(pair['road_b'])
        
        road_list = sorted(list(all_roads))
        n_roads = len(road_list)
        
        # åˆ›å»ºå…±ç°çŸ©é˜µ
        cooccur_matrix = np.zeros((n_roads, n_roads))
        road_to_idx = {road: i for i, road in enumerate(road_list)}
        
        for pair in viz_pairs:
            i = road_to_idx[pair['road_a']]
            j = road_to_idx[pair['road_b']]
            # ä½¿ç”¨æœ€å¤§æ¡ä»¶æ¦‚ç‡å¡«å……çŸ©é˜µ
            cooccur_matrix[i, j] = pair['max_conf']
            cooccur_matrix[j, i] = pair['max_conf']
        
        # åˆ›å»ºçƒ­å›¾
        plt.figure(figsize=(12, 10))
        
        mask = cooccur_matrix == 0
        sns.heatmap(cooccur_matrix, 
                   annot=True, 
                   fmt='.3f',
                   cmap='Reds',
                   xticklabels=[road[:15] + '...' if len(road) > 15 else road for road in road_list],
                   yticklabels=[road[:15] + '...' if len(road) > 15 else road for road in road_list],
                   mask=mask,
                   cbar_kws={'label': 'Max Conditional Probability'})
        
        plt.title('Training Set Road Co-occurrence Heatmap\n(Top Road Pairs by Conditional Probability)', 
                 fontsize=14, fontweight='bold')
        plt.xlabel('Road B')
        plt.ylabel('Road A')
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        heatmap_path = os.path.join(self.figs_dir, "train_cooccurrence_heatmap.png")
        plt.savefig(heatmap_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"   ğŸ“Š çƒ­å›¾ä¿å­˜åˆ°: {heatmap_path}")
        return heatmap_path
        
    def save_cooccurrence_stats(self):
        """ä¿å­˜å…±ç°ç»Ÿè®¡åˆ°CSVæ–‡ä»¶"""
        print("6. ä¿å­˜å…±ç°ç»Ÿè®¡...")
        
        if not self.cooccurrence_stats:
            print("   âŒ æ²¡æœ‰ç»Ÿè®¡æ•°æ®å¯ä¿å­˜")
            return None
        
        # è½¬æ¢ä¸ºDataFrame
        df_stats = pd.DataFrame(self.cooccurrence_stats)
        
        # æŒ‰æœ€å¤§æ¡ä»¶æ¦‚ç‡æ’åº
        df_stats = df_stats.sort_values('max_conf', ascending=False)
        
        # é‡æ–°æ’åˆ—åˆ—çš„é¡ºåº
        df_stats = df_stats[['road_a', 'road_b', 'count_a', 'count_b', 
                           'count_ab', 'conf_a2b', 'conf_b2a', 'max_conf']]
        
        # ä¿å­˜åˆ°CSV
        output_path = os.path.join(self.results_dir, "train_cooccurrence_stats.csv")
        df_stats.to_csv(output_path, index=False)
        
        print(f"   âœ… ç»Ÿè®¡æ•°æ®ä¿å­˜åˆ°: {output_path}")
        print(f"   å…±ç°é“è·¯å¯¹æ•°é‡: {len(df_stats)}")
        
        return output_path
        
    def analyze_network_candidates(self, top_pairs):
        """åˆ†æå€™é€‰ç½‘ç»œç»“æ„"""
        print("7. åˆ†æå€™é€‰è´å¶æ–¯ç½‘ç»œç»“æ„...")
        
        if len(top_pairs) < 3:
            print("   âŒ é“è·¯å¯¹æ•°é‡ä¸è¶³ï¼Œæ— æ³•æ„å»ºç½‘ç»œ")
            return None
        
        print(f"\n   æ¨èçš„å‰3å¯¹é“è·¯ç”¨äºè´å¶æ–¯ç½‘ç»œ:")
        print(f"   {'åºå·':<4} {'çˆ¶èŠ‚ç‚¹':<20} {'å­èŠ‚ç‚¹':<20} {'æ¡ä»¶æ¦‚ç‡':<10} {'å…³ç³»å¼ºåº¦'}")
        print("-" * 80)
        
        network_edges = []
        for i, pair in enumerate(top_pairs[:3]):
            # é€‰æ‹©æ¡ä»¶æ¦‚ç‡æ›´é«˜çš„æ–¹å‘ä½œä¸ºè¾¹çš„æ–¹å‘
            if pair['conf_a2b'] >= pair['conf_b2a']:
                parent, child = pair['road_a'], pair['road_b']
                cond_prob = pair['conf_a2b']
            else:
                parent, child = pair['road_b'], pair['road_a']
                cond_prob = pair['conf_b2a']
            
            network_edges.append((parent, child, cond_prob))
            
            strength = "æå¼º" if cond_prob > 0.6 else "å¼º" if cond_prob > 0.4 else "ä¸­ç­‰"
            print(f"   {i+1:<4} {parent:<20} {child:<20} {cond_prob:<10.4f} {strength}")
        
        print(f"\n   ç½‘ç»œç‰¹ç‚¹:")
        print(f"   - èŠ‚ç‚¹æ•°: {len(set([edge[0] for edge in network_edges] + [edge[1] for edge in network_edges]))}")
        print(f"   - è¾¹æ•°: {len(network_edges)}")
        print(f"   - å¹³å‡æ¡ä»¶æ¦‚ç‡: {np.mean([edge[2] for edge in network_edges]):.4f}")
        
        return network_edges
        
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´çš„è®­ç»ƒé›†å…±ç°åˆ†æ"""
        print("ğŸš€ å¼€å§‹åŸºäºè®­ç»ƒé›†çš„é“è·¯å…±ç°åˆ†æ...")
        print("="*60)
        
        try:
            # 1. æ•°æ®åŠ è½½å’Œåˆ†å‰²
            self.load_and_split_data()
            
            # 2. åˆ†æé“è·¯é¢‘ç‡
            self.analyze_road_frequencies()
            
            # 3. è®¡ç®—å…±ç°çŸ©é˜µ
            self.compute_cooccurrence_matrix()
            
            # 4. é€‰æ‹©é¡¶çº§é“è·¯å¯¹
            top_pairs = self.select_top_road_pairs()
            
            # 5. åˆ›å»ºå¯è§†åŒ–
            self.create_cooccurrence_heatmap(top_pairs)
            
            # 6. ä¿å­˜ç»Ÿè®¡æ•°æ®
            self.save_cooccurrence_stats()
            
            # 7. åˆ†æç½‘ç»œå€™é€‰
            network_edges = self.analyze_network_candidates(top_pairs)
            
            print(f"\nâœ… è®­ç»ƒé›†å…±ç°åˆ†æå®Œæˆï¼")
            print(f"ğŸ“ ç»Ÿè®¡æ–‡ä»¶: {self.results_dir}/train_cooccurrence_stats.csv")
            print(f"ğŸ“Š å¯è§†åŒ–: {self.figs_dir}/train_cooccurrence_heatmap.png")
            
            return {
                'top_pairs': top_pairs,
                'network_edges': network_edges,
                'road_stats': self.road_stats
            }
            
        except Exception as e:
            print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None

def main():
    """ä¸»å‡½æ•°"""
    analyzer = TrainCooccurrenceAnalyzer()
    results = analyzer.run_analysis()
    
    if results:
        print(f"\nğŸ¯ åˆ†ææ€»ç»“:")
        print(f"   åŸºäºè®­ç»ƒé›†çš„é“è·¯å…±ç°æ¨¡å¼å·²è¯†åˆ«")
        print(f"   é¿å…äº†æ•°æ®æ³„éœ²é—®é¢˜")
        print(f"   ä¸ºæ„å»ºé«˜è´¨é‡è´å¶æ–¯ç½‘ç»œæä¾›äº†ç»Ÿè®¡åŸºç¡€")
        print(f"   é€‰æ‹©çš„é“è·¯å¯¹å…·æœ‰çœŸå®çš„é¢„æµ‹ä»·å€¼")

if __name__ == "__main__":
    main()