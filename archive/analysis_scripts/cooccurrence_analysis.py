#!/usr/bin/env python3
"""
Charlestonæ´ªæ°´æ•°æ®é“è·¯å…±ç°åˆ†æè„šæœ¬

åŠŸèƒ½ï¼š
1. åˆ†æåŒä¸€å¤©åŒæ—¶æ·¹æ²¡çš„é“è·¯å¯¹çš„å¼ºå…±ç°æ¨¡å¼
2. ä½¿ç”¨å…³è”è§„åˆ™æŒ–æ˜æ–¹æ³•è®¡ç®—æ”¯æŒåº¦ã€ç½®ä¿¡åº¦å’Œæå‡åº¦
3. è¯†åˆ«å…·æœ‰å¼ºå…³è”æ€§çš„é“è·¯å¯¹ç»„åˆ
4. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Šå’Œå¯è§†åŒ–å›¾è¡¨

ç”¨æ³•ï¼š
    python cooccurrence_analysis.py

å‚æ•°è°ƒæ•´ï¼š
    å¯åœ¨main()å‡½æ•°ä¸­ä¿®æ”¹ä»¥ä¸‹å‚æ•°ï¼š
    - min_count: å•è·¯æœ€å°å‡ºç°å¤©æ•°é˜ˆå€¼ (é»˜è®¤: 3)
    - min_support: é“è·¯å¯¹æœ€å°å…±ç°å¤©æ•°é˜ˆå€¼ (é»˜è®¤: 5)
    - min_lift: æœ€å°æå‡åº¦é˜ˆå€¼ (é»˜è®¤: 2.0)

è¾“å‡ºï¼š
    - results/road_pair_stats.csv - è¯¦ç»†çš„é“è·¯å¯¹ç»Ÿè®¡
    - figs/top_pairs_lift.png - Top-10é“è·¯å¯¹æå‡åº¦æ¡å½¢å›¾
    - ç»ˆç«¯è¾“å‡ºæŒ‰æå‡åº¦æ’åºçš„å‰15ä¸ªé“è·¯å¯¹

å…³è”è§„åˆ™æŒ‡æ ‡è¯´æ˜ï¼š
    - Support: count(A,B)/N - é“è·¯å¯¹å…±ç°çš„ç›¸å¯¹é¢‘ç‡
    - Confidence Aâ†’B: count(A,B)/count(A) - Aå‡ºç°æ—¶Bä¹Ÿå‡ºç°çš„æ¦‚ç‡
    - Lift: conf(Aâ†’B)/(count(B)/N) - ç›¸å¯¹äºéšæœºçš„æå‡å€æ•°
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict, Counter
from itertools import combinations
import os

class CooccurrenceAnalyzer:
    """é“è·¯å…±ç°åˆ†æå™¨"""
    
    def __init__(self, data_csv_path="Road_Closures_2024.csv", results_dir="results", figs_dir="figs"):
        self.data_csv_path = data_csv_path
        self.results_dir = results_dir
        self.figs_dir = figs_dir
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(results_dir, exist_ok=True)
        os.makedirs(figs_dir, exist_ok=True)
        
        # æ•°æ®å­˜å‚¨
        self.flood_by_date = {}  # {date: set(roads)}
        self.road_counts = {}    # {road: count}
        self.pair_counts = {}    # {(road1, road2): count}
        self.total_flood_days = 0
        
        # ç»“æœå­˜å‚¨
        self.road_pair_stats = []
        
    def load_flood_data(self):
        """åŠ è½½æ´ªæ°´æ•°æ®å¹¶æŒ‰æ—¥æœŸåˆ†ç»„"""
        print("1. åŠ è½½æ´ªæ°´æ•°æ®...")
        
        # è¯»å–æ•°æ®
        df = pd.read_csv(self.data_csv_path)
        print(f"   æ€»è®°å½•æ•°: {len(df)}")
        
        # ç­›é€‰æ´ªæ°´è®°å½•
        flood_df = df[df["REASON"].str.upper() == "FLOOD"].copy()
        print(f"   æ´ªæ°´è®°å½•: {len(flood_df)}")
        
        # å¤„ç†æ—¶é—´å’Œé“è·¯åç§°
        flood_df["time_create"] = pd.to_datetime(flood_df["START"], utc=True)
        flood_df["date"] = flood_df["time_create"].dt.floor("D")
        flood_df["road"] = flood_df["STREET"].str.upper().str.strip()
        
        # æŒ‰æ—¥æœŸåˆ†ç»„ï¼Œç”Ÿæˆæ¯æ—¥æ´ªæ°´é“è·¯é›†åˆ
        for date, group in flood_df.groupby("date"):
            flooded_roads = set(group["road"].dropna().unique())
            if len(flooded_roads) > 0:  # åªä¿ç•™æœ‰é“è·¯æ•°æ®çš„æ—¥æœŸ
                self.flood_by_date[str(date.date())] = flooded_roads
        
        self.total_flood_days = len(self.flood_by_date)
        
        print(f"   æ´ªæ°´æ—¥æœŸæ•°: {self.total_flood_days}")
        print(f"   æ—¥æœŸèŒƒå›´: {min(self.flood_by_date.keys())} è‡³ {max(self.flood_by_date.keys())}")
        
        # æ˜¾ç¤ºæ¯æ—¥é“è·¯æ•°åˆ†å¸ƒ
        daily_road_counts = [len(roads) for roads in self.flood_by_date.values()]
        print(f"   æ¯æ—¥å¹³å‡é“è·¯æ•°: {np.mean(daily_road_counts):.1f}")
        print(f"   æ¯æ—¥æœ€å¤šé“è·¯æ•°: {max(daily_road_counts)}")
        print(f"   æ¯æ—¥æœ€å°‘é“è·¯æ•°: {min(daily_road_counts)}")
        
        return self.flood_by_date
        
    def compute_statistics(self, min_count=3):
        """è®¡ç®—é“è·¯å•ç‹¬å‡ºç°å’Œå…±ç°ç»Ÿè®¡"""
        print("2. è®¡ç®—é“è·¯å‡ºç°å’Œå…±ç°ç»Ÿè®¡...")
        
        # ç»Ÿè®¡æ¯æ¡é“è·¯å‡ºç°å¤©æ•°
        all_roads = set()
        for roads in self.flood_by_date.values():
            all_roads.update(roads)
        
        for road in all_roads:
            count = sum(1 for roads in self.flood_by_date.values() if road in roads)
            self.road_counts[road] = count
        
        # è¿‡æ»¤ä½é¢‘é“è·¯
        frequent_roads = {road: count for road, count in self.road_counts.items() 
                         if count >= min_count}
        
        print(f"   æ€»é“è·¯æ•°: {len(all_roads)}")
        print(f"   é¢‘ç¹é“è·¯æ•° (â‰¥{min_count}å¤©): {len(frequent_roads)}")
        
        # è®¡ç®—é“è·¯å¯¹å…±ç°æ¬¡æ•°
        pair_count = 0
        for date, roads in self.flood_by_date.items():
            # åªè€ƒè™‘é¢‘ç¹é“è·¯
            frequent_roads_today = [road for road in roads if road in frequent_roads]
            
            # è®¡ç®—æ‰€æœ‰é“è·¯å¯¹ç»„åˆ
            for road1, road2 in combinations(frequent_roads_today, 2):
                pair = tuple(sorted([road1, road2]))  # ç¡®ä¿é¡ºåºä¸€è‡´
                self.pair_counts[pair] = self.pair_counts.get(pair, 0) + 1
                pair_count += 1
        
        print(f"   é“è·¯å¯¹ç»„åˆæ€»æ•°: {len(self.pair_counts)}")
        print(f"   å…±ç°äº‹ä»¶æ€»æ•°: {pair_count}")
        
        # æ›´æ–°road_countsåªä¿ç•™é¢‘ç¹é“è·¯
        self.road_counts = frequent_roads
        
        return self.road_counts, self.pair_counts
        
    def compute_association_metrics(self, min_support=5, min_lift=2.0):
        """è®¡ç®—å…³è”è§„åˆ™æŒ‡æ ‡"""
        print("3. è®¡ç®—å…³è”è§„åˆ™æŒ‡æ ‡...")
        
        # è¿‡æ»¤æ»¡è¶³æœ€å°æ”¯æŒåº¦çš„é“è·¯å¯¹
        frequent_pairs = {pair: count for pair, count in self.pair_counts.items() 
                         if count >= min_support}
        
        print(f"   æ»¡è¶³æ”¯æŒåº¦é˜ˆå€¼ (â‰¥{min_support}) çš„é“è·¯å¯¹: {len(frequent_pairs)}")
        
        # è®¡ç®—å…³è”æŒ‡æ ‡
        strong_associations = []
        
        for (road_a, road_b), count_ab in frequent_pairs.items():
            count_a = self.road_counts[road_a]
            count_b = self.road_counts[road_b]
            
            # ç½®ä¿¡åº¦
            conf_a_to_b = count_ab / count_a
            conf_b_to_a = count_ab / count_b
            
            # æå‡åº¦
            lift_a_to_b = conf_a_to_b / (count_b / self.total_flood_days)
            lift_b_to_a = conf_b_to_a / (count_a / self.total_flood_days)
            
            # ä½¿ç”¨æ›´é«˜çš„æå‡åº¦
            max_lift = max(lift_a_to_b, lift_b_to_a)
            
            # åº”ç”¨æå‡åº¦è¿‡æ»¤
            if max_lift >= min_lift:
                strong_associations.append({
                    'A': road_a,
                    'B': road_b,
                    'countA': count_a,
                    'countB': count_b,
                    'countAB': count_ab,
                    'confA2B': conf_a_to_b,
                    'confB2A': conf_b_to_a,
                    'lift': max_lift,
                    'lift_A2B': lift_a_to_b,
                    'lift_B2A': lift_b_to_a
                })
        
        # æŒ‰æå‡åº¦æ’åº
        strong_associations.sort(key=lambda x: x['lift'], reverse=True)
        
        print(f"   å¼ºå…³è”é“è·¯å¯¹ (liftâ‰¥{min_lift}): {len(strong_associations)}")
        
        if len(strong_associations) > 0:
            print(f"   æå‡åº¦èŒƒå›´: [{min([x['lift'] for x in strong_associations]):.2f}, "
                  f"{max([x['lift'] for x in strong_associations]):.2f}]")
        
        self.road_pair_stats = strong_associations
        return strong_associations
        
    def save_results(self):
        """ä¿å­˜ç»“æœåˆ°CSV"""
        print("4. ä¿å­˜ç»Ÿè®¡ç»“æœ...")
        
        if len(self.road_pair_stats) == 0:
            print("   âš ï¸ æ²¡æœ‰æ»¡è¶³æ¡ä»¶çš„é“è·¯å¯¹ï¼Œåˆ›å»ºç©ºæ–‡ä»¶")
            empty_df = pd.DataFrame(columns=['A', 'B', 'countA', 'countB', 'countAB', 
                                           'confA2B', 'confB2A', 'lift'])
            csv_path = os.path.join(self.results_dir, "road_pair_stats.csv")
            empty_df.to_csv(csv_path, index=False)
            return csv_path
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(self.road_pair_stats)
        
        # é€‰æ‹©è¾“å‡ºåˆ—
        output_columns = ['A', 'B', 'countA', 'countB', 'countAB', 
                         'confA2B', 'confB2A', 'lift']
        df_output = df[output_columns].copy()
        
        # ä¿å­˜CSV
        csv_path = os.path.join(self.results_dir, "road_pair_stats.csv")
        df_output.to_csv(csv_path, index=False, float_format='%.4f')
        
        print(f"   âœ… ç»“æœä¿å­˜åˆ°: {csv_path}")
        print(f"   å…±ä¿å­˜ {len(df_output)} ä¸ªå¼ºå…³è”é“è·¯å¯¹")
        
        return csv_path
        
    def print_top_results(self, top_n=15):
        """æ‰“å°å‰Nä¸ªæœ€å¼ºå…³è”çš„é“è·¯å¯¹"""
        print(f"5. æ˜¾ç¤ºå‰{top_n}ä¸ªå¼ºå…³è”é“è·¯å¯¹...")
        
        if len(self.road_pair_stats) == 0:
            print("   æ²¡æœ‰æ»¡è¶³æ¡ä»¶çš„é“è·¯å¯¹")
            return
        
        print(f"\n{'='*90}")
        print(f"ğŸ† æŒ‰æå‡åº¦(Lift)æ’åºçš„å‰{min(top_n, len(self.road_pair_stats))}ä¸ªå¼ºå…³è”é“è·¯å¯¹")
        print(f"{'='*90}")
        
        # è¡¨å¤´
        print(f"{'æ’å':<4} {'é“è·¯A':<25} {'é“è·¯B':<25} {'Lift':<6} {'ç½®ä¿¡åº¦Aâ†’B':<10} {'ç½®ä¿¡åº¦Bâ†’A':<10}")
        print("-" * 90)
        
        # æ˜¾ç¤ºç»“æœ
        for i, pair in enumerate(self.road_pair_stats[:top_n]):
            rank = f"{i+1}."
            road_a = pair['A'][:24]  # æˆªæ–­é•¿åç§°
            road_b = pair['B'][:24]
            lift = f"{pair['lift']:.2f}"
            conf_ab = f"{pair['confA2B']:.3f}"
            conf_ba = f"{pair['confB2A']:.3f}"
            
            print(f"{rank:<4} {road_a:<25} {road_b:<25} {lift:<6} {conf_ab:<10} {conf_ba:<10}")
        
        # æ˜¾ç¤ºç»Ÿè®¡æ‘˜è¦
        if len(self.road_pair_stats) > 0:
            avg_lift = np.mean([x['lift'] for x in self.road_pair_stats])
            max_lift = max([x['lift'] for x in self.road_pair_stats])
            
            print(f"\nğŸ“Š ç»Ÿè®¡æ‘˜è¦:")
            print(f"   å¼ºå…³è”å¯¹æ€»æ•°: {len(self.road_pair_stats)}")
            print(f"   å¹³å‡æå‡åº¦: {avg_lift:.2f}")
            print(f"   æœ€é«˜æå‡åº¦: {max_lift:.2f}")
            
            # æœ€å¼ºå…³è”å¯¹è§£é‡Š
            top_pair = self.road_pair_stats[0]
            print(f"\nğŸ¯ æœ€å¼ºå…³è”: {top_pair['A']} â†” {top_pair['B']}")
            print(f"   å…±ç°å¤©æ•°: {top_pair['countAB']}")
            print(f"   {top_pair['A']} å‡ºç° {top_pair['countA']} å¤©")
            print(f"   {top_pair['B']} å‡ºç° {top_pair['countB']} å¤©")
            print(f"   æå‡åº¦: {top_pair['lift']:.2f} (æ¯”éšæœºé«˜ {top_pair['lift']:.1f} å€)")
        
    def create_visualization(self, top_n=10):
        """åˆ›å»ºTop-Né“è·¯å¯¹æå‡åº¦æ¡å½¢å›¾"""
        print("6. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        if len(self.road_pair_stats) == 0:
            print("   æ²¡æœ‰æ•°æ®å¯è§†åŒ–")
            return None
        
        # å‡†å¤‡æ•°æ®
        top_pairs = self.road_pair_stats[:min(top_n, len(self.road_pair_stats))]
        
        # åˆ›å»ºé“è·¯å¯¹æ ‡ç­¾
        pair_labels = []
        lifts = []
        
        for pair in top_pairs:
            # ç¼©çŸ­é“è·¯åç§°
            road_a = pair['A'].replace('STREET', 'ST').replace('AVENUE', 'AVE')[:15]
            road_b = pair['B'].replace('STREET', 'ST').replace('AVENUE', 'AVE')[:15]
            label = f"{road_a}\nâ†”\n{road_b}"
            pair_labels.append(label)
            lifts.append(pair['lift'])
        
        # åˆ›å»ºå›¾è¡¨
        plt.figure(figsize=(14, 8))
        
        # åˆ›å»ºæ¡å½¢å›¾
        bars = plt.bar(range(len(lifts)), lifts, 
                      color='steelblue', alpha=0.8, edgecolor='black', linewidth=1)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, lift in zip(bars, lifts):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,
                    f'{lift:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=10)
        
        # è®¾ç½®å›¾è¡¨å±æ€§
        plt.title(f'Top-{len(top_pairs)} é“è·¯å¯¹å…³è”å¼ºåº¦ (æå‡åº¦)', 
                 fontsize=16, fontweight='bold', pad=20)
        plt.xlabel('é“è·¯å¯¹', fontsize=12)
        plt.ylabel('æå‡åº¦ (Lift)', fontsize=12)
        
        # è®¾ç½®xè½´æ ‡ç­¾
        plt.xticks(range(len(pair_labels)), pair_labels, rotation=45, ha='right', fontsize=9)
        
        # æ·»åŠ ç½‘æ ¼
        plt.grid(axis='y', alpha=0.3, linestyle='--')
        
        # æ·»åŠ åŸºå‡†çº¿
        plt.axhline(y=2.0, color='red', linestyle='--', alpha=0.7, 
                   label='æœ€å°æå‡åº¦é˜ˆå€¼ (2.0)')
        plt.legend()
        
        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        fig_path = os.path.join(self.figs_dir, "top_pairs_lift.png")
        plt.savefig(fig_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"   ğŸ“Š å¯è§†åŒ–å›¾è¡¨ä¿å­˜åˆ°: {fig_path}")
        
        return fig_path
        
    def run_analysis(self, min_count=3, min_support=5, min_lift=2.0):
        """è¿è¡Œå®Œæ•´çš„å…±ç°åˆ†æ"""
        print("ğŸš€ å¼€å§‹Charlestonæ´ªæ°´é“è·¯å…±ç°åˆ†æ...")
        print("="*70)
        
        try:
            # 1. åŠ è½½æ•°æ®
            self.load_flood_data()
            
            # 2. è®¡ç®—ç»Ÿè®¡
            self.compute_statistics(min_count=min_count)
            
            # 3. è®¡ç®—å…³è”æŒ‡æ ‡
            self.compute_association_metrics(min_support=min_support, min_lift=min_lift)
            
            # 4. ä¿å­˜ç»“æœ
            self.save_results()
            
            # 5. æ˜¾ç¤ºç»“æœ
            self.print_top_results(top_n=15)
            
            # 6. åˆ›å»ºå¯è§†åŒ–
            self.create_visualization(top_n=10)
            
            print(f"\nâœ… é“è·¯å…±ç°åˆ†æå®Œæˆï¼")
            print(f"ğŸ“ è¯¦ç»†ç»“æœ: {self.results_dir}/road_pair_stats.csv")
            print(f"ğŸ“Š å¯è§†åŒ–å›¾è¡¨: {self.figs_dir}/top_pairs_lift.png")
            
            return self.road_pair_stats
            
        except Exception as e:
            print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None

def main():
    """ä¸»å‡½æ•° - å¯åœ¨æ­¤è°ƒæ•´åˆ†æå‚æ•°"""
    
    # åˆ†æå‚æ•° (å¯è°ƒæ•´)
    MIN_COUNT = 3      # å•è·¯æœ€å°å‡ºç°å¤©æ•°
    MIN_SUPPORT = 5    # é“è·¯å¯¹æœ€å°å…±ç°å¤©æ•°  
    MIN_LIFT = 2.0     # æœ€å°æå‡åº¦é˜ˆå€¼
    
    print(f"åˆ†æå‚æ•°:")
    print(f"  æœ€å°å•è·¯å‡ºç°å¤©æ•°: {MIN_COUNT}")
    print(f"  æœ€å°é“è·¯å¯¹å…±ç°å¤©æ•°: {MIN_SUPPORT}")
    print(f"  æœ€å°æå‡åº¦: {MIN_LIFT}")
    print()
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = CooccurrenceAnalyzer()
    
    # è¿è¡Œåˆ†æ
    results = analyzer.run_analysis(
        min_count=MIN_COUNT,
        min_support=MIN_SUPPORT, 
        min_lift=MIN_LIFT
    )
    
    if results:
        print(f"\nğŸ¯ å…³é”®å‘ç°:")
        print(f"   å‘ç° {len(results)} ä¸ªå¼ºå…³è”é“è·¯å¯¹")
        print(f"   è¿™äº›é“è·¯å¯¹åœ¨æ´ªæ°´æœŸé—´å…·æœ‰æ˜¾è‘—çš„å…±ç°æ¨¡å¼")
        print(f"   å¯ç”¨äºæ´ªæ°´é¢„è­¦å’Œåº”æ€¥å“åº”è§„åˆ’")

if __name__ == "__main__":
    main()