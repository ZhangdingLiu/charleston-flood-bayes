#!/usr/bin/env python3
"""
æ„å»ºæç®€æ´ªæ°´è´å¶æ–¯ç½‘ç»œ

åŠŸèƒ½ï¼š
1. ä¸¥æ ¼ç­›é€‰é«˜é¢‘æ ¸å¿ƒé“è·¯èŠ‚ç‚¹ (é¢‘æ¬¡â‰¥15)
2. ä½¿ç”¨äº’ä¿¡æ¯å’Œå…±ç°æ¬¡æ•°ç­›é€‰è¾¹
3. åº”ç”¨Chow-Liuç®—æ³•æ„å»ºæœ€å¤§ç”Ÿæˆæ ‘
4. é™åˆ¶èŠ‚ç‚¹åº¦æ•°â‰¤2ï¼Œç¡®ä¿ç½‘ç»œç®€æ´
5. ç”Ÿæˆultra_core_network.csv

ç”¨æ³•ï¼š
    python build_ultra_core.py

è¾“å‡ºï¼š
    - ultra_core_network.csv - æç®€ç½‘ç»œç»“æ„
    - ç»ˆç«¯è¾“å‡ºç½‘ç»œç»Ÿè®¡ä¿¡æ¯
"""

import pandas as pd
import numpy as np
import networkx as nx
from collections import Counter, defaultdict
from sklearn.metrics import mutual_info_score
from sklearn.model_selection import train_test_split
import itertools
import random

# è®¾ç½®éšæœºç§å­
RANDOM_SEED = 42
random.seed(0)
np.random.seed(0)

class UltraCoreNetworkBuilder:
    """æç®€æ ¸å¿ƒç½‘ç»œæ„å»ºå™¨"""
    
    def __init__(self, data_csv_path="Road_Closures_2024.csv"):
        self.data_csv_path = data_csv_path
        self.train_df = None
        self.core_nodes = []
        self.edge_weights = {}
        self.final_network = None
        
    def load_and_split_data(self):
        """åŠ è½½æ•°æ®å¹¶åˆ†å‰²ï¼ˆä¸main_clean.pyä¿æŒä¸€è‡´ï¼‰"""
        print("1. åŠ è½½å’Œåˆ†å‰²æ•°æ®...")
        
        # åŠ è½½æ•°æ®
        df = pd.read_csv(self.data_csv_path)
        df = df[df["REASON"].str.upper() == "FLOOD"].copy()
        
        # æ•°æ®é¢„å¤„ç†
        df["time_create"] = pd.to_datetime(df["START"], utc=True)
        df["link_id"] = df["STREET"].str.upper().str.replace(" ", "_")
        df["link_id"] = df["link_id"].astype(str)
        df["id"] = df["OBJECTID"].astype(str)
        
        # ä½¿ç”¨ç›¸åŒçš„éšæœºç§å­åˆ†å‰²
        train_df, test_df = train_test_split(
            df, test_size=0.3, random_state=RANDOM_SEED
        )
        
        self.train_df = train_df
        
        print(f"   è®­ç»ƒé›†: {len(train_df)}æ¡è®°å½•")
        print(f"   æ¶‰åŠé“è·¯: {train_df['link_id'].nunique()}æ¡")
        
        return train_df
        
    def select_core_nodes(self, min_frequency=15):
        """é€‰æ‹©æ ¸å¿ƒèŠ‚ç‚¹ï¼šé¢‘æ¬¡â‰¥15"""
        print("2. é€‰æ‹©æ ¸å¿ƒèŠ‚ç‚¹...")
        
        # ç»Ÿè®¡é“è·¯é¢‘æ¬¡
        road_counts = Counter(self.train_df['link_id'])
        
        # ç­›é€‰é«˜é¢‘èŠ‚ç‚¹
        self.core_nodes = [road for road, count in road_counts.items() 
                          if count >= min_frequency]
        
        print(f"   é¢‘æ¬¡é˜ˆå€¼: â‰¥{min_frequency}")
        print(f"   æ ¸å¿ƒèŠ‚ç‚¹æ•°: {len(self.core_nodes)}")
        
        if len(self.core_nodes) == 0:
            raise ValueError(f"æ²¡æœ‰é“è·¯æ»¡è¶³é¢‘æ¬¡â‰¥{min_frequency}çš„æ¡ä»¶")
            
        # æ˜¾ç¤ºæ ¸å¿ƒèŠ‚ç‚¹åŠå…¶é¢‘æ¬¡
        print("   æ ¸å¿ƒèŠ‚ç‚¹åˆ—è¡¨:")
        for road in sorted(self.core_nodes):
            count = road_counts[road]
            print(f"     {road.replace('_', ' '):<25} (é¢‘æ¬¡: {count})")
            
        return self.core_nodes
        
    def compute_mutual_information_edges(self, min_cooccurrence=5, min_mi=0.02):
        """è®¡ç®—è¾¹ï¼šåŸºäºå…±ç°æ¬¡æ•°å’Œäº’ä¿¡æ¯"""
        print("3. è®¡ç®—è¾¹æƒé‡...")
        
        # åˆ›å»ºæ—¥æœŸ-é“è·¯çŸ©é˜µ
        df_filtered = self.train_df[self.train_df['link_id'].isin(self.core_nodes)].copy()
        df_filtered['date'] = df_filtered['time_create'].dt.floor('D')
        
        # æ„å»ºé“è·¯-æ—¥æœŸäºŒå…ƒçŸ©é˜µ
        pivot_table = df_filtered.pivot_table(
            index='date', 
            columns='link_id', 
            values='id', 
            aggfunc='count', 
            fill_value=0
        )
        
        # è½¬æ¢ä¸ºäºŒå…ƒçŸ©é˜µ (0/1)
        binary_matrix = (pivot_table > 0).astype(int)
        
        # ç¡®ä¿æ‰€æœ‰æ ¸å¿ƒèŠ‚ç‚¹éƒ½åœ¨çŸ©é˜µä¸­
        for node in self.core_nodes:
            if node not in binary_matrix.columns:
                binary_matrix[node] = 0
        
        print(f"   æ—¶é—´çª—å£: {len(binary_matrix)}å¤©")
        print(f"   é“è·¯èŠ‚ç‚¹: {len(binary_matrix.columns)}ä¸ª")
        
        # è®¡ç®—æ‰€æœ‰é“è·¯å¯¹çš„äº’ä¿¡æ¯å’Œå…±ç°æ¬¡æ•°
        valid_edges = []
        mi_scores = []
        cooccurrence_counts = []
        
        for road1, road2 in itertools.combinations(self.core_nodes, 2):
            if road1 not in binary_matrix.columns or road2 not in binary_matrix.columns:
                continue
                
            # è·å–äºŒå…ƒåºåˆ—
            seq1 = binary_matrix[road1].values
            seq2 = binary_matrix[road2].values
            
            # è®¡ç®—å…±ç°æ¬¡æ•°
            cooccurrence = np.sum((seq1 == 1) & (seq2 == 1))
            
            # è®¡ç®—äº’ä¿¡æ¯
            if len(set(seq1)) > 1 and len(set(seq2)) > 1:  # ç¡®ä¿ä¸æ˜¯å¸¸æ•°åºåˆ—
                mi = mutual_info_score(seq1, seq2)
            else:
                mi = 0.0
            
            # åº”ç”¨ç­›é€‰æ¡ä»¶
            if cooccurrence >= min_cooccurrence and mi >= min_mi:
                valid_edges.append((road1, road2))
                self.edge_weights[(road1, road2)] = {
                    'mutual_info': mi,
                    'cooccurrence': cooccurrence,
                    'weight': mi  # ä½¿ç”¨MIä½œä¸ºè¾¹æƒé‡
                }
                mi_scores.append(mi)
                cooccurrence_counts.append(cooccurrence)
        
        print(f"   å…±ç°é˜ˆå€¼: â‰¥{min_cooccurrence}")
        print(f"   äº’ä¿¡æ¯é˜ˆå€¼: â‰¥{min_mi}")
        print(f"   æœ‰æ•ˆè¾¹æ•°: {len(valid_edges)}")
        
        if len(valid_edges) > 0:
            print(f"   äº’ä¿¡æ¯èŒƒå›´: [{min(mi_scores):.4f}, {max(mi_scores):.4f}]")
            print(f"   å…±ç°æ¬¡æ•°èŒƒå›´: [{min(cooccurrence_counts)}, {max(cooccurrence_counts)}]")
        else:
            print("   âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ»¡è¶³æ¡ä»¶çš„è¾¹")
            
        return valid_edges
        
    def build_chow_liu_tree(self, valid_edges):
        """ä½¿ç”¨Chow-Liuç®—æ³•æ„å»ºæœ€å¤§ç”Ÿæˆæ ‘"""
        print("4. æ„å»ºChow-Liuæœ€å¤§ç”Ÿæˆæ ‘...")
        
        if len(valid_edges) == 0:
            print("   âš ï¸ æ²¡æœ‰æœ‰æ•ˆè¾¹ï¼Œåˆ›å»ºç©ºç½‘ç»œ")
            self.final_network = nx.Graph()
            self.final_network.add_nodes_from(self.core_nodes)
            return self.final_network
        
        # åˆ›å»ºå®Œå…¨å›¾
        G = nx.Graph()
        G.add_nodes_from(self.core_nodes)
        
        # æ·»åŠ æ‰€æœ‰æœ‰æ•ˆè¾¹ï¼ˆæƒé‡ä¸ºè´Ÿäº’ä¿¡æ¯ï¼Œå› ä¸ºMSTç®—æ³•å¯»æ‰¾æœ€å°æƒé‡ï¼‰
        for edge in valid_edges:
            road1, road2 = edge
            mi_weight = self.edge_weights[edge]['weight']
            G.add_edge(road1, road2, weight=-mi_weight, mutual_info=mi_weight,
                      cooccurrence=self.edge_weights[edge]['cooccurrence'])
        
        # ä½¿ç”¨Kruskalç®—æ³•æ‰¾æœ€å¤§ç”Ÿæˆæ ‘ï¼ˆé€šè¿‡è´Ÿæƒé‡è½¬æ¢ä¸ºæœ€å°ç”Ÿæˆæ ‘ï¼‰
        if G.number_of_edges() > 0:
            mst = nx.minimum_spanning_tree(G, weight='weight')
            
            # æ¢å¤æ­£æƒé‡
            for u, v, data in mst.edges(data=True):
                mst[u][v]['weight'] = -data['weight']
                
            print(f"   ç”Ÿæˆæ ‘èŠ‚ç‚¹: {mst.number_of_nodes()}")
            print(f"   ç”Ÿæˆæ ‘è¾¹æ•°: {mst.number_of_edges()}")
        else:
            mst = nx.Graph()
            mst.add_nodes_from(self.core_nodes)
            print("   ç”Ÿæˆç©ºç”Ÿæˆæ ‘ï¼ˆæ²¡æœ‰æœ‰æ•ˆè¾¹ï¼‰")
        
        self.final_network = mst
        return mst
        
    def enforce_degree_constraint(self, max_degree=2):
        """é™åˆ¶èŠ‚ç‚¹åº¦æ•°â‰¤2"""
        print("5. é™åˆ¶èŠ‚ç‚¹åº¦æ•°...")
        
        if self.final_network.number_of_edges() == 0:
            print("   ç½‘ç»œæ²¡æœ‰è¾¹ï¼Œè·³è¿‡åº¦æ•°é™åˆ¶")
            return self.final_network
        
        # æ£€æŸ¥å½“å‰åº¦æ•°åˆ†å¸ƒ
        degrees = dict(self.final_network.degree())
        high_degree_nodes = [node for node, degree in degrees.items() if degree > max_degree]
        
        print(f"   æœ€å¤§åº¦æ•°é™åˆ¶: â‰¤{max_degree}")
        print(f"   è¶…é™èŠ‚ç‚¹æ•°: {len(high_degree_nodes)}")
        
        if len(high_degree_nodes) == 0:
            print("   æ‰€æœ‰èŠ‚ç‚¹å·²æ»¡è¶³åº¦æ•°é™åˆ¶")
            return self.final_network
        
        # å¯¹æ¯ä¸ªè¶…é™èŠ‚ç‚¹ï¼Œåˆ é™¤äº’ä¿¡æ¯æœ€å°çš„è¾¹
        edges_removed = 0
        for node in high_degree_nodes:
            while self.final_network.degree(node) > max_degree:
                # è·å–è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰é‚»æ¥è¾¹
                incident_edges = list(self.final_network.edges(node, data=True))
                
                if len(incident_edges) <= max_degree:
                    break
                
                # æ‰¾åˆ°äº’ä¿¡æ¯æœ€å°çš„è¾¹
                min_edge = min(incident_edges, key=lambda x: x[2]['mutual_info'])
                
                # åˆ é™¤è¾¹
                self.final_network.remove_edge(min_edge[0], min_edge[1])
                edges_removed += 1
                
                print(f"     åˆ é™¤è¾¹: {min_edge[0]} - {min_edge[1]} (MI: {min_edge[2]['mutual_info']:.4f})")
        
        print(f"   åˆ é™¤è¾¹æ•°: {edges_removed}")
        print(f"   æœ€ç»ˆè¾¹æ•°: {self.final_network.number_of_edges()}")
        
        return self.final_network
        
    def save_network(self, output_path="ultra_core_network.csv"):
        """ä¿å­˜ç½‘ç»œåˆ°CSV"""
        print("6. ä¿å­˜ç½‘ç»œ...")
        
        if self.final_network.number_of_edges() == 0:
            # å¦‚æœæ²¡æœ‰è¾¹ï¼Œåˆ›å»ºç©ºCSV
            empty_df = pd.DataFrame(columns=['source', 'target', 'mutual_info', 'cooccurrence', 'weight'])
            empty_df.to_csv(output_path, index=False)
            print(f"   âœ… ç©ºç½‘ç»œä¿å­˜åˆ°: {output_path}")
        else:
            # ä¿å­˜è¾¹ä¿¡æ¯
            edges_data = []
            for u, v, data in self.final_network.edges(data=True):
                edges_data.append({
                    'source': u,
                    'target': v,
                    'mutual_info': data['mutual_info'],
                    'cooccurrence': data['cooccurrence'],
                    'weight': data['weight']
                })
            
            edges_df = pd.DataFrame(edges_data)
            edges_df.to_csv(output_path, index=False, float_format='%.6f')
            print(f"   âœ… ç½‘ç»œä¿å­˜åˆ°: {output_path}")
        
        return output_path
        
    def print_network_statistics(self):
        """æ‰“å°ç½‘ç»œç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*60)
        print("ğŸ“Š æç®€æ ¸å¿ƒç½‘ç»œç»Ÿè®¡")
        print("="*60)
        
        n_nodes = self.final_network.number_of_nodes()
        n_edges = self.final_network.number_of_edges()
        
        print(f"èŠ‚ç‚¹æ•°: {n_nodes}")
        print(f"è¾¹æ•°: {n_edges}")
        
        if n_edges > 0:
            # è®¡ç®—å¹³å‡åº¦
            degrees = [d for n, d in self.final_network.degree()]
            avg_degree = np.mean(degrees)
            max_degree = max(degrees)
            
            print(f"å¹³å‡åº¦: {avg_degree:.2f}")
            print(f"æœ€å¤§åº¦: {max_degree}")
            
            # æ˜¾ç¤ºåº¦åˆ†å¸ƒ
            degree_dist = Counter(degrees)
            print("åº¦åˆ†å¸ƒ:")
            for degree in sorted(degree_dist.keys()):
                count = degree_dist[degree]
                print(f"  åº¦{degree}: {count}ä¸ªèŠ‚ç‚¹")
            
            # æ˜¾ç¤ºè¾¹ä¿¡æ¯
            print(f"\nè¾¹åˆ—è¡¨ (æŒ‰äº’ä¿¡æ¯æ’åº):")
            edges_with_data = [(u, v, data) for u, v, data in self.final_network.edges(data=True)]
            edges_with_data.sort(key=lambda x: x[2]['mutual_info'], reverse=True)
            
            for u, v, data in edges_with_data:
                print(f"  {u.replace('_', ' '):<25} - {v.replace('_', ' '):<25} "
                      f"(MI: {data['mutual_info']:.4f}, å…±ç°: {data['cooccurrence']})")
        else:
            print("å¹³å‡åº¦: 0.00")
            print("æœ€å¤§åº¦: 0")
            print("ç½‘ç»œæ— è¿æ¥")
        
        # è¿é€šæ€§åˆ†æ
        if n_edges > 0:
            n_components = nx.number_connected_components(self.final_network)
            largest_cc_size = len(max(nx.connected_components(self.final_network), key=len))
            print(f"\nè¿é€šç»„ä»¶æ•°: {n_components}")
            print(f"æœ€å¤§è¿é€šç»„ä»¶å¤§å°: {largest_cc_size}")
        else:
            print(f"\nè¿é€šç»„ä»¶æ•°: {n_nodes} (æ‰€æœ‰èŠ‚ç‚¹å­¤ç«‹)")
            
        print("="*60)
        
    def build_ultra_core_network(self):
        """æ„å»ºå®Œæ•´çš„æç®€æ ¸å¿ƒç½‘ç»œ"""
        print("ğŸš€ æ„å»ºæç®€æ´ªæ°´è´å¶æ–¯ç½‘ç»œ...")
        print("="*60)
        
        try:
            # 1. æ•°æ®åŠ è½½
            self.load_and_split_data()
            
            # 2. é€‰æ‹©æ ¸å¿ƒèŠ‚ç‚¹
            self.select_core_nodes(min_frequency=15)
            
            # 3. è®¡ç®—è¾¹æƒé‡
            valid_edges = self.compute_mutual_information_edges(
                min_cooccurrence=5, 
                min_mi=0.02
            )
            
            # 4. æ„å»ºChow-Liuæ ‘
            self.build_chow_liu_tree(valid_edges)
            
            # 5. é™åˆ¶åº¦æ•°
            self.enforce_degree_constraint(max_degree=2)
            
            # 6. ä¿å­˜ç½‘ç»œ
            self.save_network("ultra_core_network.csv")
            
            # 7. æ‰“å°ç»Ÿè®¡
            self.print_network_statistics()
            
            print(f"\nâœ… æç®€æ ¸å¿ƒç½‘ç»œæ„å»ºå®Œæˆï¼")
            print(f"ğŸ“ ç½‘ç»œæ–‡ä»¶: ultra_core_network.csv")
            
            return self.final_network
            
        except Exception as e:
            print(f"\nâŒ æ„å»ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return None

def main():
    """ä¸»å‡½æ•°"""
    builder = UltraCoreNetworkBuilder()
    network = builder.build_ultra_core_network()
    
    if network is not None:
        print(f"\nğŸ¯ æç®€ç½‘ç»œç‰¹ç‚¹:")
        print(f"   - é«˜é¢‘æ ¸å¿ƒé“è·¯ (é¢‘æ¬¡â‰¥15)")
        print(f"   - å¼ºå…±ç°å…³ç³» (å…±ç°â‰¥5, MIâ‰¥0.02)")
        print(f"   - æ ‘çŠ¶ç»“æ„ (åº¦æ•°â‰¤2)")
        print(f"   - æœ€ä¼˜ä¿¡æ¯é‡ (Chow-Liuç®—æ³•)")

if __name__ == "__main__":
    main()