#!/usr/bin/env python3
"""
æ¨ç†è¿‡ç¨‹è°ƒè¯•å™¨ï¼šé€æ­¥å±•ç¤ºè´å¶æ–¯æ¨ç†è¿‡ç¨‹

è¯¦ç»†å±•ç¤ºæ¯ä¸ªæ¨ç†æ­¥éª¤ï¼Œè®©ç”¨æˆ·èƒ½å¤ŸéªŒè¯æ¨ç†è¿‡ç¨‹çš„æ­£ç¡®æ€§ï¼š
1. Evidenceè®¾ç½®è¿‡ç¨‹
2. CPTæŸ¥è¯¢æ­¥éª¤
3. æ¦‚ç‡è®¡ç®—è¿‡ç¨‹
4. é˜ˆå€¼å†³ç­–é€»è¾‘
5. æµ‹è¯•æ—¥æœŸçš„è¯¦ç»†åˆ†è§£
6. è´Ÿæ ·æœ¬æ„é€ è¿‡ç¨‹éªŒè¯
"""

import random
import numpy as np
import pandas as pd
from model import FloodBayesNetwork
from precision_focused_evaluation import PrecisionFocusedEvaluator
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®éšæœºç§å­
RANDOM_SEED = 42
random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

class InferenceDebugger:
    """æ¨ç†è¿‡ç¨‹è°ƒè¯•å™¨"""
    
    def __init__(self, flood_net, test_df):
        self.flood_net = flood_net
        self.test_df = test_df
        self.bn_nodes = set(flood_net.network_bayes.nodes())
        self.marginals_dict = dict(zip(
            flood_net.marginals['link_id'], 
            flood_net.marginals['p']
        ))
        
    def debug_single_inference(self, target_node, evidence):
        """è¯¦ç»†è°ƒè¯•å•ä¸ªæ¨ç†è¿‡ç¨‹"""
        print(f"ğŸ” è¯¦ç»†æ¨ç†è¿‡ç¨‹è°ƒè¯•")
        print("=" * 60)
        print(f"ç›®æ ‡èŠ‚ç‚¹: {target_node}")
        print(f"Evidence: {evidence}")
        
        # 1. éªŒè¯è¾“å…¥
        print(f"\n1ï¸âƒ£  è¾“å…¥éªŒè¯:")
        
        if target_node not in self.bn_nodes:
            print(f"   âŒ ç›®æ ‡èŠ‚ç‚¹ '{target_node}' ä¸åœ¨è´å¶æ–¯ç½‘ç»œä¸­")
            return None
            
        print(f"   âœ… ç›®æ ‡èŠ‚ç‚¹åœ¨ç½‘ç»œä¸­")
        
        for ev_node, ev_value in evidence.items():
            if ev_node not in self.bn_nodes:
                print(f"   âŒ EvidenceèŠ‚ç‚¹ '{ev_node}' ä¸åœ¨ç½‘ç»œä¸­")
                return None
            if ev_value not in [0, 1]:
                print(f"   âŒ Evidenceå€¼ '{ev_value}' å¿…é¡»æ˜¯0æˆ–1")
                return None
                
        print(f"   âœ… æ‰€æœ‰EvidenceèŠ‚ç‚¹å’Œå€¼éƒ½æœ‰æ•ˆ")
        
        # 2. æŸ¥çœ‹ç›®æ ‡èŠ‚ç‚¹çš„CPT
        print(f"\n2ï¸âƒ£  ç›®æ ‡èŠ‚ç‚¹CPTåˆ†æ:")
        
        # è·å–çˆ¶èŠ‚ç‚¹
        parents = list(self.flood_net.network.predecessors(target_node))
        print(f"   çˆ¶èŠ‚ç‚¹: {parents if parents else 'æ— '}")
        
        # è¾¹é™…æ¦‚ç‡
        marginal_prob = self.marginals_dict.get(target_node, 0)
        print(f"   è¾¹é™…æ¦‚ç‡ P({target_node}=1): {marginal_prob:.3f}")
        
        if target_node in self.flood_net.conditionals:
            cfg = self.flood_net.conditionals[target_node]
            cpt_parents = cfg['parents']
            conditionals = cfg['conditionals']
            
            print(f"   CPTçˆ¶èŠ‚ç‚¹: {cpt_parents}")
            print(f"   æ¡ä»¶æ¦‚ç‡è¡¨:")
            
            for state, prob in conditionals.items():
                parent_state_str = ", ".join([f"{p}={s}" for p, s in zip(cpt_parents, state)])
                print(f"     P({target_node}=1 | {parent_state_str}) = {prob:.3f}")
        else:
            print(f"   è¯¥èŠ‚ç‚¹æ— æ¡ä»¶æ¦‚ç‡è¡¨ï¼ˆä½¿ç”¨è¾¹é™…æ¦‚ç‡ï¼‰")
        
        # 3. åˆ†æEvidenceå¯¹æ¨ç†çš„å½±å“
        print(f"\n3ï¸âƒ£  Evidenceå½±å“åˆ†æ:")
        
        # æ£€æŸ¥Evidenceä¸­æ˜¯å¦åŒ…å«çˆ¶èŠ‚ç‚¹
        relevant_evidence = {}
        irrelevant_evidence = {}
        
        for ev_node, ev_value in evidence.items():
            if ev_node in parents:
                relevant_evidence[ev_node] = ev_value
                print(f"   ğŸ“ ç›¸å…³Evidence: {ev_node}={ev_value} (æ˜¯{target_node}çš„çˆ¶èŠ‚ç‚¹)")
            else:
                irrelevant_evidence[ev_node] = ev_value
                print(f"   ğŸ“„ å…¶ä»–Evidence: {ev_node}={ev_value} (é€šè¿‡ç½‘ç»œé—´æ¥å½±å“)")
        
        if not relevant_evidence:
            print(f"   âš ï¸  æ²¡æœ‰ç›´æ¥ç›¸å…³çš„Evidence (æ— çˆ¶èŠ‚ç‚¹åœ¨Evidenceä¸­)")
        
        # 4. æ‰§è¡Œæ¨ç†
        print(f"\n4ï¸âƒ£  æ‰§è¡Œæ¨ç†:")
        
        try:
            # è°ƒç”¨pgmpyæ¨ç†
            from pgmpy.inference import VariableElimination
            inference = VariableElimination(self.flood_net.network_bayes)
            
            print(f"   ä½¿ç”¨å˜é‡æ¶ˆé™¤ç®—æ³•è¿›è¡Œæ¨ç†...")
            result = inference.query(variables=[target_node], evidence=evidence)
            
            prob_values = result.values
            prob_not_flooded = prob_values[0]
            prob_flooded = prob_values[1]
            
            print(f"   æ¨ç†ç»“æœ:")
            print(f"     P({target_node}=0 | Evidence) = {prob_not_flooded:.6f}")
            print(f"     P({target_node}=1 | Evidence) = {prob_flooded:.6f}")
            print(f"     æ¦‚ç‡å’Œ: {prob_not_flooded + prob_flooded:.6f}")
            
            # 5. ä¸è¾¹é™…æ¦‚ç‡å¯¹æ¯”
            print(f"\n5ï¸âƒ£  ä¸è¾¹é™…æ¦‚ç‡å¯¹æ¯”:")
            print(f"   è¾¹é™…æ¦‚ç‡ P({target_node}=1): {marginal_prob:.6f}")
            print(f"   æ¡ä»¶æ¦‚ç‡ P({target_node}=1|Evidence): {prob_flooded:.6f}")
            
            if prob_flooded > marginal_prob:
                change = (prob_flooded - marginal_prob) / marginal_prob * 100
                print(f"   ğŸ“ˆ Evidenceä½¿æ´ªæ°´æ¦‚ç‡å¢åŠ äº† {change:.1f}%")
            elif prob_flooded < marginal_prob:
                change = (marginal_prob - prob_flooded) / marginal_prob * 100
                print(f"   ğŸ“‰ Evidenceä½¿æ´ªæ°´æ¦‚ç‡é™ä½äº† {change:.1f}%")
            else:
                print(f"   â¡ï¸  Evidenceå¯¹æ´ªæ°´æ¦‚ç‡æ— å½±å“")
            
            return {
                'prob_not_flooded': prob_not_flooded,
                'prob_flooded': prob_flooded,
                'marginal_prob': marginal_prob,
                'relevant_evidence': relevant_evidence,
                'irrelevant_evidence': irrelevant_evidence
            }
            
        except Exception as e:
            print(f"   âŒ æ¨ç†å¤±è´¥: {e}")
            return None
    
    def debug_test_day_evaluation(self, date_str=None, max_examples=3):
        """è°ƒè¯•æµ‹è¯•æ—¥çš„è¯„ä¼°è¿‡ç¨‹"""
        print(f"\n\nğŸ—“ï¸  æµ‹è¯•æ—¥è¯„ä¼°è¿‡ç¨‹è°ƒè¯•")
        print("=" * 60)
        
        # æŒ‰æ—¥æœŸåˆ†ç»„æµ‹è¯•æ•°æ®
        test_by_date = self.test_df.groupby(self.test_df["time_create"].dt.floor("D"))
        
        if date_str:
            # è°ƒè¯•ç‰¹å®šæ—¥æœŸ
            target_date = pd.to_datetime(date_str).floor("D")
            day_groups = [(date, group) for date, group in test_by_date if date == target_date]
        else:
            # è°ƒè¯•å‰å‡ å¤©
            day_groups = list(test_by_date)[:max_examples]
        
        for i, (date, day_group) in enumerate(day_groups):
            print(f"\nğŸ“… æ—¥æœŸ: {date.date()} (ç¤ºä¾‹ {i+1})")
            print("-" * 40)
            
            # å½“å¤©æ´ªæ°´é“è·¯
            flooded_roads = list(day_group["link_id"].unique())
            flooded_in_bn = [road for road in flooded_roads if road in self.bn_nodes]
            
            print(f"åŸå§‹æ´ªæ°´é“è·¯: {len(flooded_roads)}æ¡")
            print(f"ç½‘ç»œä¸­æ´ªæ°´é“è·¯: {len(flooded_in_bn)}æ¡")
            print(f"æ´ªæ°´é“è·¯åˆ—è¡¨: {flooded_roads}")
            print(f"ç½‘ç»œé“è·¯åˆ—è¡¨: {flooded_in_bn}")
            
            if len(flooded_in_bn) < 2:
                print("âš ï¸  å¯ç”¨ç½‘ç»œé“è·¯ä¸è¶³2æ¡ï¼Œè·³è¿‡æ­¤æ—¥æœŸ")
                continue
            
            # Evidenceé€‰æ‹©è¿‡ç¨‹
            evidence_count = max(1, int(len(flooded_in_bn) * 0.5))
            evidence_roads = flooded_in_bn[:evidence_count]
            target_roads = flooded_in_bn[evidence_count:]
            
            print(f"\nEvidenceé€‰æ‹© (å‰{evidence_count}æ¡):")
            for j, road in enumerate(evidence_roads):
                marginal_p = self.marginals_dict.get(road, 0)
                print(f"  {j+1}. {road} (è¾¹é™…P={marginal_p:.3f})")
            
            evidence = {road: 1 for road in evidence_roads}
            
            print(f"\nç›®æ ‡é“è·¯æ¨ç† ({len(target_roads)}æ¡):")
            
            # å¯¹æ¯ä¸ªç›®æ ‡é“è·¯è¿›è¡Œè¯¦ç»†æ¨ç†
            for target_road in target_roads:
                print(f"\n  ğŸ¯ ç›®æ ‡: {target_road}")
                
                # ç®€åŒ–ç‰ˆæ¨ç†è°ƒè¯•
                try:
                    result = self.flood_net.infer_w_evidence(target_road, evidence)
                    prob_flood = result['flooded']
                    
                    # çˆ¶èŠ‚ç‚¹åˆ†æ
                    parents = list(self.flood_net.network.predecessors(target_road))
                    relevant_parents = [p for p in parents if p in evidence]
                    
                    print(f"     çˆ¶èŠ‚ç‚¹: {parents}")
                    print(f"     ç›¸å…³Evidenceçˆ¶èŠ‚ç‚¹: {relevant_parents}")
                    print(f"     æ¨ç†æ¦‚ç‡: P(æ´ªæ°´) = {prob_flood:.6f}")
                    
                    # è¾¹é™…æ¦‚ç‡å¯¹æ¯”
                    marginal_p = self.marginals_dict.get(target_road, 0)
                    print(f"     è¾¹é™…æ¦‚ç‡: P(æ´ªæ°´) = {marginal_p:.6f}")
                    
                    if prob_flood > marginal_p:
                        print(f"     ğŸ“ˆ Evidenceæå‡äº†æ´ªæ°´æ¦‚ç‡")
                    elif prob_flood < marginal_p:
                        print(f"     ğŸ“‰ Evidenceé™ä½äº†æ´ªæ°´æ¦‚ç‡") 
                    else:
                        print(f"     â¡ï¸  Evidenceæ— å½±å“")
                        
                except Exception as e:
                    print(f"     âŒ æ¨ç†å¤±è´¥: {e}")
    
    def debug_negative_sampling(self, date_str=None, max_examples=3):
        """è°ƒè¯•è´Ÿæ ·æœ¬æ„é€ è¿‡ç¨‹"""
        print(f"\n\nğŸš« è´Ÿæ ·æœ¬æ„é€ è¿‡ç¨‹è°ƒè¯•")
        print("=" * 60)
        
        # è·å–ä½æ¦‚ç‡é“è·¯ä½œä¸ºè´Ÿæ ·æœ¬å€™é€‰
        low_prob_roads = [
            road for road, prob in self.marginals_dict.items() 
            if road in self.bn_nodes and prob <= 0.15
        ]
        
        print(f"ä½æ¦‚ç‡è´Ÿæ ·æœ¬å€™é€‰: {len(low_prob_roads)}æ¡")
        print(f"å€™é€‰é“è·¯ (Pâ‰¤0.15): {low_prob_roads[:10]}{'...' if len(low_prob_roads) > 10 else ''}")
        
        # æŒ‰æ—¥æœŸåˆ†ç»„æµ‹è¯•æ•°æ®
        test_by_date = self.test_df.groupby(self.test_df["time_create"].dt.floor("D"))
        
        if date_str:
            target_date = pd.to_datetime(date_str).floor("D")
            day_groups = [(date, group) for date, group in test_by_date if date == target_date]
        else:
            day_groups = list(test_by_date)[:max_examples]
        
        for i, (date, day_group) in enumerate(day_groups):
            print(f"\nğŸ“… æ—¥æœŸ: {date.date()} è´Ÿæ ·æœ¬åˆ†æ")
            print("-" * 40)
            
            flooded_roads = list(day_group["link_id"].unique())
            flooded_in_bn = [road for road in flooded_roads if road in self.bn_nodes]
            
            # å½“å¤©æ²¡æœ‰æ´ªæ°´çš„ä½æ¦‚ç‡é“è·¯
            negative_candidates = [
                road for road in low_prob_roads 
                if road not in flooded_roads
            ]
            
            print(f"å½“å¤©æ´ªæ°´é“è·¯: {flooded_in_bn}")
            print(f"è´Ÿæ ·æœ¬å€™é€‰: {len(negative_candidates)}æ¡")
            
            if len(negative_candidates) > 0:
                # é€‰æ‹©å‰3ä¸ªä½œä¸ºè´Ÿæ ·æœ¬
                selected_negatives = negative_candidates[:3]
                print(f"é€‰ä¸­è´Ÿæ ·æœ¬: {selected_negatives}")
                
                # åˆ†ææ¯ä¸ªè´Ÿæ ·æœ¬
                for neg_road in selected_negatives:
                    marginal_p = self.marginals_dict.get(neg_road, 0)
                    print(f"\n  ğŸš« è´Ÿæ ·æœ¬: {neg_road}")
                    print(f"     è¾¹é™…æ¦‚ç‡: {marginal_p:.6f}")
                    print(f"     é€‰æ‹©ç†ç”±: è¾¹é™…æ¦‚ç‡ä½ï¼Œå½“å¤©æ— æ´ªæ°´è®°å½•")
                    
                    # æŸ¥çœ‹è¿™æ¡é“è·¯åœ¨è®­ç»ƒé›†ä¸­çš„å‡ºç°æƒ…å†µ
                    train_occurrences = len(self.flood_net.marginals[
                        self.flood_net.marginals['link_id'] == neg_road
                    ])
                    if train_occurrences > 0:
                        print(f"     è®­ç»ƒé›†ä¸­: ç¡®å®å­˜åœ¨ä¸”æ¦‚ç‡å¾ˆä½")
                    else:
                        print(f"     è®­ç»ƒé›†ä¸­: æœªå‡ºç°ï¼ˆè¾¹é™…æ¦‚ç‡=0ï¼‰")
            else:
                print("âš ï¸  å½“å¤©æ— åˆé€‚çš„è´Ÿæ ·æœ¬å€™é€‰")
    
    def debug_threshold_decision(self, prob_values, pos_threshold=0.6, neg_threshold=0.3):
        """è°ƒè¯•é˜ˆå€¼å†³ç­–è¿‡ç¨‹"""
        print(f"\n\nğŸšï¸  é˜ˆå€¼å†³ç­–è¿‡ç¨‹è°ƒè¯•")
        print("=" * 60)
        print(f"æ­£é¢„æµ‹é˜ˆå€¼: {pos_threshold}")
        print(f"è´Ÿé¢„æµ‹é˜ˆå€¼: {neg_threshold}")
        print(f"ä¸ç¡®å®šåŒºé—´: ({neg_threshold}, {pos_threshold})")
        
        # åˆ†æä¸€ç³»åˆ—æ¦‚ç‡å€¼
        if not isinstance(prob_values, list):
            prob_values = [prob_values]
        
        decisions = []
        for prob in prob_values:
            if prob >= pos_threshold:
                decision = "æ­£é¢„æµ‹(æ´ªæ°´)"
                confidence = prob
            elif prob <= neg_threshold:
                decision = "è´Ÿé¢„æµ‹(æ— æ´ªæ°´)"
                confidence = 1 - prob
            else:
                decision = "ä¸ç¡®å®š(å¼ƒæƒ)"
                confidence = 0.5
            
            decisions.append((prob, decision, confidence))
            print(f"æ¦‚ç‡={prob:.3f} â†’ {decision} (ç½®ä¿¡åº¦={confidence:.3f})")
        
        return decisions
    
    def comprehensive_inference_demo(self):
        """ç»¼åˆæ¨ç†æ¼”ç¤º"""
        print(f"\n\nğŸ­ ç»¼åˆæ¨ç†æ¼”ç¤º")
        print("=" * 60)
        
        # é€‰æ‹©ä¸€ä¸ªæœ‰ä»£è¡¨æ€§çš„æµ‹è¯•æ—¥
        test_by_date = self.test_df.groupby(self.test_df["time_create"].dt.floor("D"))
        
        # æ‰¾ä¸€ä¸ªæœ‰è¶³å¤Ÿç½‘ç»œé“è·¯çš„æ—¥æœŸ
        target_date = None
        target_group = None
        
        for date, group in test_by_date:
            flooded_roads = list(group["link_id"].unique())
            flooded_in_bn = [road for road in flooded_roads if road in self.bn_nodes]
            
            if len(flooded_in_bn) >= 4:  # éœ€è¦è¶³å¤Ÿçš„é“è·¯è¿›è¡Œæ¼”ç¤º
                target_date = date
                target_group = group
                break
        
        if target_date is None:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„æ¼”ç¤ºæ—¥æœŸ")
            return
        
        print(f"ğŸ¯ æ¼”ç¤ºæ—¥æœŸ: {target_date.date()}")
        
        # æ‰§è¡Œå®Œæ•´çš„æ¨ç†æµç¨‹
        flooded_roads = list(target_group["link_id"].unique())
        flooded_in_bn = [road for road in flooded_roads if road in self.bn_nodes]
        
        print(f"å½“å¤©æ´ªæ°´é“è·¯: {flooded_in_bn}")
        
        # é€‰æ‹©Evidence
        evidence_count = max(1, int(len(flooded_in_bn) * 0.5))
        evidence_roads = flooded_in_bn[:evidence_count]
        target_roads = flooded_in_bn[evidence_count:]
        
        evidence = {road: 1 for road in evidence_roads}
        
        print(f"\n1ï¸âƒ£  Evidenceè®¾ç½®: {evidence}")
        
        # å¯¹ç¬¬ä¸€ä¸ªç›®æ ‡é“è·¯è¿›è¡Œè¯¦ç»†æ¨ç†
        if target_roads:
            target_road = target_roads[0]
            print(f"\n2ï¸âƒ£  è¯¦ç»†æ¨ç†ç›®æ ‡: {target_road}")
            
            # æ‰§è¡Œè¯¦ç»†æ¨ç†
            debug_result = self.debug_single_inference(target_road, evidence)
            
            if debug_result:
                # é˜ˆå€¼å†³ç­–
                prob_flooded = debug_result['prob_flooded']
                print(f"\n3ï¸âƒ£  é˜ˆå€¼å†³ç­–:")
                
                decisions = self.debug_threshold_decision([prob_flooded])
                
                print(f"\n4ï¸âƒ£  æœ€ç»ˆç»“æœ:")
                prob, decision, confidence = decisions[0]
                print(f"   æ¨ç†æ¦‚ç‡: {prob:.6f}")
                print(f"   å†³ç­–ç»“æœ: {decision}")
                print(f"   å†³ç­–ç½®ä¿¡åº¦: {confidence:.6f}")
                print(f"   çœŸå®æ ‡ç­¾: æ´ªæ°´ (å› ä¸ºç›®æ ‡é“è·¯ç¡®å®å‘ç”Ÿäº†æ´ªæ°´)")
                
                # è¯„ä¼°ç»“æœ
                if "æ­£é¢„æµ‹" in decision:
                    print("   âœ… é¢„æµ‹æ­£ç¡® (True Positive)")
                elif "è´Ÿé¢„æµ‹" in decision:
                    print("   âŒ é¢„æµ‹é”™è¯¯ (False Negative)")
                else:
                    print("   â“ ä¸ç¡®å®šé¢„æµ‹ (å¼ƒæƒ)")

def load_test_system():
    """åŠ è½½æµ‹è¯•ç³»ç»Ÿ"""
    # åŠ è½½æ•°æ®
    df = pd.read_csv("Road_Closures_2024.csv")
    df = df[df["REASON"].str.upper() == "FLOOD"].copy()
    
    # é¢„å¤„ç†
    df["time_create"] = pd.to_datetime(df["START"], utc=True)
    df["link_id"] = df["STREET"].str.upper().str.replace(" ", "_")
    df["link_id"] = df["link_id"].astype(str)
    df["id"] = df["OBJECTID"].astype(str)
    
    # æ—¶åºåˆ†å‰²
    df_sorted = df.sort_values('time_create')
    split_idx = int(len(df_sorted) * 0.7)
    train_df = df_sorted.iloc[:split_idx].copy()
    test_df = df_sorted.iloc[split_idx:].copy()
    
    # æ„å»ºç½‘ç»œ
    flood_net = FloodBayesNetwork(t_window="D")
    flood_net.fit_marginal(train_df)
    flood_net.build_network_by_co_occurrence(
        train_df, occ_thr=3, edge_thr=2, weight_thr=0.3, report=False
    )
    flood_net.fit_conditional(train_df, max_parents=2, alpha=1.0)
    flood_net.build_bayes_network()
    
    return flood_net, test_df

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ æ¨ç†è¿‡ç¨‹è°ƒè¯•å™¨")
    print("=" * 60)
    
    # åŠ è½½ç³»ç»Ÿ
    flood_net, test_df = load_test_system()
    
    # åˆ›å»ºè°ƒè¯•å™¨
    debugger = InferenceDebugger(flood_net, test_df)
    
    # 1. æ¼”ç¤ºå•ä¸ªæ¨ç†è¿‡ç¨‹
    print("\nğŸ” å•ä¸ªæ¨ç†è¿‡ç¨‹æ¼”ç¤º:")
    example_evidence = {"HAGOOD_AVE": 1, "WASHINGTON_ST": 1}
    example_target = "RUTLEDGE_AVE"
    
    debugger.debug_single_inference(example_target, example_evidence)
    
    # 2. è°ƒè¯•æµ‹è¯•æ—¥è¯„ä¼°
    debugger.debug_test_day_evaluation(max_examples=2)
    
    # 3. è°ƒè¯•è´Ÿæ ·æœ¬æ„é€ 
    debugger.debug_negative_sampling(max_examples=2)
    
    # 4. ç»¼åˆæ¼”ç¤º
    debugger.comprehensive_inference_demo()
    
    print(f"\n\nâœ… æ¨ç†è¿‡ç¨‹è°ƒè¯•å®Œæˆï¼")
    print(f"ğŸ¯ å…³é”®éªŒè¯ç‚¹:")
    print(f"   âœ“ æ¨ç†ç®—æ³•æ­£ç¡®æ‰§è¡Œ")
    print(f"   âœ“ Evidenceå½±å“è®¡ç®—å‡†ç¡®")
    print(f"   âœ“ é˜ˆå€¼å†³ç­–é€»è¾‘åˆç†")
    print(f"   âœ“ è´Ÿæ ·æœ¬æ„é€ ä¿å®ˆ")
    
    return debugger

if __name__ == "__main__":
    debugger = main()