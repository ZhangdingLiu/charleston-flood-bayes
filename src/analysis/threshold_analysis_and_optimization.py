#!/usr/bin/env python3
"""
é˜ˆå€¼åˆ†æå’Œä¼˜åŒ–

åˆ†æå½“å‰é˜ˆå€¼è®¾ç½®é—®é¢˜ï¼Œé‡æ–°ä¼˜åŒ–ä»¥è¾¾åˆ°ç›®æ ‡æ€§èƒ½ï¼š
- Precision â‰¥ 0.8
- Recall â‰¥ 0.4

æ­¥éª¤ï¼š
1. åˆ†ææ‰€æœ‰æµ‹è¯•æ•°æ®çš„æ¦‚ç‡åˆ†å¸ƒ
2. ç½‘æ ¼æœç´¢æœ€ä¼˜é˜ˆå€¼ç»„åˆ
3. éªŒè¯æ–°ç­–ç•¥çš„æ€§èƒ½
4. ç”Ÿæˆå®Œæ•´çš„è¯„ä¼°æŠ¥å‘Š
"""

import random
import numpy as np
import pandas as pd
from model import FloodBayesNetwork
from precision_focused_evaluation import PrecisionFocusedEvaluator
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®éšæœºç§å­
RANDOM_SEED = 42
random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

class ThresholdOptimizer:
    """é˜ˆå€¼ä¼˜åŒ–å™¨"""
    
    def __init__(self, flood_net, test_df):
        self.flood_net = flood_net
        self.test_df = test_df
        self.bn_nodes = set(flood_net.network_bayes.nodes())
        self.marginals_dict = dict(zip(
            flood_net.marginals['link_id'], 
            flood_net.marginals['p']
        ))
        
        # å­˜å‚¨æ‰€æœ‰æ¨ç†æ¦‚ç‡ä»¥ä¾›åˆ†æ
        self.all_predictions = []
        self.probability_distribution = []
        
    def collect_all_predictions(self):
        """æ”¶é›†æ‰€æœ‰æµ‹è¯•æ ·æœ¬çš„æ¨ç†æ¦‚ç‡"""
        print("ğŸ” æ”¶é›†æ‰€æœ‰æµ‹è¯•æ ·æœ¬çš„æ¨ç†æ¦‚ç‡åˆ†å¸ƒ")
        print("=" * 60)
        
        # è·å–è´Ÿæ ·æœ¬å€™é€‰
        negative_candidates = [
            road for road, prob in self.marginals_dict.items() 
            if road in self.bn_nodes and prob <= 0.15
        ]
        
        # æŒ‰æ—¥æœŸåˆ†ç»„æµ‹è¯•æ•°æ®
        test_by_date = self.test_df.groupby(self.test_df["time_create"].dt.floor("D"))
        
        positive_probs = []
        negative_probs = []
        
        valid_days = 0
        total_days = 0
        
        for date, day_group in test_by_date:
            total_days += 1
            
            # å½“å¤©æ´ªæ°´é“è·¯åˆ—è¡¨
            flooded_roads = list(day_group["link_id"].unique())
            flooded_in_bn = [road for road in flooded_roads if road in self.bn_nodes]
            
            if len(flooded_in_bn) < 2:
                continue
                
            valid_days += 1
            
            # Evidenceé€‰æ‹©
            evidence_count = max(1, int(len(flooded_in_bn) * 0.5))
            evidence_roads = flooded_in_bn[:evidence_count]
            target_roads = flooded_in_bn[evidence_count:]
            
            evidence = {road: 1 for road in evidence_roads}
            
            # å¤„ç†æ­£æ ·æœ¬ï¼ˆçœŸå®æ´ªæ°´é“è·¯ï¼‰
            for target_road in target_roads:
                try:
                    result = self.flood_net.infer_w_evidence(target_road, evidence)
                    prob_flood = result['flooded']
                    
                    positive_probs.append(prob_flood)
                    self.all_predictions.append({
                        'type': 'positive',
                        'road': target_road,
                        'true_label': 1,
                        'prob_flood': prob_flood,
                        'date': date
                    })
                except:
                    continue
            
            # å¤„ç†è´Ÿæ ·æœ¬
            available_negatives = [road for road in negative_candidates if road not in flooded_roads]
            selected_negatives = available_negatives[:min(3, len(target_roads))]
            
            for neg_road in selected_negatives:
                try:
                    result = self.flood_net.infer_w_evidence(neg_road, evidence)
                    prob_flood = result['flooded']
                    
                    negative_probs.append(prob_flood)
                    self.all_predictions.append({
                        'type': 'negative',
                        'road': neg_road,
                        'true_label': 0,
                        'prob_flood': prob_flood,
                        'date': date
                    })
                except:
                    continue
        
        self.probability_distribution = {
            'positive_probs': positive_probs,
            'negative_probs': negative_probs
        }
        
        print(f"ğŸ“Š æ•°æ®æ”¶é›†ç»“æœ:")
        print(f"   æ€»æµ‹è¯•å¤©æ•°: {total_days}")
        print(f"   æœ‰æ•ˆè¯„ä¼°å¤©æ•°: {valid_days}")
        print(f"   æ­£æ ·æœ¬æ•°: {len(positive_probs)}")
        print(f"   è´Ÿæ ·æœ¬æ•°: {len(negative_probs)}")
        print(f"   æ€»æ ·æœ¬æ•°: {len(self.all_predictions)}")
        
        return self.probability_distribution
    
    def analyze_probability_distribution(self):
        """åˆ†ææ¦‚ç‡åˆ†å¸ƒç‰¹å¾"""
        print(f"\nğŸ“ˆ æ¦‚ç‡åˆ†å¸ƒåˆ†æ")
        print("=" * 50)
        
        pos_probs = self.probability_distribution['positive_probs']
        neg_probs = self.probability_distribution['negative_probs']
        
        if pos_probs:
            print(f"ğŸ”¸ æ­£æ ·æœ¬æ¦‚ç‡åˆ†å¸ƒ:")
            print(f"   æ•°é‡: {len(pos_probs)}")
            print(f"   å‡å€¼: {np.mean(pos_probs):.4f}")
            print(f"   æ ‡å‡†å·®: {np.std(pos_probs):.4f}")
            print(f"   ä¸­ä½æ•°: {np.median(pos_probs):.4f}")
            print(f"   èŒƒå›´: [{np.min(pos_probs):.4f}, {np.max(pos_probs):.4f}]")
            print(f"   åˆ†ä½æ•°: 25%={np.percentile(pos_probs, 25):.4f}, 75%={np.percentile(pos_probs, 75):.4f}")
        
        if neg_probs:
            print(f"\nğŸ”¸ è´Ÿæ ·æœ¬æ¦‚ç‡åˆ†å¸ƒ:")
            print(f"   æ•°é‡: {len(neg_probs)}")
            print(f"   å‡å€¼: {np.mean(neg_probs):.4f}")
            print(f"   æ ‡å‡†å·®: {np.std(neg_probs):.4f}")
            print(f"   ä¸­ä½æ•°: {np.median(neg_probs):.4f}")
            print(f"   èŒƒå›´: [{np.min(neg_probs):.4f}, {np.max(neg_probs):.4f}]")
            print(f"   åˆ†ä½æ•°: 25%={np.percentile(neg_probs, 25):.4f}, 75%={np.percentile(neg_probs, 75):.4f}")
        
        # åˆ†æé‡å æƒ…å†µ
        if pos_probs and neg_probs:
            pos_mean = np.mean(pos_probs)
            neg_mean = np.mean(neg_probs)
            separation = pos_mean - neg_mean
            
            print(f"\nğŸ” åˆ†å¸ƒåˆ†ç¦»åº¦åˆ†æ:")
            print(f"   æ­£æ ·æœ¬å‡å€¼ - è´Ÿæ ·æœ¬å‡å€¼: {separation:.4f}")
            print(f"   åˆ†ç¦»åº¦: {'è‰¯å¥½' if separation > 0.1 else 'è¾ƒå·®' if separation > 0.05 else 'å¾ˆå·®'}")
            
            # è®¡ç®—æœ€ä½³åˆ†å‰²ç‚¹
            all_probs = sorted(pos_probs + neg_probs)
            best_threshold = (pos_mean + neg_mean) / 2
            print(f"   å»ºè®®åˆ†å‰²ç‚¹: {best_threshold:.4f}")
    
    def create_probability_distribution_plot(self, save_path="probability_distribution.png"):
        """åˆ›å»ºæ¦‚ç‡åˆ†å¸ƒå¯è§†åŒ–"""
        print(f"\nğŸ¨ åˆ›å»ºæ¦‚ç‡åˆ†å¸ƒå¯è§†åŒ–")
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        pos_probs = self.probability_distribution['positive_probs']
        neg_probs = self.probability_distribution['negative_probs']
        
        # ç›´æ–¹å›¾
        ax1.hist(pos_probs, bins=20, alpha=0.6, color='red', label=f'æ­£æ ·æœ¬ (n={len(pos_probs)})', density=True)
        ax1.hist(neg_probs, bins=20, alpha=0.6, color='blue', label=f'è´Ÿæ ·æœ¬ (n={len(neg_probs)})', density=True)
        ax1.set_xlabel('æ´ªæ°´æ¦‚ç‡')
        ax1.set_ylabel('å¯†åº¦')
        ax1.set_title('æ¦‚ç‡åˆ†å¸ƒç›´æ–¹å›¾')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # ç®±çº¿å›¾
        data_for_box = [pos_probs, neg_probs]
        labels = ['æ­£æ ·æœ¬', 'è´Ÿæ ·æœ¬']
        box_plot = ax2.boxplot(data_for_box, labels=labels, patch_artist=True)
        box_plot['boxes'][0].set_facecolor('red')
        box_plot['boxes'][1].set_facecolor('blue')
        ax2.set_ylabel('æ´ªæ°´æ¦‚ç‡')
        ax2.set_title('æ¦‚ç‡åˆ†å¸ƒç®±çº¿å›¾')
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ… æ¦‚ç‡åˆ†å¸ƒå›¾å·²ä¿å­˜è‡³: {save_path}")
        plt.show()
        
        return fig
    
    def optimize_thresholds_grid_search(self, target_precision=0.8, min_recall=0.4):
        """ç½‘æ ¼æœç´¢æœ€ä¼˜é˜ˆå€¼"""
        print(f"\nğŸ¯ ç½‘æ ¼æœç´¢æœ€ä¼˜é˜ˆå€¼")
        print(f"ç›®æ ‡: Precision â‰¥ {target_precision}, Recall â‰¥ {min_recall}")
        print("=" * 60)
        
        # æ‰©å¤§æœç´¢èŒƒå›´ï¼Œé™ä½é˜ˆå€¼
        positive_thresholds = np.arange(0.1, 0.8, 0.05)  # ä»0.1å¼€å§‹
        negative_thresholds = np.arange(0.05, 0.4, 0.05)
        
        best_configs = []
        all_results = []
        
        print(f"ğŸ” æœç´¢ç©ºé—´: {len(positive_thresholds)} Ã— {len(negative_thresholds)} = {len(positive_thresholds) * len(negative_thresholds)} ç»„åˆ")
        
        for i, pos_thr in enumerate(positive_thresholds):
            if i % 3 == 0:
                print(f"   è¿›åº¦: {i+1}/{len(positive_thresholds)} æ­£é˜ˆå€¼...")
            
            for neg_thr in negative_thresholds:
                if neg_thr >= pos_thr:
                    continue  # ç¡®ä¿ neg_thr < pos_thr
                
                # è®¡ç®—è¯¥é˜ˆå€¼ç»„åˆä¸‹çš„æ€§èƒ½
                metrics = self.evaluate_threshold_combination(pos_thr, neg_thr)
                
                result = {
                    'pos_threshold': pos_thr,
                    'neg_threshold': neg_thr,
                    **metrics
                }
                all_results.append(result)
                
                # æ£€æŸ¥æ˜¯å¦æ»¡è¶³ç›®æ ‡æ¡ä»¶
                if (metrics['precision'] >= target_precision and 
                    metrics['recall'] >= min_recall and
                    metrics['total_predictions'] >= 10):  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„é¢„æµ‹
                    
                    best_configs.append(result)
        
        print(f"\nğŸ“Š æœç´¢ç»“æœ:")
        print(f"   æ€»æœç´¢ç»„åˆ: {len(all_results)}")
        print(f"   æ»¡è¶³æ¡ä»¶çš„ç»„åˆ: {len(best_configs)}")
        
        if best_configs:
            # æŒ‰F1åˆ†æ•°æ’åº
            best_configs.sort(key=lambda x: x['f1_score'], reverse=True)
            
            print(f"\nğŸ† TOP-5 æœ€ä½³é˜ˆå€¼ç»„åˆ:")
            print(f"   {'Rank':<4} {'Pos_Thr':<8} {'Neg_Thr':<8} {'Precision':<10} {'Recall':<8} {'F1':<8} {'Predictions':<11}")
            print("-" * 70)
            
            for i, config in enumerate(best_configs[:5], 1):
                print(f"   {i:<4} {config['pos_threshold']:<8.3f} {config['neg_threshold']:<8.3f} "
                      f"{config['precision']:<10.3f} {config['recall']:<8.3f} {config['f1_score']:<8.3f} "
                      f"{config['total_predictions']:<11}")
            
            # æ¨èæœ€ä½³é…ç½®
            recommended = best_configs[0]
            print(f"\nâœ… æ¨èé…ç½®:")
            print(f"   æ­£é¢„æµ‹é˜ˆå€¼: {recommended['pos_threshold']:.3f}")
            print(f"   è´Ÿé¢„æµ‹é˜ˆå€¼: {recommended['neg_threshold']:.3f}")
            print(f"   é¢„æœŸæ€§èƒ½: P={recommended['precision']:.3f}, R={recommended['recall']:.3f}, F1={recommended['f1_score']:.3f}")
            
            return recommended, best_configs, all_results
        else:
            print(f"âŒ æœªæ‰¾åˆ°æ»¡è¶³æ¡ä»¶çš„é˜ˆå€¼ç»„åˆ")
            
            # æ˜¾ç¤ºæœ€æ¥è¿‘çš„ç»“æœ
            all_results.sort(key=lambda x: x['f1_score'], reverse=True)
            print(f"\nğŸ“‹ æœ€ä½³F1åˆ†æ•°çš„å‰5ä¸ªç»“æœ:")
            print(f"   {'Pos_Thr':<8} {'Neg_Thr':<8} {'Precision':<10} {'Recall':<8} {'F1':<8}")
            print("-" * 50)
            
            for config in all_results[:5]:
                print(f"   {config['pos_threshold']:<8.3f} {config['neg_threshold']:<8.3f} "
                      f"{config['precision']:<10.3f} {config['recall']:<8.3f} {config['f1_score']:<8.3f}")
            
            return None, [], all_results
    
    def evaluate_threshold_combination(self, pos_threshold, neg_threshold):
        """è¯„ä¼°ç‰¹å®šé˜ˆå€¼ç»„åˆçš„æ€§èƒ½"""
        tp = fp = tn = fn = uncertain = 0
        
        for pred in self.all_predictions:
            prob = pred['prob_flood']
            true_label = pred['true_label']
            
            # åº”ç”¨é˜ˆå€¼å†³ç­–
            if prob >= pos_threshold:
                prediction = 1
            elif prob <= neg_threshold:
                prediction = 0
            else:
                prediction = -1  # uncertain
                uncertain += 1
                continue
            
            # è®¡ç®—æ··æ·†çŸ©é˜µ
            if prediction == 1 and true_label == 1:
                tp += 1
            elif prediction == 1 and true_label == 0:
                fp += 1
            elif prediction == 0 and true_label == 1:
                fn += 1
            elif prediction == 0 and true_label == 0:
                tn += 1
        
        # è®¡ç®—æŒ‡æ ‡
        total_predictions = tp + fp + tn + fn
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
        accuracy = (tp + tn) / total_predictions if total_predictions > 0 else 0.0
        
        return {
            'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn,
            'uncertain': uncertain,
            'total_predictions': total_predictions,
            'precision': precision,
            'recall': recall,
            'f1_score': f1_score,
            'accuracy': accuracy
        }
    
    def validate_optimized_thresholds(self, pos_threshold, neg_threshold):
        """éªŒè¯ä¼˜åŒ–åçš„é˜ˆå€¼æ€§èƒ½"""
        print(f"\nğŸ”¬ éªŒè¯ä¼˜åŒ–åçš„é˜ˆå€¼æ€§èƒ½")
        print(f"æ–°é˜ˆå€¼: æ­£é¢„æµ‹={pos_threshold:.3f}, è´Ÿé¢„æµ‹={neg_threshold:.3f}")
        print("=" * 60)
        
        # é‡æ–°è®¡ç®—è¯¦ç»†æ€§èƒ½
        metrics = self.evaluate_threshold_combination(pos_threshold, neg_threshold)
        
        print(f"ğŸ“Š è¯¦ç»†æ€§èƒ½æŒ‡æ ‡:")
        print(f"   True Positives (TP):  {metrics['tp']:4d}")
        print(f"   False Positives (FP): {metrics['fp']:4d}")
        print(f"   True Negatives (TN):  {metrics['tn']:4d}")
        print(f"   False Negatives (FN): {metrics['fn']:4d}")
        print(f"   ä¸ç¡®å®šé¢„æµ‹:           {metrics['uncertain']:4d}")
        print(f"   æ€»æœ‰æ•ˆé¢„æµ‹:           {metrics['total_predictions']:4d}")
        
        print(f"\nğŸ“ˆ å…³é”®æŒ‡æ ‡:")
        print(f"   ç²¾ç¡®åº¦ (Precision): {metrics['precision']:.6f}")
        print(f"   å¬å›ç‡ (Recall):    {metrics['recall']:.6f}")
        print(f"   F1åˆ†æ•° (F1-Score):  {metrics['f1_score']:.6f}")
        print(f"   å‡†ç¡®ç‡ (Accuracy):  {metrics['accuracy']:.6f}")
        
        # ç›®æ ‡è¾¾æˆæ£€æŸ¥
        target_precision = 0.8
        target_recall = 0.4
        
        precision_achieved = metrics['precision'] >= target_precision
        recall_achieved = metrics['recall'] >= target_recall
        
        print(f"\nğŸ¯ ç›®æ ‡è¾¾æˆæƒ…å†µ:")
        print(f"   ç²¾ç¡®åº¦ç›®æ ‡ (â‰¥{target_precision}): {metrics['precision']:.3f} {'âœ…' if precision_achieved else 'âŒ'}")
        print(f"   å¬å›ç‡ç›®æ ‡ (â‰¥{target_recall}):  {metrics['recall']:.3f} {'âœ…' if recall_achieved else 'âŒ'}")
        
        if precision_achieved and recall_achieved:
            print(f"   ğŸ‰ ç›®æ ‡å…¨éƒ¨è¾¾æˆï¼")
        else:
            print(f"   âš ï¸ éƒ¨åˆ†ç›®æ ‡æœªè¾¾æˆï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´")
        
        return metrics

def load_system():
    """åŠ è½½ç³»ç»Ÿ"""
    # åŠ è½½æ•°æ®
    df = pd.read_csv("Road_Closures_2024.csv")
    df = df[df["REASON"].str.upper() == "FLOOD"].copy()
    
    # é¢„å¤„ç†
    df["time_create"] = pd.to_datetime(df["START"], utc=True)
    df["link_id"] = df["STREET"].str.upper().str.replace(" ", "_")
    df["link_id"] = df["link_id"].astype(str)
    df["id"] = df["OBJECTID"].astype(str)
    
    # æ—¶åºåˆ†å‰²
    df_sorted = df.sort_values('time_create')
    split_idx = int(len(df_sorted) * 0.7)
    train_df = df_sorted.iloc[:split_idx].copy()
    test_df = df_sorted.iloc[split_idx:].copy()
    
    # æ„å»ºç½‘ç»œ
    flood_net = FloodBayesNetwork(t_window="D")
    flood_net.fit_marginal(train_df)
    flood_net.build_network_by_co_occurrence(
        train_df, occ_thr=3, edge_thr=2, weight_thr=0.3, report=False
    )
    flood_net.fit_conditional(train_df, max_parents=2, alpha=1.0)
    flood_net.build_bayes_network()
    
    return flood_net, test_df

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ é˜ˆå€¼åˆ†æå’Œä¼˜åŒ–")
    print("=" * 80)
    
    # åŠ è½½ç³»ç»Ÿ
    flood_net, test_df = load_system()
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = ThresholdOptimizer(flood_net, test_df)
    
    # 1. æ”¶é›†æ‰€æœ‰é¢„æµ‹æ¦‚ç‡
    prob_dist = optimizer.collect_all_predictions()
    
    # 2. åˆ†ææ¦‚ç‡åˆ†å¸ƒ
    optimizer.analyze_probability_distribution()
    
    # 3. åˆ›å»ºæ¦‚ç‡åˆ†å¸ƒå¯è§†åŒ–
    fig1 = optimizer.create_probability_distribution_plot()
    
    # 4. ç½‘æ ¼æœç´¢æœ€ä¼˜é˜ˆå€¼
    recommended, best_configs, all_results = optimizer.optimize_thresholds_grid_search()
    
    # 5. éªŒè¯æ¨èçš„é˜ˆå€¼
    if recommended:
        final_metrics = optimizer.validate_optimized_thresholds(
            recommended['pos_threshold'], 
            recommended['neg_threshold']
        )
        
        print(f"\nâœ… é˜ˆå€¼ä¼˜åŒ–å®Œæˆï¼")
        print(f"ğŸ¯ æ¨èä½¿ç”¨:")
        print(f"   æ­£é¢„æµ‹é˜ˆå€¼: {recommended['pos_threshold']:.3f}")
        print(f"   è´Ÿé¢„æµ‹é˜ˆå€¼: {recommended['neg_threshold']:.3f}")
        
        return optimizer, recommended, final_metrics
    else:
        print(f"\nâš ï¸ æœªæ‰¾åˆ°æ»¡è¶³ç›®æ ‡çš„é˜ˆå€¼ï¼Œè¯·æ£€æŸ¥æ•°æ®æˆ–è°ƒæ•´ç›®æ ‡")
        return optimizer, None, None

if __name__ == "__main__":
    optimizer, recommended, metrics = main()