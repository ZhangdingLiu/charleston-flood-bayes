#!/usr/bin/env python3
"""
Parameter Analysis Visualizer
å‚æ•°åˆ†æå¯è§†åŒ–æ¨¡å—

ä¸ºè´å¶æ–¯ç½‘ç»œæ´ªæ°´é¢„æµ‹æ¨¡å‹çš„å‚æ•°ä¼˜åŒ–ç»“æœåˆ›å»ºå„ç§å¯è§†åŒ–å›¾è¡¨

ä½œè€…ï¼šClaude AI
æ—¥æœŸï¼š2025-01-21
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.patches import Rectangle
import warnings
import os
import sys
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.patches as mpatches
warnings.filterwarnings('ignore')

# ç¡®ä¿sklearnå¯ç”¨
try:
    from sklearn.preprocessing import MinMaxScaler, StandardScaler
except ImportError:
    print("âš ï¸ sklearnæœªå®‰è£…ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½å—é™")
    MinMaxScaler = None
    StandardScaler = None

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“å’Œæ ·å¼
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['font.size'] = 10

class ParameterVisualizer:
    """å‚æ•°åˆ†æå¯è§†åŒ–å™¨"""
    
    def __init__(self, results_df, output_dir="visualizations"):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å™¨
        
        Args:
            results_df (pd.DataFrame): å‚æ•°æœç´¢ç»“æœDataFrame
            output_dir (str): è¾“å‡ºç›®å½•
        """
        self.df = results_df.copy()
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # è®¾ç½®é…è‰²æ–¹æ¡ˆ
        self.colors = {
            'primary': '#2E86AB',
            'secondary': '#A23B72', 
            'accent': '#F18F01',
            'success': '#C73E1D',
            'light': '#F5F5F5',
            'dark': '#333333'
        }
        
    def create_3d_performance_scatter(self, save_name="precision_recall_f1_3d.png"):
        """åˆ›å»º3Dæ€§èƒ½æ•£ç‚¹å›¾ (Precision vs Recall vs F1)"""
        print("ğŸ¨ åˆ›å»º3Dæ€§èƒ½æ•£ç‚¹å›¾...")
        
        fig = plt.figure(figsize=(12, 9))
        ax = fig.add_subplot(111, projection='3d')
        
        # åˆ›å»ºé¢œè‰²æ˜ å°„ - æ ¹æ®F1åˆ†æ•°ä¸Šè‰²
        scatter = ax.scatter(
            self.df['precision'], 
            self.df['recall'], 
            self.df['f1_score'],
            c=self.df['f1_score'], 
            cmap='viridis',
            alpha=0.7,
            s=50
        )
        
        # è®¾ç½®æ ‡ç­¾å’Œæ ‡é¢˜
        ax.set_xlabel('Precision', fontsize=12, labelpad=10)
        ax.set_ylabel('Recall', fontsize=12, labelpad=10)
        ax.set_zlabel('F1 Score', fontsize=12, labelpad=10)
        ax.set_title('Parameter Performance 3D Distribution\n(Precision vs Recall vs F1)', 
                     fontsize=14, pad=20)
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(scatter, ax=ax, shrink=0.8, aspect=30, pad=0.1)
        cbar.set_label('F1 Score', fontsize=10)
        
        # æ·»åŠ ç½‘æ ¼
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬æ¡†
        stats_text = f"Total Combinations: {len(self.df)}\n"
        stats_text += f"Best F1: {self.df['f1_score'].max():.3f}\n"
        stats_text += f"Best Precision: {self.df['precision'].max():.3f}\n"
        stats_text += f"Best Recall: {self.df['recall'].max():.3f}"
        
        ax.text2D(0.02, 0.98, stats_text, transform=ax.transAxes, 
                 verticalalignment='top', bbox=dict(boxstyle='round', 
                 facecolor='white', alpha=0.8), fontsize=9)
        
        plt.tight_layout()
        save_path = os.path.join(self.output_dir, save_name)
        plt.savefig(save_path, bbox_inches='tight')
        plt.close()
        print(f"âœ… 3Dæ•£ç‚¹å›¾å·²ä¿å­˜: {save_path}")
        
    def create_parameter_heatmaps(self, save_name="parameter_heatmaps.png"):
        """åˆ›å»ºå‚æ•°ç»„åˆæ€§èƒ½çƒ­å›¾"""
        print("ğŸ¨ åˆ›å»ºå‚æ•°çƒ­å›¾...")
        
        # é€‰æ‹©ä¸»è¦çš„ç½‘ç»œæ„å»ºå‚æ•°è¿›è¡Œçƒ­å›¾æ˜¾ç¤º
        param_pairs = [
            ('occ_thr', 'edge_thr'),
            ('occ_thr', 'weight_thr'),
            ('evidence_count', 'pred_threshold'),
            ('neg_pos_ratio', 'marginal_prob_threshold')
        ]
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        axes = axes.ravel()
        
        for idx, (param1, param2) in enumerate(param_pairs):
            ax = axes[idx]
            
            # åˆ›å»ºæ•°æ®é€è§†è¡¨
            pivot_data = self.df.pivot_table(
                values='f1_score', 
                index=param1, 
                columns=param2, 
                aggfunc='mean'
            )
            
            # åˆ›å»ºçƒ­å›¾
            sns.heatmap(
                pivot_data, 
                annot=True, 
                fmt='.3f', 
                cmap='YlOrRd',
                cbar_kws={'label': 'F1 Score'},
                ax=ax,
                square=True
            )
            
            ax.set_title(f'F1 Score Heatmap: {param1} vs {param2}', fontsize=12)
            ax.set_xlabel(param2.replace('_', ' ').title(), fontsize=10)
            ax.set_ylabel(param1.replace('_', ' ').title(), fontsize=10)
        
        plt.suptitle('Parameter Combination Performance Heatmaps', fontsize=16, y=0.98)
        plt.tight_layout()
        plt.subplots_adjust(top=0.93)
        
        save_path = os.path.join(self.output_dir, save_name)
        plt.savefig(save_path, bbox_inches='tight')
        plt.close()
        print(f"âœ… å‚æ•°çƒ­å›¾å·²ä¿å­˜: {save_path}")
        
    def create_parameter_sensitivity_analysis(self, save_name="parameter_sensitivity.png"):
        """åˆ›å»ºå‚æ•°æ•æ„Ÿæ€§åˆ†æå›¾"""
        print("ğŸ¨ åˆ›å»ºå‚æ•°æ•æ„Ÿæ€§åˆ†æå›¾...")
        
        # è¯†åˆ«éœ€è¦åˆ†æçš„å‚æ•°
        numeric_params = ['occ_thr', 'edge_thr', 'weight_thr', 'evidence_count', 
                         'pred_threshold', 'neg_pos_ratio', 'marginal_prob_threshold']
        
        fig, axes = plt.subplots(3, 3, figsize=(18, 15))
        axes = axes.ravel()
        
        for idx, param in enumerate(numeric_params):
            if idx >= len(axes):
                break
                
            ax = axes[idx]
            
            # æŒ‰å‚æ•°å€¼åˆ†ç»„ï¼Œè®¡ç®—å¹³å‡æ€§èƒ½
            param_performance = self.df.groupby(param).agg({
                'f1_score': ['mean', 'std'],
                'precision': 'mean',
                'recall': 'mean'
            }).round(4)
            
            param_performance.columns = ['f1_mean', 'f1_std', 'precision_mean', 'recall_mean']
            param_performance = param_performance.reset_index()
            
            # ç»˜åˆ¶F1åˆ†æ•°åŠå…¶æ ‡å‡†å·®
            ax.errorbar(
                param_performance[param], 
                param_performance['f1_mean'],
                yerr=param_performance['f1_std'],
                marker='o', 
                linewidth=2,
                capsize=5,
                capthick=2,
                label='F1 Score Â± Std',
                color=self.colors['primary']
            )
            
            # ç»˜åˆ¶ç²¾ç¡®åº¦å’Œå¬å›ç‡
            ax.plot(param_performance[param], param_performance['precision_mean'], 
                   'o--', label='Precision', color=self.colors['accent'], alpha=0.8)
            ax.plot(param_performance[param], param_performance['recall_mean'], 
                   's--', label='Recall', color=self.colors['secondary'], alpha=0.8)
            
            ax.set_xlabel(param.replace('_', ' ').title(), fontsize=10)
            ax.set_ylabel('Performance Score', fontsize=10)
            ax.set_title(f'Sensitivity Analysis: {param.replace("_", " ").title()}', fontsize=11)
            ax.legend(fontsize=8)
            ax.grid(True, alpha=0.3)
            
        # ç§»é™¤å¤šä½™çš„å­å›¾
        for idx in range(len(numeric_params), len(axes)):
            axes[idx].remove()
        
        plt.suptitle('Parameter Sensitivity Analysis', fontsize=16, y=0.98)
        plt.tight_layout()
        plt.subplots_adjust(top=0.93)
        
        save_path = os.path.join(self.output_dir, save_name)
        plt.savefig(save_path, bbox_inches='tight')
        plt.close()
        print(f"âœ… å‚æ•°æ•æ„Ÿæ€§åˆ†æå›¾å·²ä¿å­˜: {save_path}")
        
    def create_pareto_frontier_analysis(self, save_name="pareto_frontier.png"):
        """åˆ›å»ºParetoå‰æ²¿åˆ†æ (Precision vs Recallæƒè¡¡)"""
        print("ğŸ¨ åˆ›å»ºParetoå‰æ²¿åˆ†æå›¾...")
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))
        
        # å·¦å›¾: Precision vs Recallæ•£ç‚¹å›¾
        scatter = ax1.scatter(
            self.df['recall'], 
            self.df['precision'],
            c=self.df['f1_score'], 
            cmap='viridis',
            alpha=0.7,
            s=50
        )
        
        ax1.set_xlabel('Recall', fontsize=12)
        ax1.set_ylabel('Precision', fontsize=12)
        ax1.set_title('Precision vs Recall Trade-off', fontsize=14)
        ax1.grid(True, alpha=0.3)
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar1 = plt.colorbar(scatter, ax=ax1)
        cbar1.set_label('F1 Score', fontsize=10)
        
        # æ·»åŠ ç­‰F1çº¿
        recall_range = np.linspace(0, 1, 100)
        f1_levels = [0.5, 0.6, 0.7, 0.8, 0.9]
        
        for f1 in f1_levels:
            if f1 > 0:
                precision_line = f1 * recall_range / (2 * recall_range - f1)
                # åªç»˜åˆ¶æœ‰æ•ˆèŒƒå›´å†…çš„çº¿
                valid_mask = (precision_line >= 0) & (precision_line <= 1) & (recall_range > f1/2)
                if np.any(valid_mask):
                    ax1.plot(recall_range[valid_mask], precision_line[valid_mask], 
                            '--', alpha=0.5, color='gray', linewidth=1)
                    
                    # æ·»åŠ F1æ ‡ç­¾
                    if np.any(valid_mask):
                        mid_idx = len(recall_range[valid_mask]) // 2
                        if mid_idx < len(recall_range[valid_mask]) and mid_idx < len(precision_line[valid_mask]):
                            ax1.text(recall_range[valid_mask][mid_idx], 
                                   precision_line[valid_mask][mid_idx] + 0.02, 
                                   f'F1={f1}', fontsize=8, alpha=0.7)
        
        # å³å›¾: æŒ‰çº¦æŸæ¡ä»¶ç­›é€‰çš„ç»“æœ
        # å®šä¹‰å‡ ä¸ªå¸¸è§çš„çº¦æŸæ¡ä»¶
        constraints = [
            {'name': 'High Precision (â‰¥0.8)', 'condition': self.df['precision'] >= 0.8, 'color': self.colors['success']},
            {'name': 'High Recall (â‰¥0.8)', 'condition': self.df['recall'] >= 0.8, 'color': self.colors['accent']},
            {'name': 'Balanced (Pâ‰¥0.7, Râ‰¥0.7)', 'condition': (self.df['precision'] >= 0.7) & (self.df['recall'] >= 0.7), 'color': self.colors['primary']},
            {'name': 'High F1 (â‰¥0.8)', 'condition': self.df['f1_score'] >= 0.8, 'color': self.colors['secondary']}
        ]
        
        for constraint in constraints:
            filtered_df = self.df[constraint['condition']]
            if len(filtered_df) > 0:
                ax2.scatter(
                    filtered_df['recall'], 
                    filtered_df['precision'],
                    label=f"{constraint['name']} (n={len(filtered_df)})",
                    alpha=0.7,
                    color=constraint['color'],
                    s=60
                )
        
        ax2.set_xlabel('Recall', fontsize=12)
        ax2.set_ylabel('Precision', fontsize=12)
        ax2.set_title('Configurations by Performance Constraints', fontsize=14)
        ax2.legend(fontsize=9)
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        save_path = os.path.join(self.output_dir, save_name)
        plt.savefig(save_path, bbox_inches='tight')
        plt.close()
        print(f"âœ… Paretoå‰æ²¿åˆ†æå›¾å·²ä¿å­˜: {save_path}")
        
    def create_constraint_filtering_visualization(self, constraints, save_name="constraint_filtering.png"):
        """åˆ›å»ºçº¦æŸæ¡ä»¶ç­›é€‰å¯è§†åŒ–"""
        print("ğŸ¨ åˆ›å»ºçº¦æŸæ¡ä»¶ç­›é€‰å¯è§†åŒ–...")
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # åº”ç”¨çº¦æŸæ¡ä»¶
        constraint_mask = pd.Series([True] * len(self.df), index=self.df.index)
        
        if 'min_precision' in constraints:
            constraint_mask &= (self.df['precision'] >= constraints['min_precision'])
        if 'min_recall' in constraints:
            constraint_mask &= (self.df['recall'] >= constraints['min_recall'])
        if 'min_f1_score' in constraints:
            constraint_mask &= (self.df['f1_score'] >= constraints['min_f1_score'])
        if 'min_samples' in constraints:
            constraint_mask &= (self.df['total_samples'] >= constraints['min_samples'])
        
        filtered_df = self.df[constraint_mask]
        excluded_df = self.df[~constraint_mask]
        
        # å›¾1: çº¦æŸå‰åå¯¹æ¯”æ•£ç‚¹å›¾
        ax1.scatter(excluded_df['recall'], excluded_df['precision'], 
                   alpha=0.3, color='lightgray', s=30, label=f'Excluded (n={len(excluded_df)})')
        ax1.scatter(filtered_df['recall'], filtered_df['precision'], 
                   alpha=0.8, color=self.colors['primary'], s=60, label=f'Satisfying Constraints (n={len(filtered_df)})')
        
        ax1.set_xlabel('Recall', fontsize=12)
        ax1.set_ylabel('Precision', fontsize=12)
        ax1.set_title('Constraint Filtering Results', fontsize=14)
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # æ·»åŠ çº¦æŸçº¿
        if 'min_precision' in constraints:
            ax1.axhline(y=constraints['min_precision'], color='red', linestyle='--', 
                       alpha=0.7, label=f"Min Precision = {constraints['min_precision']}")
        if 'min_recall' in constraints:
            ax1.axvline(x=constraints['min_recall'], color='red', linestyle='--', 
                       alpha=0.7, label=f"Min Recall = {constraints['min_recall']}")
        
        # å›¾2: F1åˆ†æ•°åˆ†å¸ƒå¯¹æ¯”
        bins = np.linspace(0, 1, 20)
        ax2.hist(self.df['f1_score'], bins=bins, alpha=0.5, color='lightgray', 
                label=f'All Configurations (n={len(self.df)})', density=True)
        if len(filtered_df) > 0:
            ax2.hist(filtered_df['f1_score'], bins=bins, alpha=0.8, 
                    color=self.colors['primary'], label=f'Satisfying Constraints (n={len(filtered_df)})', density=True)
        
        ax2.set_xlabel('F1 Score', fontsize=12)
        ax2.set_ylabel('Density', fontsize=12)
        ax2.set_title('F1 Score Distribution', fontsize=14)
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # å›¾3: å‚æ•°åˆ†å¸ƒæ¯”è¾ƒ (é€‰æ‹©å‡ ä¸ªå…³é”®å‚æ•°)
        key_params = ['occ_thr', 'pred_threshold', 'evidence_count']
        
        for i, param in enumerate(key_params):
            if i >= 1:  # åªæ˜¾ç¤ºä¸€ä¸ªå‚æ•°çš„åˆ†å¸ƒ
                break
                
            param_counts_all = self.df[param].value_counts().sort_index()
            param_counts_filtered = filtered_df[param].value_counts().sort_index() if len(filtered_df) > 0 else pd.Series()
            
            x_pos = np.arange(len(param_counts_all))
            ax3.bar(x_pos - 0.2, param_counts_all.values, width=0.4, 
                   alpha=0.6, color='lightgray', label='All Configurations')
            
            if len(param_counts_filtered) > 0:
                # ç¡®ä¿ç´¢å¼•å¯¹é½
                filtered_values = [param_counts_filtered.get(idx, 0) for idx in param_counts_all.index]
                ax3.bar(x_pos + 0.2, filtered_values, width=0.4, 
                       alpha=0.8, color=self.colors['primary'], label='Satisfying Constraints')
            
            ax3.set_xlabel(f'{param.replace("_", " ").title()}', fontsize=12)
            ax3.set_ylabel('Count', fontsize=12)
            ax3.set_title(f'{param.replace("_", " ").title()} Distribution', fontsize=14)
            ax3.set_xticks(x_pos)
            ax3.set_xticklabels(param_counts_all.index)
            ax3.legend()
            ax3.grid(True, alpha=0.3)
        
        # å›¾4: çº¦æŸæ»¡è¶³æƒ…å†µæ€»ç»“
        constraint_info = []
        if 'min_precision' in constraints:
            precision_satisfied = (self.df['precision'] >= constraints['min_precision']).sum()
            constraint_info.append(f"Precision â‰¥ {constraints['min_precision']}: {precision_satisfied}/{len(self.df)} ({precision_satisfied/len(self.df)*100:.1f}%)")
        
        if 'min_recall' in constraints:
            recall_satisfied = (self.df['recall'] >= constraints['min_recall']).sum()
            constraint_info.append(f"Recall â‰¥ {constraints['min_recall']}: {recall_satisfied}/{len(self.df)} ({recall_satisfied/len(self.df)*100:.1f}%)")
        
        if 'min_f1_score' in constraints:
            f1_satisfied = (self.df['f1_score'] >= constraints['min_f1_score']).sum()
            constraint_info.append(f"F1 Score â‰¥ {constraints['min_f1_score']}: {f1_satisfied}/{len(self.df)} ({f1_satisfied/len(self.df)*100:.1f}%)")
        
        constraint_info.append(f"\nAll constraints satisfied: {len(filtered_df)}/{len(self.df)} ({len(filtered_df)/len(self.df)*100:.1f}%)")
        
        ax4.text(0.1, 0.7, '\n'.join(constraint_info), transform=ax4.transAxes, 
                fontsize=11, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))
        
        ax4.set_title('Constraint Satisfaction Summary', fontsize=14)
        ax4.axis('off')
        
        plt.tight_layout()
        save_path = os.path.join(self.output_dir, save_name)
        plt.savefig(save_path, bbox_inches='tight')
        plt.close()
        print(f"âœ… çº¦æŸæ¡ä»¶ç­›é€‰å¯è§†åŒ–å·²ä¿å­˜: {save_path}")
        
        return filtered_df
    
    def generate_all_visualizations(self, constraints=None):
        """ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨"""
        print("ğŸ¨ å¼€å§‹ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨...")
        print("=" * 60)
        
        # åŸºç¡€æ€§èƒ½å¯è§†åŒ–
        self.create_3d_performance_scatter()
        self.create_parameter_heatmaps()
        self.create_parameter_sensitivity_analysis()
        self.create_pareto_frontier_analysis()
        
        # å¦‚æœæä¾›äº†çº¦æŸæ¡ä»¶ï¼Œåˆ›å»ºçº¦æŸç­›é€‰å¯è§†åŒ–
        filtered_df = None
        if constraints:
            filtered_df = self.create_constraint_filtering_visualization(constraints)
        
        print("=" * 60)
        print("ğŸ‰ æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆï¼")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        
        return filtered_df

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºç”¨æ³•"""
    # è¿™é‡Œåº”è¯¥åŠ è½½çœŸå®çš„ç»“æœæ•°æ®
    print("âš ï¸ è¿™æ˜¯å¯è§†åŒ–æ¨¡å—çš„æ¼”ç¤ºå‡½æ•°")
    print("å®é™…ä½¿ç”¨æ—¶ï¼Œè¯·é€šè¿‡ run_parameter_optimization.py è°ƒç”¨")
    
    # æ¼”ç¤ºçº¦æŸæ¡ä»¶
    demo_constraints = {
        'min_precision': 0.8,
        'min_recall': 0.6,
        'min_f1_score': 0.7,
        'min_samples': 30
    }
    
    print(f"æ¼”ç¤ºçº¦æŸæ¡ä»¶: {demo_constraints}")

if __name__ == "__main__":
    main()