#!/usr/bin/env python3
"""
æ¯”è¾ƒè¯„ä¼°ç­–ç•¥ï¼šç²¾ç¡®åº¦ä¼˜å…ˆ vs ä¼ ç»Ÿæ´ªæ°´æ¨ç†

å¯¹æ¯”ä¸¤ç§è¯„ä¼°æ–¹æ³•ï¼š
1. ä¼ ç»Ÿflood-onlyç­–ç•¥ (test_improved_eval.py)
2. æ–°çš„precision-focusedç­–ç•¥ (precision_focused_evaluation.py)
"""

import random
import numpy as np
import pandas as pd
from model import FloodBayesNetwork
from precision_focused_evaluation import PrecisionFocusedEvaluator

# è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§
RANDOM_SEED = 42
random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

def traditional_flood_only_evaluation(flood_net, test_df, prob_thr=0.5):
    """
    ä¼ ç»Ÿçš„flood-onlyè¯„ä¼°ç­–ç•¥ï¼ˆæ¥è‡ªtest_improved_eval.pyï¼‰
    """
    bn_nodes = set(flood_net.network_bayes.nodes())
    
    all_predictions = []
    all_true_labels = []
    evaluated_days = 0
    
    # æŒ‰æ—¥æœŸåˆ†ç»„æµ‹è¯•æ•°æ®
    test_by_date = test_df.groupby(test_df["time_create"].dt.floor("D"))
    
    for date, day_group in test_by_date:
        # å½“å¤©æ´ªæ°´é“è·¯åˆ—è¡¨
        flooded_roads = list(day_group["link_id"].unique())
        
        # åªè€ƒè™‘åœ¨è´å¶æ–¯ç½‘ç»œä¸­çš„é“è·¯
        flooded_in_bn = [road for road in flooded_roads if road in bn_nodes]
        
        if len(flooded_in_bn) < 2:
            continue  # éœ€è¦è‡³å°‘2æ¡é“è·¯æ‰èƒ½åšæ¨ç†
        
        evaluated_days += 1
        
        # é€‰æ‹©ç¬¬ä¸€æ¡é“è·¯ä½œä¸ºevidence
        evidence_road = flooded_in_bn[0]
        target_roads = flooded_in_bn[1:]
        
        evidence = {evidence_road: 1}
        
        # å¯¹æ¯ä¸ªç›®æ ‡é“è·¯è¿›è¡Œæ¨ç†
        for target_road in target_roads:
            try:
                # è´å¶æ–¯æ¨ç†
                result = flood_net.infer_w_evidence(target_road, evidence)
                prob_flood = result['flooded']
                
                # é¢„æµ‹æ ‡ç­¾ï¼ˆæ ¹æ®æ¦‚ç‡é˜ˆå€¼ï¼‰
                pred_label = 1 if prob_flood >= prob_thr else 0
                true_label = 1  # ç›®æ ‡é“è·¯ç¡®å®å‘ç”Ÿäº†æ´ªæ°´
                
                all_predictions.append(pred_label)
                all_true_labels.append(true_label)
                    
            except Exception as e:
                continue
    
    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    if len(all_predictions) == 0:
        return {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'samples': 0}
    
    # åœ¨è¿™ç§ç‰¹æ®Šè®¾å®šä¸‹ï¼Œæ‰€æœ‰true_labeléƒ½æ˜¯1
    tp = sum(all_predictions)  # é¢„æµ‹ä¸ºæ­£çš„æ•°é‡
    fn = len(all_predictions) - tp  # é¢„æµ‹ä¸ºè´Ÿçš„æ•°é‡
    
    precision = tp / tp if tp > 0 else 0.0  # åœ¨è¿™ç§è®¾å®šä¸‹precisionæ€»æ˜¯1.0æˆ–0.0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
    
    return {
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'samples': len(all_predictions),
        'evaluated_days': evaluated_days,
        'tp': tp,
        'fn': fn
    }

def load_data():
    """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
    df = pd.read_csv("Road_Closures_2024.csv")
    df = df[df["REASON"].str.upper() == "FLOOD"].copy()
    
    # æ•°æ®é¢„å¤„ç†
    df["time_create"] = pd.to_datetime(df["START"], utc=True)
    df["link_id"] = df["STREET"].str.upper().str.replace(" ", "_")
    df["link_id"] = df["link_id"].astype(str)
    df["id"] = df["OBJECTID"].astype(str)
    
    # æ—¶åºåˆ†å‰²ï¼Œé¿å…æ•°æ®æ³„éœ²
    df_sorted = df.sort_values('time_create')
    split_idx = int(len(df_sorted) * 0.7)
    train_df = df_sorted.iloc[:split_idx].copy()
    test_df = df_sorted.iloc[split_idx:].copy()
    
    return train_df, test_df

def build_network(train_df):
    """æ„å»ºè´å¶æ–¯ç½‘ç»œ"""
    flood_net = FloodBayesNetwork(t_window="D")
    flood_net.fit_marginal(train_df)
    
    # æ„å»ºå…±ç°ç½‘ç»œ
    flood_net.build_network_by_co_occurrence(
        train_df,
        occ_thr=3,
        edge_thr=2,
        weight_thr=0.3,
        report=False
    )
    
    if flood_net.network.number_of_nodes() == 0:
        return None
    
    # æ‹Ÿåˆæ¡ä»¶æ¦‚ç‡
    flood_net.fit_conditional(train_df, max_parents=2, alpha=1.0)
    
    # æ„å»ºè´å¶æ–¯ç½‘ç»œ
    flood_net.build_bayes_network()
    
    return flood_net

def compare_strategies():
    """å¯¹æ¯”ä¸¤ç§è¯„ä¼°ç­–ç•¥"""
    print("ğŸ” è¯„ä¼°ç­–ç•¥å¯¹æ¯”åˆ†æ")
    print("=" * 60)
    
    # 1. åŠ è½½æ•°æ®å’Œæ„å»ºç½‘ç»œ
    train_df, test_df = load_data()
    flood_net = build_network(train_df)
    
    if flood_net is None:
        print("âŒ æ— æ³•æ„å»ºæœ‰æ•ˆç½‘ç»œ")
        return
    
    print(f"æ•°æ®è§„æ¨¡: è®­ç»ƒé›†{len(train_df)}æ¡, æµ‹è¯•é›†{len(test_df)}æ¡")
    print(f"ç½‘ç»œè§„æ¨¡: {flood_net.network.number_of_nodes()}ä¸ªèŠ‚ç‚¹, {flood_net.network.number_of_edges()}æ¡è¾¹")
    
    # 2. ä¼ ç»Ÿflood-onlyè¯„ä¼°
    print("\nğŸ“Š ä¼ ç»ŸFlood-Onlyè¯„ä¼°ç­–ç•¥")
    print("-" * 40)
    
    traditional_results = {}
    thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]
    
    for thr in thresholds:
        result = traditional_flood_only_evaluation(flood_net, test_df, prob_thr=thr)
        traditional_results[thr] = result
        print(f"é˜ˆå€¼{thr:.1f}: F1={result['f1']:.3f}, P={result['precision']:.3f}, R={result['recall']:.3f}, æ ·æœ¬={result['samples']}")
    
    # æ‰¾åˆ°ä¼ ç»Ÿæ–¹æ³•çš„æœ€ä½³ç»“æœ
    best_traditional = max(traditional_results.values(), key=lambda x: x['f1'])
    best_thr = [k for k, v in traditional_results.items() if v == best_traditional][0]
    
    # 3. ç²¾ç¡®åº¦ä¼˜å…ˆè¯„ä¼°
    print("\nğŸ¯ ç²¾ç¡®åº¦ä¼˜å…ˆè¯„ä¼°ç­–ç•¥")
    print("-" * 40)
    
    evaluator = PrecisionFocusedEvaluator(flood_net, test_df)
    
    # ä¼˜åŒ–é˜ˆå€¼
    best_config = evaluator.optimize_thresholds_for_precision(
        target_precision=0.8, 
        min_recall=0.3
    )
    
    # æµ‹è¯•ä¸åŒç­–ç•¥
    strategies = ['centrality', 'random', 'first']
    precision_results = {}
    
    for strategy in strategies:
        results = evaluator.evaluate_precision_focused(
            evidence_strategy=strategy, 
            include_negatives=True,
            verbose=False
        )
        metrics = evaluator.calculate_metrics(results)
        precision_results[strategy] = metrics
        print(f"{strategy}: F1={metrics['f1']:.3f}, P={metrics['precision']:.3f}, R={metrics['recall']:.3f}, "
              f"æ ·æœ¬={metrics['samples']}, å¼ƒæƒç‡={metrics['abstention_rate']:.3f}")
    
    # æ‰¾åˆ°ç²¾ç¡®åº¦æ–¹æ³•çš„æœ€ä½³ç»“æœ
    best_precision = max(precision_results.values(), key=lambda x: x['f1'])
    best_strategy = [k for k, v in precision_results.items() if v == best_precision][0]
    
    # 4. è¯¦ç»†å¯¹æ¯”åˆ†æ
    print("\nğŸ“ˆ è¯¦ç»†å¯¹æ¯”åˆ†æ")
    print("=" * 60)
    
    print(f"\nğŸ”¸ ä¼ ç»ŸFlood-Onlyç­–ç•¥ (æœ€ä½³é˜ˆå€¼={best_thr})")
    print(f"  âœ“ ç²¾ç¡®åº¦: {best_traditional['precision']:.3f}")
    print(f"  âœ“ å¬å›ç‡: {best_traditional['recall']:.3f}")
    print(f"  âœ“ F1åˆ†æ•°: {best_traditional['f1']:.3f}")
    print(f"  âœ“ è¯„ä¼°æ ·æœ¬: {best_traditional['samples']}")
    print(f"  âœ“ è¯„ä¼°å¤©æ•°: {best_traditional['evaluated_days']}")
    print(f"  âš ï¸  åªæµ‹è¯•æ­£æ ·æœ¬ï¼Œç²¾ç¡®åº¦å¯èƒ½è™šé«˜")
    print(f"  âš ï¸  å•ä¸€evidenceç­–ç•¥ï¼Œä¿¡æ¯åˆ©ç”¨ä¸å……åˆ†")
    
    print(f"\nğŸ”¸ ç²¾ç¡®åº¦ä¼˜å…ˆç­–ç•¥ (æœ€ä½³ç­–ç•¥={best_strategy})")
    print(f"  âœ“ ç²¾ç¡®åº¦: {best_precision['precision']:.3f}")
    print(f"  âœ“ å¬å›ç‡: {best_precision['recall']:.3f}")
    print(f"  âœ“ F1åˆ†æ•°: {best_precision['f1']:.3f}")
    print(f"  âœ“ è¯„ä¼°æ ·æœ¬: {best_precision['samples']}")
    print(f"  âœ“ å¼ƒæƒç‡: {best_precision['abstention_rate']:.3f}")
    print(f"  âœ“ åŒ…å«è´Ÿæ ·æœ¬æµ‹è¯•ï¼Œç²¾ç¡®åº¦æ›´å¯é ")
    print(f"  âœ“ å¤ševidenceç­–ç•¥ï¼Œä¿¡æ¯åˆ©ç”¨æ›´å……åˆ†")
    print(f"  âœ“ åŒé˜ˆå€¼ç³»ç»Ÿï¼Œé¿å…ä¸ç¡®å®šé¢„æµ‹")
    
    # 5. å…³é”®ä¼˜åŠ¿åˆ†æ
    print(f"\nğŸ¯ ç²¾ç¡®åº¦ä¼˜å…ˆç­–ç•¥çš„å…³é”®ä¼˜åŠ¿")
    print("-" * 40)
    print(f"1. ğŸ“Š çœŸå®ç²¾ç¡®åº¦æµ‹è¯•: åŒ…å«{best_precision['negative_samples']}ä¸ªè´Ÿæ ·æœ¬")
    print(f"2. ğŸšï¸  ä¿å®ˆé¢„æµ‹ç­–ç•¥: {best_precision['abstention_rate']:.1%}çš„é¢„æµ‹è¢«æ ‡è®°ä¸ºä¸ç¡®å®š")
    print(f"3. ğŸ”„ å¤šæ ·åŒ–evidence: ä¸åŒç­–ç•¥é€‚åº”ä¸åŒåœºæ™¯")
    print(f"4. ğŸ¯ ç›®æ ‡å¯¼å‘ä¼˜åŒ–: ä¸“é—¨ä¼˜åŒ–ç²¾ç¡®åº¦â‰¥0.8, å¬å›ç‡â‰¥0.3")
    print(f"5. ğŸš¨ é€‚åº”è§‚æµ‹åå·®: ä¸“é—¨å¤„ç†Charlestonè­¦å¯Ÿæ•°æ®ç‰¹å¾")
    
    # 6. é€‚ç”¨åœºæ™¯å»ºè®®
    print(f"\nğŸ’¡ åº”ç”¨å»ºè®®")
    print("-" * 40)
    print(f"ğŸ”¸ ä¼ ç»Ÿç­–ç•¥é€‚ç”¨äº: å¿«é€Ÿè¯„ä¼°ã€æ¦‚å¿µéªŒè¯")
    print(f"ğŸ”¸ ç²¾ç¡®åº¦ç­–ç•¥é€‚ç”¨äº: å®é™…éƒ¨ç½²ã€é«˜ç²¾åº¦è¦æ±‚ã€è§‚æµ‹åå·®æ•°æ®")
    print(f"ğŸ”¸ æ¨èé…ç½®: {best_strategy}ç­–ç•¥ + é˜ˆå€¼(æ­£:{evaluator.positive_threshold:.2f}, è´Ÿ:{evaluator.negative_threshold:.2f})")
    
    return {
        'traditional_best': best_traditional,
        'precision_best': best_precision,
        'recommendation': f"{best_strategy}ç­–ç•¥"
    }

if __name__ == "__main__":
    results = compare_strategies()