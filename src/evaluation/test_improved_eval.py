#!/usr/bin/env python3
"""
æµ‹è¯•æ”¹è¿›çš„è¯„ä¼°ç­–ç•¥ - ç®€åŒ–ç‰ˆæœ¬

åªæµ‹è¯•æ ¸å¿ƒçš„"æ´ªæ°´é“è·¯æ¨ç†"è¯„ä¼°ç­–ç•¥ï¼ŒéªŒè¯æ€è·¯æ˜¯å¦æ­£ç¡®
"""

import random
import numpy as np
import pandas as pd
from model import FloodBayesNetwork
from sklearn.model_selection import train_test_split

# è®¾ç½®éšæœºç§å­
RANDOM_SEED = 42
random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

def load_data():
    """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
    print("ğŸš€ æµ‹è¯•æ”¹è¿›çš„è¯„ä¼°ç­–ç•¥")
    print("="*50)
    print("1. åŠ è½½æ•°æ®...")
    
    # åŠ è½½æ•°æ®
    df = pd.read_csv("Road_Closures_2024.csv")
    df = df[df["REASON"].str.upper() == "FLOOD"].copy()
    
    # æ•°æ®é¢„å¤„ç†
    df["time_create"] = pd.to_datetime(df["START"], utc=True)
    df["link_id"] = df["STREET"].str.upper().str.replace(" ", "_")
    df["link_id"] = df["link_id"].astype(str)
    df["id"] = df["OBJECTID"].astype(str)
    
    # æ—¶åºåˆ†å‰²ï¼Œé¿å…æ•°æ®æ³„éœ²
    df_sorted = df.sort_values('time_create')
    split_idx = int(len(df_sorted) * 0.7)
    train_df = df_sorted.iloc[:split_idx].copy()
    test_df = df_sorted.iloc[split_idx:].copy()
    
    print(f"   æ€»è®°å½•: {len(df)}æ¡")
    print(f"   è®­ç»ƒé›†: {len(train_df)}æ¡")
    print(f"   æµ‹è¯•é›†: {len(test_df)}æ¡")
    
    return train_df, test_df

def build_network(train_df):
    """æ„å»ºè´å¶æ–¯ç½‘ç»œ"""
    print("\n2. æ„å»ºè´å¶æ–¯ç½‘ç»œ...")
    
    # åˆ›å»ºç½‘ç»œ
    flood_net = FloodBayesNetwork(t_window="D")
    flood_net.fit_marginal(train_df)
    
    # æ„å»ºå…±ç°ç½‘ç»œï¼ˆä½¿ç”¨è¾ƒå®½æ¾çš„å‚æ•°ç¡®ä¿æœ‰ç½‘ç»œï¼‰
    flood_net.build_network_by_co_occurrence(
        train_df,
        occ_thr=3,      # è¾ƒä½çš„é˜ˆå€¼
        edge_thr=2,     # è¾ƒä½çš„é˜ˆå€¼
        weight_thr=0.3, # è¾ƒä½çš„é˜ˆå€¼
        report=False
    )
    
    print(f"   èŠ‚ç‚¹æ•°: {flood_net.network.number_of_nodes()}")
    print(f"   è¾¹æ•°: {flood_net.network.number_of_edges()}")
    
    if flood_net.network.number_of_nodes() == 0:
        print("   âŒ ç½‘ç»œä¸ºç©ºï¼Œå°è¯•æ›´å®½æ¾çš„å‚æ•°")
        return None
    
    # æ‹Ÿåˆæ¡ä»¶æ¦‚ç‡
    flood_net.fit_conditional(train_df, max_parents=2, alpha=1.0)
    
    # æ„å»ºè´å¶æ–¯ç½‘ç»œ
    flood_net.build_bayes_network()
    
    print("   âœ… ç½‘ç»œæ„å»ºå®Œæˆ")
    return flood_net

def evaluate_flood_only(flood_net, test_df, prob_thr=0.5):
    """
    ç‰¹æ®Šè¯„ä¼°ç­–ç•¥ï¼šåªå¯¹æœ‰æ´ªæ°´è®°å½•çš„é“è·¯è¿›è¡Œæ¨ç†
    """
    print(f"\n3. ç‰¹æ®Šè¯„ä¼°ç­–ç•¥ (é˜ˆå€¼={prob_thr})...")
    
    bn_nodes = set(flood_net.network_bayes.nodes())
    
    all_predictions = []
    all_true_labels = []
    evaluated_days = 0
    
    # æŒ‰æ—¥æœŸåˆ†ç»„æµ‹è¯•æ•°æ®
    test_by_date = test_df.groupby(test_df["time_create"].dt.floor("D"))
    
    for date, day_group in test_by_date:
        # å½“å¤©æ´ªæ°´é“è·¯åˆ—è¡¨
        flooded_roads = list(day_group["link_id"].unique())
        
        # åªè€ƒè™‘åœ¨è´å¶æ–¯ç½‘ç»œä¸­çš„é“è·¯
        flooded_in_bn = [road for road in flooded_roads if road in bn_nodes]
        
        if len(flooded_in_bn) < 2:
            continue  # éœ€è¦è‡³å°‘2æ¡é“è·¯æ‰èƒ½åšæ¨ç†
        
        evaluated_days += 1
        
        # é€‰æ‹©ç¬¬ä¸€æ¡é“è·¯ä½œä¸ºevidence
        evidence_road = flooded_in_bn[0]
        target_roads = flooded_in_bn[1:]
        
        evidence = {evidence_road: 1}
        
        if evaluated_days <= 3:  # æ˜¾ç¤ºå‰3å¤©çš„è¯¦ç»†æƒ…å†µ
            print(f"   ğŸ“… {date.date()}: æ´ªæ°´é“è·¯{len(flooded_in_bn)}")
            print(f"       Evidence: {evidence_road}")
            print(f"       Targets: {target_roads}")
        
        # å¯¹æ¯ä¸ªç›®æ ‡é“è·¯è¿›è¡Œæ¨ç†
        for target_road in target_roads:
            try:
                # è´å¶æ–¯æ¨ç†
                result = flood_net.infer_w_evidence(target_road, evidence)
                prob_flood = result['flooded']
                
                # é¢„æµ‹æ ‡ç­¾ï¼ˆæ ¹æ®æ¦‚ç‡é˜ˆå€¼ï¼‰
                pred_label = 1 if prob_flood >= prob_thr else 0
                true_label = 1  # ç›®æ ‡é“è·¯ç¡®å®å‘ç”Ÿäº†æ´ªæ°´
                
                all_predictions.append(pred_label)
                all_true_labels.append(true_label)
                
                if evaluated_days <= 3:
                    print(f"         {target_road}: P(flood)={prob_flood:.3f}, pred={pred_label}")
                    
            except Exception as e:
                if evaluated_days <= 3:
                    print(f"         {target_road}: æ¨ç†å¤±è´¥ - {e}")
                continue
    
    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    if len(all_predictions) == 0:
        return {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'samples': 0}
    
    # åœ¨è¿™ç§ç‰¹æ®Šè®¾å®šä¸‹ï¼Œæ‰€æœ‰true_labeléƒ½æ˜¯1
    tp = sum(all_predictions)  # é¢„æµ‹ä¸ºæ­£çš„æ•°é‡
    fn = len(all_predictions) - tp  # é¢„æµ‹ä¸ºè´Ÿçš„æ•°é‡
    
    precision = tp / tp if tp > 0 else 0.0  # åœ¨è¿™ç§è®¾å®šä¸‹precisionæ€»æ˜¯1.0æˆ–0.0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
    
    print(f"   ğŸ“Š è¯„ä¼°ç»“æœ:")
    print(f"       æ€»é¢„æµ‹æ ·æœ¬: {len(all_predictions)}")
    print(f"       è¯„ä¼°å¤©æ•°: {evaluated_days}")
    print(f"       True Positives: {tp}")
    print(f"       False Negatives: {fn}")
    print(f"       Precision: {precision:.3f}")
    print(f"       Recall: {recall:.3f}")
    print(f"       F1 Score: {f1:.3f}")
    
    return {
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'samples': len(all_predictions),
        'evaluated_days': evaluated_days,
        'tp': tp,
        'fn': fn
    }

def main():
    """ä¸»å‡½æ•°"""
    # 1. åŠ è½½æ•°æ®
    train_df, test_df = load_data()
    
    # 2. æ„å»ºç½‘ç»œ
    flood_net = build_network(train_df)
    if flood_net is None:
        print("âŒ æ— æ³•æ„å»ºæœ‰æ•ˆç½‘ç»œ")
        return
    
    # 3. æµ‹è¯•ä¸åŒæ¦‚ç‡é˜ˆå€¼
    print(f"\n4. æµ‹è¯•ä¸åŒæ¦‚ç‡é˜ˆå€¼...")
    thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]
    
    results = []
    for thr in thresholds:
        result = evaluate_flood_only(flood_net, test_df, prob_thr=thr)
        result['threshold'] = thr
        results.append(result)
    
    # 5. æ€»ç»“ç»“æœ
    print(f"\n5. ç»“æœæ€»ç»“:")
    print(f"   {'é˜ˆå€¼':<6} {'F1':<6} {'ç²¾ç¡®ç‡':<8} {'å¬å›ç‡':<8} {'æ ·æœ¬æ•°':<6}")
    print("-" * 40)
    
    for result in results:
        print(f"   {result['threshold']:<6.1f} {result['f1']:<6.3f} {result['precision']:<8.3f} "
              f"{result['recall']:<8.3f} {result['samples']:<6}")
    
    # æ‰¾åˆ°æœ€ä½³é˜ˆå€¼
    best_result = max(results, key=lambda x: x['f1'])
    print(f"\n   ğŸ¯ æœ€ä½³é˜ˆå€¼: {best_result['threshold']} (F1: {best_result['f1']:.3f})")
    
    print(f"\nâœ… è¯„ä¼°ç­–ç•¥éªŒè¯å®Œæˆï¼")
    print(f"ğŸ’¡ å…³é”®æ´å¯Ÿ:")
    print(f"   - åªè€ƒè™‘æœ‰æ´ªæ°´è®°å½•çš„é“è·¯è¿›è¡Œæ¨ç†")
    print(f"   - é¿å…äº†è´Ÿæ ·æœ¬ä¸å¯é çš„é—®é¢˜")
    print(f"   - æ›´ç¬¦åˆå®é™…åº”ç”¨åœºæ™¯")

if __name__ == "__main__":
    main()