#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆ10æ¬¡æ´ªæ°´æ—¥æœŸäº¤å‰éªŒè¯å®éªŒ
é¿å…pandaså…¼å®¹æ€§é—®é¢˜ï¼Œä½¿ç”¨åŸºç¡€Pythonå¤„ç†CSV
"""

import json
import os
import sys
import random
import time
from datetime import datetime
from collections import defaultdict, Counter
import csv

# Set random seed
RANDOM_SEED = 42
random.seed(RANDOM_SEED)

class SimpleFloodCrossValidator:
    """ç®€åŒ–ç‰ˆæ´ªæ°´æ—¥æœŸäº¤å‰éªŒè¯å™¨"""
    
    def __init__(self):
        # æœ€ä½³å‚æ•°é…ç½®
        self.best_params = {
            'occ_thr': 4,
            'edge_thr': 3, 
            'weight_thr': 0.2,
            'evidence_count': 1,
            'pred_threshold': 0.1
        }
        
        # Top 10æ´ªæ°´æ—¥æœŸ
        self.top10_dates = [
            '2017/09/11',  # 52æ¡é“è·¯
            '2016/10/08',  # 26æ¡é“è·¯
            '2019/12/23',  # 22æ¡é“è·¯
            '2024/04/11',  # 19æ¡é“è·¯
            '2024/08/06',  # 18æ¡é“è·¯
            '2023/08/30',  # 16æ¡é“è·¯
            '2022/09/30',  # 16æ¡é“è·¯
            '2015/11/09',  # 16æ¡é“è·¯
            '2022/11/10',  # 15æ¡é“è·¯
            '2020/05/20'   # 15æ¡é“è·¯
        ]
        
        self.all_results = []
        self.flood_data = []
        
    def load_flood_data(self):
        """åŠ è½½æ´ªæ°´æ•°æ®"""
        print("ğŸ”„ åŠ è½½æ´ªæ°´æ•°æ®...")
        
        with open("Road_Closures_2024.csv", 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row['REASON'].upper() == 'FLOOD':
                    # æå–æ—¥æœŸ
                    start_date = row['START'].split(' ')[0].replace('"', '')
                    street = row['STREET'].replace('"', '').upper().replace(' ', '_')
                    
                    # å¤„ç†BOMå­—ç¬¦
                    objectid_key = 'OBJECTID'
                    if objectid_key not in row:
                        objectid_key = 'ï»¿OBJECTID'  # å¸¦BOMçš„å­—æ®µå
                        
                    self.flood_data.append({
                        'date': start_date,
                        'street': street,
                        'objectid': row.get(objectid_key, '')
                    })
        
        print(f"âœ… åŠ è½½å®Œæˆ: {len(self.flood_data)} æ¡æ´ªæ°´è®°å½•")
        
        # ç»Ÿè®¡æ¯æ—¥é“è·¯æ•°
        date_roads = defaultdict(set)
        for record in self.flood_data:
            date_roads[record['date']].add(record['street'])
            
        print(f"ğŸ“Š æ•°æ®æ¦‚è§ˆ:")
        for date in self.top10_dates:
            if date in date_roads:
                road_count = len(date_roads[date])
                print(f"   {date}: {road_count}æ¡é“è·¯")
            else:
                print(f"   {date}: æ•°æ®ä¸­ä¸å­˜åœ¨")
                
        return self.flood_data
        
    def run_single_experiment(self, test_date_idx):
        """è¿è¡Œå•æ¬¡å®éªŒï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        test_date = self.top10_dates[test_date_idx]
        exp_num = test_date_idx + 1
        
        print(f"\n{'='*60}")
        print(f"ğŸ“… å®éªŒ {exp_num}/10: {test_date}")
        print(f"{'='*60}")
        
        # 1. æ•°æ®åˆ†å‰²
        test_records = [r for r in self.flood_data if r['date'] == test_date]
        train_records = [r for r in self.flood_data if r['date'] != test_date]
        
        test_roads = set(r['street'] for r in test_records)
        
        print(f"ğŸ“Š æ•°æ®åˆ†å‰²:")
        print(f"   è®­ç»ƒæ•°æ®: {len(train_records)} æ¡è®°å½•")
        print(f"   æµ‹è¯•æ•°æ®: {len(test_records)} æ¡è®°å½•")
        print(f"   æµ‹è¯•é“è·¯: {len(test_roads)} æ¡")
        
        if len(test_roads) < 2:
            print("âŒ æµ‹è¯•é“è·¯æ•°é‡ä¸è¶³ï¼Œè·³è¿‡")
            return None
            
        # æ˜¾ç¤ºæµ‹è¯•é“è·¯
        test_roads_list = list(test_roads)
        print(f"   é“è·¯åˆ—è¡¨: {', '.join(test_roads_list[:8])}{'...' if len(test_roads_list) > 8 else ''}")
        
        # 2. ç®€åŒ–çš„"ç½‘ç»œåˆ†æ"
        # ç»Ÿè®¡è®­ç»ƒé›†ä¸­é“è·¯å‡ºç°é¢‘æ¬¡
        road_freq = Counter(r['street'] for r in train_records)
        
        # è¿‡æ»¤ä½é¢‘é“è·¯ï¼ˆæ¨¡æ‹Ÿç½‘ç»œèŠ‚ç‚¹ç­›é€‰ï¼‰
        network_roads = set(road for road, freq in road_freq.items() if freq >= self.best_params['occ_thr'])
        test_network_roads = test_roads & network_roads
        
        print(f"ğŸ—ï¸ ç®€åŒ–ç½‘ç»œåˆ†æ:")
        print(f"   ç½‘ç»œé“è·¯: {len(network_roads)} æ¡ (å‡ºç°â‰¥{self.best_params['occ_thr']}æ¬¡)")
        print(f"   æµ‹è¯•é›†åœ¨ç½‘ç»œä¸­: {len(test_network_roads)} æ¡é“è·¯")
        
        if len(test_network_roads) < 2:
            print("âŒ æµ‹è¯•é›†ç½‘ç»œé“è·¯ä¸è¶³2æ¡ï¼Œè·³è¿‡")
            return None
            
        # 3. ç®€åŒ–çš„"é¢„æµ‹"è¿‡ç¨‹
        test_network_roads_list = list(test_network_roads)
        evidence_road = random.choice(test_network_roads_list)
        predict_roads = [r for r in test_network_roads_list if r != evidence_road]
        
        print(f"ğŸ¯ è¯æ®è¾“å…¥: [{evidence_road}]")
        print(f"ğŸ”® é¢„æµ‹ç›®æ ‡: {len(predict_roads)} æ¡é“è·¯")
        
        # 4. ç®€åŒ–çš„"æ€§èƒ½è¯„ä¼°"
        # åŸºäºé“è·¯é¢‘æ¬¡ä½œä¸º"é¢„æµ‹æ¦‚ç‡"çš„ä»£ç†
        road_probs = {}
        max_freq = max(road_freq.values()) if road_freq else 1
        
        for road in predict_roads:
            # ç®€åŒ–æ¦‚ç‡ï¼šåŸºäºè®­ç»ƒé›†é¢‘æ¬¡
            prob = road_freq.get(road, 0) / max_freq
            road_probs[road] = prob
            
        # ç”Ÿæˆé¢„æµ‹ï¼ˆåŸºäºé˜ˆå€¼ï¼‰
        threshold = self.best_params['pred_threshold'] 
        predictions = {road: 1 if prob > threshold else 0 for road, prob in road_probs.items()}
        true_labels = {road: 1 for road in predict_roads}  # æ‰€æœ‰ç›®æ ‡é“è·¯å®é™…éƒ½å‘æ´ªæ°´
        
        # è®¡ç®—æŒ‡æ ‡
        tp = sum(1 for road in predict_roads if predictions[road] == 1 and true_labels[road] == 1)
        fp = sum(1 for road in predict_roads if predictions[road] == 1 and true_labels[road] == 0)
        tn = sum(1 for road in predict_roads if predictions[road] == 0 and true_labels[road] == 0)
        fn = sum(1 for road in predict_roads if predictions[road] == 0 and true_labels[road] == 1)
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0
        
        print(f"\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
        print(f"   Precision: {precision:.3f}")
        print(f"   Recall:    {recall:.3f}")
        print(f"   F1 Score:  {f1:.3f}")
        print(f"   Accuracy:  {accuracy:.3f}")
        print(f"\nğŸ“Š æ··æ·†çŸ©é˜µ: TP={tp}, FP={fp}, TN={tn}, FN={fn}")
        print(f"ğŸ¯ æ­£ç¡®é¢„æµ‹: {tp}/{len(predict_roads)} æ¡é“è·¯")
        
        # ä¿å­˜ç»“æœ
        result = {
            'experiment_id': exp_num,
            'test_date': test_date,
            'train_records': len(train_records),
            'test_roads_total': len(test_roads),
            'test_roads_in_network': len(test_network_roads),
            'network_roads': len(network_roads),
            'evidence_road': evidence_road,
            'predict_roads_count': len(predict_roads),
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'accuracy': accuracy,
            'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn,
            'correct_predictions': tp
        }
        
        return result
        
    def run_all_experiments(self):
        """è¿è¡Œå…¨éƒ¨å®éªŒ"""
        print("ğŸš€ å¼€å§‹10æ¬¡æ´ªæ°´æ—¥æœŸäº¤å‰éªŒè¯å®éªŒ")
        print(f"ğŸ“Š ä½¿ç”¨ç®€åŒ–å‚æ•°: {self.best_params}")
        
        start_time = time.time()
        
        # åŠ è½½æ•°æ®
        self.load_flood_data()
        
        # è¿è¡Œå®éªŒ
        successful_results = []
        
        for i in range(len(self.top10_dates)):
            result = self.run_single_experiment(i)
            if result:
                successful_results.append(result)
                self.all_results.append(result)
                
        print(f"\n{'='*60}")
        print(f"ğŸ“Š å®éªŒæ±‡æ€»")
        print(f"{'='*60}")
        
        if not successful_results:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„å®éªŒ")
            return None
            
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        metrics = ['precision', 'recall', 'f1_score', 'accuracy']
        avg_metrics = {}
        std_metrics = {}
        
        for metric in metrics:
            values = [r[metric] for r in successful_results]
            avg_metrics[metric] = sum(values) / len(values)
            
            # ç®€å•æ ‡å‡†å·®è®¡ç®—
            mean_val = avg_metrics[metric]
            variance = sum((x - mean_val) ** 2 for x in values) / len(values)
            std_metrics[metric] = variance ** 0.5
            
        print(f"âœ… æˆåŠŸå®éªŒ: {len(successful_results)}/10")
        print(f"\nğŸ“ˆ å¹³å‡æ€§èƒ½æŒ‡æ ‡ (Mean Â± Std):")
        print(f"   Precision: {avg_metrics['precision']:.3f} Â± {std_metrics['precision']:.3f}")
        print(f"   Recall:    {avg_metrics['recall']:.3f} Â± {std_metrics['recall']:.3f}")
        print(f"   F1 Score:  {avg_metrics['f1_score']:.3f} Â± {std_metrics['f1_score']:.3f}")
        print(f"   Accuracy:  {avg_metrics['accuracy']:.3f} Â± {std_metrics['accuracy']:.3f}")
        
        # æœ€ä½³å’Œæœ€å·®å®éªŒ
        if len(successful_results) > 0:
            best_exp = max(successful_results, key=lambda x: x['f1_score'])
            worst_exp = min(successful_results, key=lambda x: x['f1_score'])
            
            print(f"\nğŸ† æœ€ä½³å®éªŒ: {best_exp['test_date']} (F1: {best_exp['f1_score']:.3f})")
            print(f"ğŸ˜ æœ€å·®å®éªŒ: {worst_exp['test_date']} (F1: {worst_exp['f1_score']:.3f})")
            
        execution_time = time.time() - start_time
        print(f"\nâ±ï¸  æ‰§è¡Œæ—¶é—´: {execution_time:.1f} ç§’")
        
        # ä¿å­˜ç»“æœ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        result_file = f"flood_cross_validation_results_{timestamp}.json"
        
        results_summary = {
            'summary': {
                'total_experiments': len(self.top10_dates),
                'successful_experiments': len(successful_results),
                'avg_precision': avg_metrics['precision'],
                'avg_recall': avg_metrics['recall'],
                'avg_f1_score': avg_metrics['f1_score'],
                'avg_accuracy': avg_metrics['accuracy'],
                'std_precision': std_metrics['precision'],
                'std_recall': std_metrics['recall'],
                'std_f1_score': std_metrics['f1_score'],
                'std_accuracy': std_metrics['accuracy'],
                'execution_time': execution_time,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            },
            'detailed_results': successful_results,
            'parameters': self.best_params
        }
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(results_summary, f, indent=2, ensure_ascii=False)
            
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
        
        return successful_results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŠ Charlestonæ´ªæ°´é¢„æµ‹ - ç®€åŒ–ç‰ˆ10æ¬¡äº¤å‰éªŒè¯")
    
    validator = SimpleFloodCrossValidator()
    results = validator.run_all_experiments()
    
    if results:
        print(f"\nğŸ‰ å®éªŒå®Œæˆï¼æˆåŠŸå®Œæˆ {len(results)} æ¬¡å®éªŒ")
    else:
        print(f"\nğŸ’¥ å®éªŒå¤±è´¥ï¼")
        
    return validator, results

if __name__ == "__main__":
    validator, results = main()