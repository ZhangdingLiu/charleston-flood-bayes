#!/usr/bin/env python3
"""
10æ¬¡æ´ªæ°´æ—¥æœŸäº¤å‰éªŒè¯å®éªŒ
ä½¿ç”¨Top 10æ´ªæ°´æ—¥æœŸè¿›è¡ŒLeave-One-Outäº¤å‰éªŒè¯ï¼Œå…¨é¢è¯„ä¼°è´å¶æ–¯æ¨¡å‹æ€§èƒ½
"""

import pandas as pd
import numpy as np
import warnings
import time
import json
import os
import sys
import random
from datetime import datetime
from collections import defaultdict
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score
from pathlib import Path

warnings.filterwarnings('ignore')

# Add project root to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from model import FloodBayesNetwork
except ImportError:
    try:
        from core.model import FloodBayesNetwork
    except ImportError:
        print("âŒ Cannot import FloodBayesNetwork, please ensure model.py or core/model.py exists")
        sys.exit(1)

# Set random seed for reproducibility
RANDOM_SEED = 42
random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

class FloodDateCrossValidator:
    """10æ¬¡æ´ªæ°´æ—¥æœŸäº¤å‰éªŒè¯å™¨"""
    
    def __init__(self):
        # æœ€ä½³å‚æ•°é…ç½® (åŸºäºå‚æ•°ä¼˜åŒ–ç»“æœ)
        self.best_params = {
            'occ_thr': 4,
            'edge_thr': 3,
            'weight_thr': 0.2,
            'evidence_count': 1,
            'pred_threshold': 0.1,
            'negative_candidates': 9,
            'marginal_prob_threshold': 0.08
        }
        
        # Top 10æ´ªæ°´æ—¥æœŸ
        self.top10_dates = [
            '2017-09-11',  # 52æ¡é“è·¯
            '2016-10-08',  # 26æ¡é“è·¯
            '2019-12-23',  # 22æ¡é“è·¯
            '2024-04-11',  # 19æ¡é“è·¯
            '2024-08-06',  # 18æ¡é“è·¯
            '2023-08-30',  # 16æ¡é“è·¯
            '2022-09-30',  # 16æ¡é“è·¯
            '2015-11-09',  # 16æ¡é“è·¯
            '2022-11-10',  # 15æ¡é“è·¯
            '2020-05-20'   # 15æ¡é“è·¯
        ]
        
        self.all_results = []
        self.df = None
        
    def load_and_preprocess_data(self):
        """åŠ è½½å’Œé¢„å¤„ç†æ´ªæ°´æ•°æ®"""
        print("ğŸ”„ åŠ è½½æ´ªæ°´æ•°æ®...")
        
        # åŠ è½½æ•°æ®
        self.df = pd.read_csv("Road_Closures_2024.csv")
        self.df = self.df[self.df["REASON"].str.upper() == "FLOOD"].copy()
        
        # é¢„å¤„ç†
        self.df["time_create"] = pd.to_datetime(self.df["START"], utc=True)
        self.df["link_id"] = self.df["STREET"].str.upper().str.replace(" ", "_")
        self.df["link_id"] = self.df["link_id"].astype(str)
        self.df["id"] = self.df["OBJECTID"].astype(str)
        self.df['flood_date'] = self.df['time_create'].dt.floor('D')
        self.df['date_str'] = self.df['flood_date'].dt.strftime('%Y-%m-%d')
        
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(self.df)} æ¡æ´ªæ°´è®°å½•")
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: {self.df['flood_date'].min().strftime('%Y-%m-%d')} è‡³ {self.df['flood_date'].max().strftime('%Y-%m-%d')}")
        
        # éªŒè¯Top 10æ—¥æœŸåœ¨æ•°æ®ä¸­çš„å­˜åœ¨
        available_dates = set(self.df['date_str'].unique())
        missing_dates = []
        for date in self.top10_dates:
            if date not in available_dates:
                missing_dates.append(date)
        
        if missing_dates:
            print(f"âš ï¸ ä»¥ä¸‹æ—¥æœŸåœ¨æ•°æ®ä¸­ä¸å­˜åœ¨ï¼Œå°†è·³è¿‡: {missing_dates}")
            self.top10_dates = [d for d in self.top10_dates if d not in missing_dates]
            print(f"âœ… å®é™…æµ‹è¯•æ—¥æœŸæ•°: {len(self.top10_dates)}")
            
        return self.df
        
    def run_single_experiment(self, test_date_idx):
        """è¿è¡Œå•æ¬¡å®éªŒ"""
        test_date = self.top10_dates[test_date_idx]
        exp_num = test_date_idx + 1
        
        print(f"\n{'='*80}")
        print(f"ğŸ“… å®éªŒ {exp_num}/{len(self.top10_dates)}: {test_date}")
        print(f"{'='*80}")
        
        # 1. æ•°æ®åˆ†å‰²
        test_df = self.df[self.df['date_str'] == test_date].copy()
        train_df = self.df[self.df['date_str'] != test_date].copy()
        
        test_roads = set(test_df['link_id'].unique())
        
        print(f"ğŸ“Š æ•°æ®åˆ†å‰²:")
        print(f"   è®­ç»ƒæ•°æ®: {len(train_df)} æ¡è®°å½•")
        print(f"   æµ‹è¯•æ•°æ®: {len(test_df)} æ¡è®°å½• ({len(test_roads)} æ¡é“è·¯)")
        print(f"   æµ‹è¯•é“è·¯: {', '.join(list(test_roads)[:8])}{'...' if len(test_roads) > 8 else ''}")
        
        if len(test_roads) < 2:
            print("âŒ æµ‹è¯•é“è·¯æ•°é‡ä¸è¶³2æ¡ï¼Œè·³è¿‡æ­¤å®éªŒ")
            return None
            
        # 2. æ„å»ºè´å¶æ–¯ç½‘ç»œ
        print(f"\nğŸ—ï¸ æ„å»ºè´å¶æ–¯ç½‘ç»œ...")
        flood_net = FloodBayesNetwork(t_window="D")
        
        try:
            # æ„å»ºç½‘ç»œ
            flood_net.build_network_by_co_occurrence(
                train_df,
                occ_thr=self.best_params['occ_thr'],
                edge_thr=self.best_params['edge_thr'],
                weight_thr=self.best_params['weight_thr'],
                report=False
            )
            
            # æ‹Ÿåˆæ¡ä»¶æ¦‚ç‡
            flood_net.fit_conditional(train_df, max_parents=2, alpha=1.0)
            flood_net.build_bayes_network()
            
            network_roads = set(flood_net.network.nodes())
            test_network_roads = test_roads & network_roads
            
            print(f"âœ… ç½‘ç»œæ„å»ºå®Œæˆ:")
            print(f"   ç½‘ç»œèŠ‚ç‚¹: {len(network_roads)} æ¡é“è·¯")
            print(f"   ç½‘ç»œè¾¹æ•°: {flood_net.network.number_of_edges()} æ¡")
            print(f"   æµ‹è¯•é›†åœ¨ç½‘ç»œä¸­: {len(test_network_roads)} æ¡é“è·¯")
            
            if len(test_network_roads) < 2:
                print("âŒ æµ‹è¯•é›†åœ¨ç½‘ç»œä¸­çš„é“è·¯æ•°é‡ä¸è¶³2æ¡ï¼Œè·³è¿‡æ­¤å®éªŒ")
                return None
                
        except Exception as e:
            print(f"âŒ ç½‘ç»œæ„å»ºå¤±è´¥: {e}")
            return None
            
        # 3. é¢„æµ‹å’Œè¯„ä¼°
        print(f"\nğŸ”® é¢„æµ‹å’Œè¯„ä¼°...")
        
        # éšæœºé€‰æ‹©1æ¡é“è·¯ä½œä¸ºè¯æ®
        test_network_roads_list = list(test_network_roads)
        evidence_road = random.choice(test_network_roads_list)
        predict_roads = [r for r in test_network_roads_list if r != evidence_road]
        
        print(f"ğŸ¯ è¯æ®è¾“å…¥: [{evidence_road}] (1æ¡é“è·¯)")
        print(f"ğŸ” é¢„æµ‹ç›®æ ‡: {len(predict_roads)} æ¡é“è·¯")
        print(f"   é“è·¯åˆ—è¡¨: {', '.join(predict_roads[:6])}{'...' if len(predict_roads) > 6 else ''}")
        
        # æ‰§è¡Œé¢„æµ‹
        try:
            evidence = {evidence_road: 1}  # è¯æ®é“è·¯å‘ç”Ÿæ´ªæ°´
            
            # è·å–é¢„æµ‹æ¦‚ç‡
            pred_probs = {}
            for road in predict_roads:
                try:
                    prob = flood_net.query_probability(road, evidence)
                    pred_probs[road] = prob
                except:
                    pred_probs[road] = 0.0
            
            # ç”Ÿæˆé¢„æµ‹æ ‡ç­¾
            pred_threshold = self.best_params['pred_threshold']
            predictions = {road: 1 if prob > pred_threshold else 0 for road, prob in pred_probs.items()}
            true_labels = {road: 1 for road in predict_roads}  # æµ‹è¯•æ—¥æœŸæ‰€æœ‰é“è·¯éƒ½å‘æ´ªæ°´
            
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            y_true = [true_labels[road] for road in predict_roads]
            y_pred = [predictions[road] for road in predict_roads]
            
            precision = precision_score(y_true, y_pred, zero_division=0)
            recall = recall_score(y_true, y_pred, zero_division=0)
            f1 = f1_score(y_true, y_pred, zero_division=0)
            accuracy = accuracy_score(y_true, y_pred)
            
            # æ··æ·†çŸ©é˜µ
            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
            
            print(f"\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
            print(f"   Precision: {precision:.3f}")
            print(f"   Recall:    {recall:.3f}")
            print(f"   F1 Score:  {f1:.3f}")
            print(f"   Accuracy:  {accuracy:.3f}")
            print(f"\nğŸ“Š æ··æ·†çŸ©é˜µ:")
            print(f"   TP: {tp}, FP: {fp}")
            print(f"   TN: {tn}, FN: {fn}")
            
            # é¢„æµ‹è¯¦æƒ…
            correct_predictions = sum(1 for road in predict_roads if predictions[road] == 1)
            print(f"\nğŸ¯ é¢„æµ‹è¯¦æƒ…:")
            print(f"   æ­£ç¡®é¢„æµ‹: {correct_predictions}/{len(predict_roads)} æ¡é“è·¯")
            print(f"   é¢„æµ‹æ¦‚ç‡èŒƒå›´: {min(pred_probs.values()):.3f} - {max(pred_probs.values()):.3f}")
            
            # ä¿å­˜ç»“æœ
            experiment_result = {
                'experiment_id': exp_num,
                'test_date': test_date,
                'train_records': len(train_df),
                'test_roads_total': len(test_roads),
                'test_roads_in_network': len(test_network_roads),
                'network_nodes': len(network_roads),
                'network_edges': flood_net.network.number_of_edges(),
                'evidence_road': evidence_road,
                'predict_roads_count': len(predict_roads),
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'accuracy': accuracy,
                'tp': int(tp), 'fp': int(fp), 'tn': int(tn), 'fn': int(fn),
                'pred_probs': pred_probs,
                'predictions': predictions,
                'correct_predictions': correct_predictions
            }
            
            return experiment_result
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹è¯„ä¼°å¤±è´¥: {e}")
            return None
            
    def run_all_experiments(self):
        """è¿è¡Œå…¨éƒ¨10æ¬¡å®éªŒ"""
        print(f"\nğŸš€ å¼€å§‹10æ¬¡æ´ªæ°´æ—¥æœŸäº¤å‰éªŒè¯å®éªŒ")
        print(f"ğŸ“Š ä½¿ç”¨æœ€ä½³å‚æ•°é…ç½®: {self.best_params}")
        print(f"ğŸ“… æµ‹è¯•æ—¥æœŸ: {len(self.top10_dates)} ä¸ª")
        
        start_time = time.time()
        
        # åŠ è½½æ•°æ®
        self.load_and_preprocess_data()
        
        # è¿è¡Œæ¯æ¬¡å®éªŒ
        successful_experiments = []
        
        for i in range(len(self.top10_dates)):
            result = self.run_single_experiment(i)
            if result is not None:
                successful_experiments.append(result)
                self.all_results.append(result)
        
        print(f"\n{'='*80}")
        print(f"ğŸ“Š å®éªŒå®Œæˆæ±‡æ€»")
        print(f"{'='*80}")
        
        if len(successful_experiments) == 0:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„å®éªŒ")
            return None
            
        # è®¡ç®—å¹³å‡æ€§èƒ½æŒ‡æ ‡
        avg_precision = np.mean([r['precision'] for r in successful_experiments])
        avg_recall = np.mean([r['recall'] for r in successful_experiments])
        avg_f1 = np.mean([r['f1_score'] for r in successful_experiments])
        avg_accuracy = np.mean([r['accuracy'] for r in successful_experiments])
        
        std_precision = np.std([r['precision'] for r in successful_experiments])
        std_recall = np.std([r['recall'] for r in successful_experiments])
        std_f1 = np.std([r['f1_score'] for r in successful_experiments])
        std_accuracy = np.std([r['accuracy'] for r in successful_experiments])
        
        print(f"âœ… æˆåŠŸå®éªŒ: {len(successful_experiments)}/{len(self.top10_dates)}")
        print(f"\nğŸ“ˆ å¹³å‡æ€§èƒ½æŒ‡æ ‡ (Mean Â± Std):")
        print(f"   Precision: {avg_precision:.3f} Â± {std_precision:.3f}")
        print(f"   Recall:    {avg_recall:.3f} Â± {std_recall:.3f}")
        print(f"   F1 Score:  {avg_f1:.3f} Â± {std_f1:.3f}")
        print(f"   Accuracy:  {avg_accuracy:.3f} Â± {std_accuracy:.3f}")
        
        # æ‰¾å‡ºæœ€ä½³å’Œæœ€å·®å®éªŒ
        best_exp = max(successful_experiments, key=lambda x: x['f1_score'])
        worst_exp = min(successful_experiments, key=lambda x: x['f1_score'])
        
        print(f"\nğŸ† æœ€ä½³å®éªŒ: {best_exp['test_date']} (F1: {best_exp['f1_score']:.3f})")
        print(f"ğŸ˜ æœ€å·®å®éªŒ: {worst_exp['test_date']} (F1: {worst_exp['f1_score']:.3f})")
        
        execution_time = time.time() - start_time
        print(f"\nâ±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {execution_time:.1f} ç§’")
        
        # ä¿å­˜ç»“æœ
        self.save_results({
            'experiment_summary': {
                'total_experiments': len(self.top10_dates),
                'successful_experiments': len(successful_experiments),
                'avg_precision': float(avg_precision),
                'avg_recall': float(avg_recall),
                'avg_f1_score': float(avg_f1),
                'avg_accuracy': float(avg_accuracy),
                'std_precision': float(std_precision),
                'std_recall': float(std_recall),
                'std_f1_score': float(std_f1),
                'std_accuracy': float(std_accuracy),
                'best_experiment': best_exp['test_date'],
                'worst_experiment': worst_exp['test_date'],
                'execution_time': execution_time,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            },
            'detailed_results': successful_experiments,
            'parameters': self.best_params
        })
        
        return successful_experiments
        
    def save_results(self, results):
        """ä¿å­˜å®éªŒç»“æœ"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # åˆ›å»ºç»“æœç›®å½•
        result_dir = Path(f"results/flood_date_cross_validation_{timestamp}")
        result_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜JSONç»“æœ
        with open(result_dir / "experiment_results.json", 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
            
        # ä¿å­˜CSVæ±‡æ€»
        summary_data = []
        for result in results['detailed_results']:
            summary_data.append({
                'experiment_id': result['experiment_id'],
                'test_date': result['test_date'],
                'test_roads_total': result['test_roads_total'],
                'test_roads_in_network': result['test_roads_in_network'],
                'network_nodes': result['network_nodes'],
                'evidence_road': result['evidence_road'],
                'predict_roads_count': result['predict_roads_count'],
                'precision': result['precision'],
                'recall': result['recall'],
                'f1_score': result['f1_score'],
                'accuracy': result['accuracy'],
                'correct_predictions': result['correct_predictions']
            })
            
        summary_df = pd.DataFrame(summary_data)
        summary_df.to_csv(result_dir / "performance_summary.csv", index=False)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {result_dir}")
        print(f"   - experiment_results.json (è¯¦ç»†ç»“æœ)")
        print(f"   - performance_summary.csv (æ€§èƒ½æ±‡æ€»)")
        
        return result_dir

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŠ Charlestonæ´ªæ°´é¢„æµ‹ - 10æ¬¡æ´ªæ°´æ—¥æœŸäº¤å‰éªŒè¯")
    print("åŸºäºTop 10å†å²æ´ªæ°´äº‹ä»¶çš„è´å¶æ–¯ç½‘ç»œæ€§èƒ½è¯„ä¼°")
    
    validator = FloodDateCrossValidator()
    results = validator.run_all_experiments()
    
    if results:
        print(f"\nğŸ‰ å®éªŒå®Œæˆï¼æˆåŠŸå®Œæˆ {len(results)} æ¬¡å®éªŒ")
    else:
        print(f"\nğŸ’¥ å®éªŒå¤±è´¥ï¼è¯·æ£€æŸ¥æ•°æ®å’Œå‚æ•°è®¾ç½®")
    
    return validator, results

if __name__ == "__main__":
    validator, results = main()