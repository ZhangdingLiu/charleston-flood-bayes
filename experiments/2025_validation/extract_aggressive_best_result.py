#!/usr/bin/env python3
"""
ä»æ¿€è¿›ç­–ç•¥å®éªŒä¸­æå–æœ€ä½³ç»“æœ
æŒ‰ç…§ best_2017_09_11_threshold_04_experiment.json æ ¼å¼è¾“å‡º
"""

import json
import csv
from datetime import datetime

def extract_aggressive_best_result():
    print("ğŸ” æå–æ¿€è¿›ç­–ç•¥æœ€ä½³å®éªŒç»“æœ...")
    
    # 1. åŠ è½½æ¿€è¿›ç­–ç•¥çš„CSVæ•°æ®
    aggressive_results = []
    with open('enhanced_coverage_validation_summary_20250820_212943.csv', 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            if row['strategy'] == 'aggressive':
                # è½¬æ¢æ•°å€¼å­—æ®µ
                numeric_fields = ['pred_threshold', 'coverage_rate', 'test_roads_total', 
                                'test_roads_in_network', 'network_nodes', 'network_edges',
                                'precision', 'recall', 'f1_score', 'accuracy', 
                                'tp', 'fp', 'tn', 'fn', 'trial_id']
                for field in numeric_fields:
                    if field in row and row[field]:
                        row[field] = float(row[field])
                aggressive_results.append(row)
    
    print(f"âœ… åŠ è½½æ¿€è¿›ç­–ç•¥å®éªŒ: {len(aggressive_results)} æ¡è®°å½•")
    
    # 2. æ‰¾åˆ°æœ€ä½³F1åˆ†æ•°çš„å®éªŒ (æ’é™¤F1=0çš„)
    valid_results = [r for r in aggressive_results if r['f1_score'] > 0]
    if not valid_results:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ¿€è¿›ç­–ç•¥ç»“æœ")
        return
    
    best_result = max(valid_results, key=lambda x: x['f1_score'])
    print(f"ğŸ† æœ€ä½³å®éªŒ: é˜ˆå€¼{best_result['pred_threshold']}, F1={best_result['f1_score']:.3f}")
    
    # 3. åŠ è½½å¯¹åº”çš„è¯¦ç»†JSONæ•°æ®
    with open('enhanced_coverage_validation_results_20250820_212943.json', 'r', encoding='utf-8') as f:
        detailed_data = json.load(f)
    
    # 4. æ‰¾åˆ°åŒ¹é…çš„è¯¦ç»†å®éªŒ
    target_threshold = best_result['pred_threshold'] 
    target_trial = int(best_result['trial_id'])
    
    matching_experiment = None
    for exp in detailed_data['detailed_results']:
        if (exp['strategy'] == 'aggressive' and 
            exp['pred_threshold'] == target_threshold and 
            exp['trial_id'] == target_trial):
            matching_experiment = exp
            break
    
    if not matching_experiment:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è¯¦ç»†å®éªŒæ•°æ®")
        return
    
    print(f"âœ… æ‰¾åˆ°åŒ¹é…çš„è¯¦ç»†å®éªŒ")
    
    # 5. æŒ‰ç…§åŸºçº¿æ ¼å¼æ„é€ ç»“æœ
    best_experiment_result = {
        "experiment_info": {
            "date": matching_experiment['test_date'],
            "threshold": matching_experiment['pred_threshold'],
            "trial_id": matching_experiment['trial_id'],
            "strategy": "aggressive_enhanced_coverage",
            "strategy_name": "æ¿€è¿›ä¼˜åŒ–ç­–ç•¥(å¢å¼ºè¦†ç›–ç‡)",
            "network_type": "enhanced_bayesian_network", 
            "performance": {
                "precision": matching_experiment['precision'],
                "recall": matching_experiment['recall'],
                "f1_score": matching_experiment['f1_score'],
                "accuracy": matching_experiment['accuracy']
            },
            "network_stats": {
                "total_nodes": matching_experiment['network_nodes'],
                "total_edges": matching_experiment['network_edges'],
                "coverage_rate": matching_experiment['coverage_rate'],
                "test_roads_covered": f"{matching_experiment['test_roads_in_network']}/{matching_experiment['test_roads_total']}"
            }
        },
        "best_experiment": {
            "test_date": matching_experiment['test_date'],
            "pred_threshold": matching_experiment['pred_threshold'], 
            "trial_id": matching_experiment['trial_id'],
            "test_roads_total": matching_experiment['test_roads_total'],
            "test_roads_in_network": matching_experiment['test_roads_in_network'],
            "coverage_rate": matching_experiment['coverage_rate'],
            "evidence_roads_count": len(matching_experiment['evidence_roads']),
            "positive_predict_roads_count": matching_experiment['positive_predict_roads_count'],
            "negative_predict_roads_count": matching_experiment['negative_predict_roads_count'],
            "total_predict_roads_count": matching_experiment['total_predict_roads_count'],
            "successful_predictions": matching_experiment['successful_predictions'],
            "failed_predictions": matching_experiment['failed_predictions'],
            "prediction_mode": "full_network_enhanced_coverage",
            "evidence_roads": matching_experiment['evidence_roads'],
            "network_parameters": {
                "occ_thr": 1,      # æ¿€è¿›ç­–ç•¥å‚æ•°
                "edge_thr": 1,
                "weight_thr": 0.05,
                "evidence_ratio": 0.3
            },
            "performance_metrics": {
                "precision": matching_experiment['precision'],
                "recall": matching_experiment['recall'], 
                "f1_score": matching_experiment['f1_score'],
                "accuracy": matching_experiment['accuracy'],
                "tp": matching_experiment['tp'],
                "fp": matching_experiment['fp'], 
                "tn": matching_experiment['tn'],
                "fn": matching_experiment['fn']
            },
            "network_statistics": {
                "total_nodes": matching_experiment['network_nodes'],
                "total_edges": matching_experiment['network_edges'],
                "nodes_vs_baseline": f"{matching_experiment['network_nodes']} vs 40 (åŸºçº¿)",
                "edges_vs_baseline": f"{matching_experiment['network_edges']} vs 39 (åŸºçº¿)",
                "coverage_improvement": f"{matching_experiment['coverage_rate']:.1%} vs 50% (åŸºçº¿)"
            },
            "detailed_predictions": matching_experiment['detailed_predictions']
        },
        "analysis": {
            "key_improvements": [
                f"ç½‘ç»œè§„æ¨¡æ‰©å¤§è‡³{matching_experiment['network_nodes']}ä¸ªèŠ‚ç‚¹",
                f"è¦†ç›–ç‡æå‡è‡³{matching_experiment['coverage_rate']:.1%} ({matching_experiment['test_roads_in_network']}/{matching_experiment['test_roads_total']}æ¡é“è·¯)",
                f"å¯é¢„æµ‹{matching_experiment['total_predict_roads_count']}æ¡é“è·¯çŠ¶æ€",
                f"ä½¿ç”¨å…¨å†å²æ•°æ®è®­ç»ƒ(855æ¡è®°å½•)"
            ],
            "performance_vs_baseline": {
                "coverage_rate": {
                    "enhanced": matching_experiment['coverage_rate'],
                    "baseline": 0.50,  # åŸºçº¿çº¦50%
                    "improvement": f"+{(matching_experiment['coverage_rate'] - 0.50)*100:.1f}ä¸ªç™¾åˆ†ç‚¹"
                },
                "network_nodes": {
                    "enhanced": matching_experiment['network_nodes'],
                    "baseline": 40,
                    "improvement": f"+{matching_experiment['network_nodes'] - 40}ä¸ªèŠ‚ç‚¹"
                },
                "predictable_roads": {
                    "enhanced": matching_experiment['total_predict_roads_count'],
                    "baseline": 33,  # åŸºçº¿é¢„æµ‹33æ¡é“è·¯
                    "improvement": f"+{matching_experiment['total_predict_roads_count'] - 33}æ¡é“è·¯"
                }
            },
            "trade_offs": {
                "advantages": [
                    f"è¦†ç›–ç‡å¤§å¹…æå‡({matching_experiment['coverage_rate']:.1%})",
                    f"ç½‘ç»œè§„æ¨¡æ˜¾è‘—æ‰©å¤§({matching_experiment['network_nodes']}èŠ‚ç‚¹)",
                    "å¯ç›‘æ§æ›´å¤šé“è·¯",
                    "ç²¾åº¦ä¾ç„¶ä¿æŒ100%"
                ],
                "challenges": [
                    f"å¬å›ç‡ç›¸å¯¹è¾ƒä½({matching_experiment['recall']:.1%})",
                    "å¤§ç½‘ç»œå¯¼è‡´é¢„æµ‹æ¦‚ç‡æ™®éåä½",
                    "ç¨€ç–æ•°æ®é—®é¢˜",
                    f"F1åˆ†æ•°({matching_experiment['f1_score']:.3f})ä½äºåŸºçº¿"
                ]
            },
            "recommendations": [
                "é€‚ç”¨äºæœ€å¤§åŒ–ç›‘æ§è¦†ç›–èŒƒå›´çš„åœºæ™¯",
                "å¯å®¹å¿è¾ƒå¤šæ¼æŠ¥ä½†è¦æ±‚é›¶è¯¯æŠ¥",
                "å»ºè®®ç»“åˆå¤šä¸ªé˜ˆå€¼è¿›è¡Œé¢„è­¦åˆ†çº§",
                "è€ƒè™‘å‚æ•°å¾®è°ƒå¹³è¡¡è¦†ç›–ç‡ä¸æ€§èƒ½"
            ]
        },
        "metadata": {
            "generation_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "source_experiment": "enhanced_coverage_validation.py",
            "comparison_baseline": "best_2017_09_11_threshold_04_experiment.json",
            "methodology": "enhanced_coverage_bayesian_inference",
            "training_data": "å…¨å†å²æ•°æ®(é™¤æµ‹è¯•æ—¥æœŸ)",
            "test_date_description": "2017å¹´9æœˆ11æ—¥æ´ªæ°´äº‹ä»¶ - Charlestonæœ€ä¸¥é‡æ´ªæ°´ä¹‹ä¸€"
        }
    }
    
    # 6. ä¿å­˜ç»“æœ
    output_file = f"aggressive_best_2017_09_11_threshold_{target_threshold:.1f}_experiment.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(best_experiment_result, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ æ¿€è¿›ç­–ç•¥æœ€ä½³å®éªŒç»“æœå·²ä¿å­˜: {output_file}")
    
    # 7. è¾“å‡ºå…³é”®ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š æ¿€è¿›ç­–ç•¥(121èŠ‚ç‚¹)æœ€ä½³å®éªŒæ‘˜è¦:")
    print(f"{'='*60}")
    print(f"ğŸ¯ å®éªŒé…ç½®:")
    print(f"   æµ‹è¯•æ—¥æœŸ: {matching_experiment['test_date']}")
    print(f"   é¢„æµ‹é˜ˆå€¼: {matching_experiment['pred_threshold']}")
    print(f"   è¯•éªŒID: {matching_experiment['trial_id']}")
    
    print(f"\nğŸŒ ç½‘ç»œè§„æ¨¡:")
    print(f"   æ€»èŠ‚ç‚¹æ•°: {matching_experiment['network_nodes']} (vs åŸºçº¿40)")
    print(f"   æ€»è¾¹æ•°: {matching_experiment['network_edges']} (vs åŸºçº¿39)")
    print(f"   è¦†ç›–ç‡: {matching_experiment['coverage_rate']:.1%} ({matching_experiment['test_roads_in_network']}/{matching_experiment['test_roads_total']})")
    
    print(f"\nğŸ”¬ é¢„æµ‹ç»Ÿè®¡:")
    print(f"   è¯æ®é“è·¯: {len(matching_experiment['evidence_roads'])} æ¡")
    print(f"   é¢„æµ‹é“è·¯: {matching_experiment['total_predict_roads_count']} æ¡")
    print(f"   æ­£æ ·æœ¬: {matching_experiment['positive_predict_roads_count']} æ¡")
    print(f"   è´Ÿæ ·æœ¬: {matching_experiment['negative_predict_roads_count']} æ¡")
    
    print(f"\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
    print(f"   Precision: {matching_experiment['precision']:.3f} (100% - æ— è¯¯æŠ¥)")
    print(f"   Recall: {matching_experiment['recall']:.3f} ({matching_experiment['recall']*100:.1f}%)")
    print(f"   F1 Score: {matching_experiment['f1_score']:.3f}")
    print(f"   Accuracy: {matching_experiment['accuracy']:.3f} ({matching_experiment['accuracy']*100:.1f}%)")
    
    print(f"\nğŸ“Š æ··æ·†çŸ©é˜µ:")
    print(f"   TP: {matching_experiment['tp']} (æ­£ç¡®é¢„æµ‹æ´ªæ°´)")
    print(f"   FP: {matching_experiment['fp']} (è¯¯æŠ¥)")
    print(f"   TN: {matching_experiment['tn']} (æ­£ç¡®é¢„æµ‹æ— æ´ªæ°´)") 
    print(f"   FN: {matching_experiment['fn']} (æ¼æŠ¥)")
    
    # 8. æ˜¾ç¤ºè¯¦ç»†é¢„æµ‹æ ·ä¾‹
    predictions = matching_experiment['detailed_predictions']
    tp_roads = [p for p in predictions if p['true_label'] == 1 and p['predicted_label'] == 1]
    fn_roads = [p for p in predictions if p['true_label'] == 1 and p['predicted_label'] == 0]
    
    print(f"\nğŸ›£ï¸ é¢„æµ‹æ ·ä¾‹:")
    print(f"   âœ… æˆåŠŸé¢„æµ‹æ´ªæ°´é“è·¯ (å‰5æ¡):")
    tp_roads.sort(key=lambda x: x['predicted_probability'], reverse=True)
    for i, road in enumerate(tp_roads[:5]):
        print(f"     {i+1}. {road['road_name']}: æ¦‚ç‡{road['predicted_probability']:.3f}")
    
    print(f"   âš ï¸ æ¼æŠ¥æ´ªæ°´é“è·¯ (å‰5æ¡):")
    fn_roads.sort(key=lambda x: x['predicted_probability'], reverse=True) 
    for i, road in enumerate(fn_roads[:5]):
        print(f"     {i+1}. {road['road_name']}: æ¦‚ç‡{road['predicted_probability']:.3f}")
    
    return output_file

if __name__ == "__main__":
    result_file = extract_aggressive_best_result()